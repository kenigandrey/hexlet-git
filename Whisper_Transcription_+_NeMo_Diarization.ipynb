{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kenigandrey/hexlet-git/blob/main/Whisper_Transcription_%2B_NeMo_Diarization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eCmjcOc9yEtQ"
      },
      "source": [
        "# Installing Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Tn1c-CoDv2kw",
        "outputId": "cbb13706-97a0-4ee4-8974-7316b73bb300",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/SYSTRAN/faster-whisper.git\n",
            "  Cloning https://github.com/SYSTRAN/faster-whisper.git to /tmp/pip-req-build-o01ra7dt\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/SYSTRAN/faster-whisper.git /tmp/pip-req-build-o01ra7dt\n",
            "  Resolved https://github.com/SYSTRAN/faster-whisper.git to commit fb65cd387f4941e1bf2381b88b0f6b9957e56e03\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: ctranslate2==4.4.0 in /usr/local/lib/python3.10/dist-packages (4.4.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from ctranslate2==4.4.0) (75.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from ctranslate2==4.4.0) (1.26.4)\n",
            "Requirement already satisfied: pyyaml<7,>=5.3 in /usr/local/lib/python3.10/dist-packages (from ctranslate2==4.4.0) (6.0.2)\n",
            "Requirement already satisfied: huggingface_hub>=0.13 in /usr/local/lib/python3.10/dist-packages (from faster-whisper==1.1.0rc0) (0.26.2)\n",
            "Requirement already satisfied: tokenizers<1,>=0.13 in /usr/local/lib/python3.10/dist-packages (from faster-whisper==1.1.0rc0) (0.20.3)\n",
            "Requirement already satisfied: onnxruntime<2,>=1.14 in /usr/local/lib/python3.10/dist-packages (from faster-whisper==1.1.0rc0) (1.20.0)\n",
            "Requirement already satisfied: torch>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from faster-whisper==1.1.0rc0) (2.5.0+cu121)\n",
            "Requirement already satisfied: av>=11 in /usr/local/lib/python3.10/dist-packages (from faster-whisper==1.1.0rc0) (13.1.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from faster-whisper==1.1.0rc0) (4.66.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub>=0.13->faster-whisper==1.1.0rc0) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub>=0.13->faster-whisper==1.1.0rc0) (2024.9.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub>=0.13->faster-whisper==1.1.0rc0) (24.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub>=0.13->faster-whisper==1.1.0rc0) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub>=0.13->faster-whisper==1.1.0rc0) (4.12.2)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.10/dist-packages (from onnxruntime<2,>=1.14->faster-whisper==1.1.0rc0) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime<2,>=1.14->faster-whisper==1.1.0rc0) (24.3.25)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime<2,>=1.14->faster-whisper==1.1.0rc0) (4.25.5)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime<2,>=1.14->faster-whisper==1.1.0rc0) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.1->faster-whisper==1.1.0rc0) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.1->faster-whisper==1.1.0rc0) (3.1.4)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime<2,>=1.14->faster-whisper==1.1.0rc0) (1.3.0)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.10/dist-packages (from coloredlogs->onnxruntime<2,>=1.14->faster-whisper==1.1.0rc0) (10.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.1.1->faster-whisper==1.1.0rc0) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub>=0.13->faster-whisper==1.1.0rc0) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub>=0.13->faster-whisper==1.1.0rc0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub>=0.13->faster-whisper==1.1.0rc0) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub>=0.13->faster-whisper==1.1.0rc0) (2024.8.30)\n",
            "Requirement already satisfied: nemo-toolkit>=2.dev in /usr/local/lib/python3.10/dist-packages (from nemo-toolkit[asr]>=2.dev) (2.0.0rc1)\n",
            "Requirement already satisfied: fiddle in /usr/local/lib/python3.10/dist-packages (from nemo-toolkit>=2.dev->nemo-toolkit[asr]>=2.dev) (0.3.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.24 in /usr/local/lib/python3.10/dist-packages (from nemo-toolkit>=2.dev->nemo-toolkit[asr]>=2.dev) (0.26.2)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from nemo-toolkit>=2.dev->nemo-toolkit[asr]>=2.dev) (0.60.0)\n",
            "Requirement already satisfied: numpy>=1.22 in /usr/local/lib/python3.10/dist-packages (from nemo-toolkit>=2.dev->nemo-toolkit[asr]>=2.dev) (1.26.4)\n",
            "Requirement already satisfied: onnx>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from nemo-toolkit>=2.dev->nemo-toolkit[asr]>=2.dev) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from nemo-toolkit>=2.dev->nemo-toolkit[asr]>=2.dev) (2.8.2)\n",
            "Requirement already satisfied: ruamel.yaml in /usr/local/lib/python3.10/dist-packages (from nemo-toolkit>=2.dev->nemo-toolkit[asr]>=2.dev) (0.18.6)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from nemo-toolkit>=2.dev->nemo-toolkit[asr]>=2.dev) (1.5.2)\n",
            "Requirement already satisfied: setuptools>=65.5.1 in /usr/local/lib/python3.10/dist-packages (from nemo-toolkit>=2.dev->nemo-toolkit[asr]>=2.dev) (75.1.0)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (from nemo-toolkit>=2.dev->nemo-toolkit[asr]>=2.dev) (2.17.0)\n",
            "Requirement already satisfied: text-unidecode in /usr/local/lib/python3.10/dist-packages (from nemo-toolkit>=2.dev->nemo-toolkit[asr]>=2.dev) (1.3)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from nemo-toolkit>=2.dev->nemo-toolkit[asr]>=2.dev) (2.5.0+cu121)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from nemo-toolkit>=2.dev->nemo-toolkit[asr]>=2.dev) (4.66.6)\n",
            "Requirement already satisfied: wget in /usr/local/lib/python3.10/dist-packages (from nemo-toolkit>=2.dev->nemo-toolkit[asr]>=2.dev) (3.2)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from nemo-toolkit>=2.dev->nemo-toolkit[asr]>=2.dev) (1.16.0)\n",
            "Requirement already satisfied: braceexpand in /usr/local/lib/python3.10/dist-packages (from nemo-toolkit[asr]>=2.dev) (0.1.7)\n",
            "Requirement already satisfied: editdistance in /usr/local/lib/python3.10/dist-packages (from nemo-toolkit[asr]>=2.dev) (0.8.1)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (from nemo-toolkit[asr]>=2.dev) (0.8.0)\n",
            "Requirement already satisfied: g2p-en in /usr/local/lib/python3.10/dist-packages (from nemo-toolkit[asr]>=2.dev) (2.1.0)\n",
            "Requirement already satisfied: jiwer in /usr/local/lib/python3.10/dist-packages (from nemo-toolkit[asr]>=2.dev) (3.0.5)\n",
            "Requirement already satisfied: kaldi-python-io in /usr/local/lib/python3.10/dist-packages (from nemo-toolkit[asr]>=2.dev) (1.2.2)\n",
            "Requirement already satisfied: kaldiio in /usr/local/lib/python3.10/dist-packages (from nemo-toolkit[asr]>=2.dev) (2.18.0)\n",
            "Requirement already satisfied: lhotse>=1.24.2 in /usr/local/lib/python3.10/dist-packages (from nemo-toolkit[asr]>=2.dev) (1.27.0)\n",
            "Requirement already satisfied: librosa>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from nemo-toolkit[asr]>=2.dev) (0.10.2.post1)\n",
            "Requirement already satisfied: marshmallow in /usr/local/lib/python3.10/dist-packages (from nemo-toolkit[asr]>=2.dev) (3.23.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from nemo-toolkit[asr]>=2.dev) (24.2)\n",
            "Requirement already satisfied: pyannote.core in /usr/local/lib/python3.10/dist-packages (from nemo-toolkit[asr]>=2.dev) (5.0.0)\n",
            "Requirement already satisfied: pyannote.metrics in /usr/local/lib/python3.10/dist-packages (from nemo-toolkit[asr]>=2.dev) (3.2.1)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (from nemo-toolkit[asr]>=2.dev) (0.25.1)\n",
            "Requirement already satisfied: pyloudnorm in /usr/local/lib/python3.10/dist-packages (from nemo-toolkit[asr]>=2.dev) (0.1.1)\n",
            "Requirement already satisfied: resampy in /usr/local/lib/python3.10/dist-packages (from nemo-toolkit[asr]>=2.dev) (0.4.3)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.10/dist-packages (from nemo-toolkit[asr]>=2.dev) (1.13.1)\n",
            "Requirement already satisfied: soundfile in /usr/local/lib/python3.10/dist-packages (from nemo-toolkit[asr]>=2.dev) (0.12.1)\n",
            "Requirement already satisfied: sox in /usr/local/lib/python3.10/dist-packages (from nemo-toolkit[asr]>=2.dev) (1.5.0)\n",
            "Requirement already satisfied: texterrors in /usr/local/lib/python3.10/dist-packages (from nemo-toolkit[asr]>=2.dev) (0.5.1)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from nemo-toolkit[asr]>=2.dev) (3.1.0)\n",
            "Requirement already satisfied: hydra-core<=1.3.2,>1.3 in /usr/local/lib/python3.10/dist-packages (from nemo-toolkit[asr]>=2.dev) (1.3.2)\n",
            "Requirement already satisfied: omegaconf<=2.3 in /usr/local/lib/python3.10/dist-packages (from nemo-toolkit[asr]>=2.dev) (2.3.0)\n",
            "Requirement already satisfied: pytorch-lightning>2.2.1 in /usr/local/lib/python3.10/dist-packages (from nemo-toolkit[asr]>=2.dev) (2.4.0)\n",
            "Requirement already satisfied: torchmetrics>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from nemo-toolkit[asr]>=2.dev) (1.6.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from nemo-toolkit[asr]>=2.dev) (4.46.2)\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.10/dist-packages (from nemo-toolkit[asr]>=2.dev) (0.18.6)\n",
            "Requirement already satisfied: webdataset>=0.2.86 in /usr/local/lib/python3.10/dist-packages (from nemo-toolkit[asr]>=2.dev) (0.2.100)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (from nemo-toolkit[asr]>=2.dev) (3.1.0)\n",
            "Requirement already satisfied: inflect in /usr/local/lib/python3.10/dist-packages (from nemo-toolkit[asr]>=2.dev) (7.4.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from nemo-toolkit[asr]>=2.dev) (2.2.2)\n",
            "Requirement already satisfied: sacremoses>=0.0.43 in /usr/local/lib/python3.10/dist-packages (from nemo-toolkit[asr]>=2.dev) (0.1.1)\n",
            "Requirement already satisfied: sentencepiece<1.0.0 in /usr/local/lib/python3.10/dist-packages (from nemo-toolkit[asr]>=2.dev) (0.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.24->nemo-toolkit>=2.dev->nemo-toolkit[asr]>=2.dev) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.24->nemo-toolkit>=2.dev->nemo-toolkit[asr]>=2.dev) (2024.9.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.24->nemo-toolkit>=2.dev->nemo-toolkit[asr]>=2.dev) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.24->nemo-toolkit>=2.dev->nemo-toolkit[asr]>=2.dev) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.24->nemo-toolkit>=2.dev->nemo-toolkit[asr]>=2.dev) (4.12.2)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.10/dist-packages (from hydra-core<=1.3.2,>1.3->nemo-toolkit[asr]>=2.dev) (4.9.3)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.10/dist-packages (from lhotse>=1.24.2->nemo-toolkit[asr]>=2.dev) (3.0.1)\n",
            "Requirement already satisfied: click>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from lhotse>=1.24.2->nemo-toolkit[asr]>=2.dev) (8.1.7)\n",
            "Requirement already satisfied: cytoolz>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from lhotse>=1.24.2->nemo-toolkit[asr]>=2.dev) (1.0.0)\n",
            "Requirement already satisfied: intervaltree>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from lhotse>=1.24.2->nemo-toolkit[asr]>=2.dev) (3.1.0)\n",
            "Requirement already satisfied: tabulate>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from lhotse>=1.24.2->nemo-toolkit[asr]>=2.dev) (0.9.0)\n",
            "Requirement already satisfied: lilcom>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from lhotse>=1.24.2->nemo-toolkit[asr]>=2.dev) (1.8.0)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.10.0->nemo-toolkit[asr]>=2.dev) (1.4.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.10.0->nemo-toolkit[asr]>=2.dev) (4.4.2)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.10.0->nemo-toolkit[asr]>=2.dev) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.10.0->nemo-toolkit[asr]>=2.dev) (0.5.0.post1)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.10.0->nemo-toolkit[asr]>=2.dev) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.10.0->nemo-toolkit[asr]>=2.dev) (1.1.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->nemo-toolkit>=2.dev->nemo-toolkit[asr]>=2.dev) (0.43.0)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from onnx>=1.7.0->nemo-toolkit>=2.dev->nemo-toolkit[asr]>=2.dev) (4.25.5)\n",
            "Requirement already satisfied: lightning-utilities>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning>2.2.1->nemo-toolkit[asr]>=2.dev) (0.11.8)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from sacremoses>=0.0.43->nemo-toolkit[asr]>=2.dev) (2024.9.11)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->nemo-toolkit>=2.dev->nemo-toolkit[asr]>=2.dev) (3.5.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile->nemo-toolkit[asr]>=2.dev) (1.17.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->nemo-toolkit>=2.dev->nemo-toolkit[asr]>=2.dev) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->nemo-toolkit>=2.dev->nemo-toolkit[asr]>=2.dev) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->nemo-toolkit>=2.dev->nemo-toolkit[asr]>=2.dev) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->nemo-toolkit>=2.dev->nemo-toolkit[asr]>=2.dev) (1.3.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->nemo-toolkit[asr]>=2.dev) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets->nemo-toolkit[asr]>=2.dev) (0.3.8)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets->nemo-toolkit[asr]>=2.dev) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets->nemo-toolkit[asr]>=2.dev) (0.70.16)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets->nemo-toolkit[asr]>=2.dev) (3.10.10)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from fiddle->nemo-toolkit>=2.dev->nemo-toolkit[asr]>=2.dev) (1.4.0)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from fiddle->nemo-toolkit>=2.dev->nemo-toolkit[asr]>=2.dev) (0.20.3)\n",
            "Requirement already satisfied: libcst in /usr/local/lib/python3.10/dist-packages (from fiddle->nemo-toolkit>=2.dev->nemo-toolkit[asr]>=2.dev) (1.5.0)\n",
            "Requirement already satisfied: nltk>=3.2.4 in /usr/local/lib/python3.10/dist-packages (from g2p-en->nemo-toolkit[asr]>=2.dev) (3.9.1)\n",
            "Requirement already satisfied: distance>=0.1.3 in /usr/local/lib/python3.10/dist-packages (from g2p-en->nemo-toolkit[asr]>=2.dev) (0.1.3)\n",
            "Requirement already satisfied: more-itertools>=8.5.0 in /usr/local/lib/python3.10/dist-packages (from inflect->nemo-toolkit[asr]>=2.dev) (10.5.0)\n",
            "Requirement already satisfied: typeguard>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from inflect->nemo-toolkit[asr]>=2.dev) (4.4.1)\n",
            "Requirement already satisfied: rapidfuzz<4,>=3 in /usr/local/lib/python3.10/dist-packages (from jiwer->nemo-toolkit[asr]>=2.dev) (3.10.1)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->nemo-toolkit[asr]>=2.dev) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->nemo-toolkit[asr]>=2.dev) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil->nemo-toolkit>=2.dev->nemo-toolkit[asr]>=2.dev) (1.16.0)\n",
            "Requirement already satisfied: sortedcontainers>=2.0.4 in /usr/local/lib/python3.10/dist-packages (from pyannote.core->nemo-toolkit[asr]>=2.dev) (2.4.0)\n",
            "Requirement already satisfied: pyannote.database>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from pyannote.metrics->nemo-toolkit[asr]>=2.dev) (5.1.0)\n",
            "Requirement already satisfied: docopt>=0.6.2 in /usr/local/lib/python3.10/dist-packages (from pyannote.metrics->nemo-toolkit[asr]>=2.dev) (0.6.2)\n",
            "Requirement already satisfied: matplotlib>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pyannote.metrics->nemo-toolkit[asr]>=2.dev) (3.8.0)\n",
            "Requirement already satisfied: future>=0.16.0 in /usr/local/lib/python3.10/dist-packages (from pyloudnorm->nemo-toolkit[asr]>=2.dev) (1.0.0)\n",
            "Requirement already satisfied: ruamel.yaml.clib>=0.2.7 in /usr/local/lib/python3.10/dist-packages (from ruamel.yaml->nemo-toolkit>=2.dev->nemo-toolkit[asr]>=2.dev) (0.2.12)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard->nemo-toolkit>=2.dev->nemo-toolkit[asr]>=2.dev) (1.67.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard->nemo-toolkit>=2.dev->nemo-toolkit[asr]>=2.dev) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->nemo-toolkit>=2.dev->nemo-toolkit[asr]>=2.dev) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard->nemo-toolkit>=2.dev->nemo-toolkit[asr]>=2.dev) (3.1.3)\n",
            "Requirement already satisfied: pybind11 in /usr/local/lib/python3.10/dist-packages (from texterrors->nemo-toolkit[asr]>=2.dev) (2.13.6)\n",
            "Requirement already satisfied: plac in /usr/local/lib/python3.10/dist-packages (from texterrors->nemo-toolkit[asr]>=2.dev) (1.4.3)\n",
            "Requirement already satisfied: loguru in /usr/local/lib/python3.10/dist-packages (from texterrors->nemo-toolkit[asr]>=2.dev) (0.7.2)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from texterrors->nemo-toolkit[asr]>=2.dev) (2.5.0)\n",
            "Requirement already satisfied: Levenshtein in /usr/local/lib/python3.10/dist-packages (from texterrors->nemo-toolkit[asr]>=2.dev) (0.26.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers->nemo-toolkit[asr]>=2.dev) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers->nemo-toolkit[asr]>=2.dev) (0.20.3)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb->nemo-toolkit[asr]>=2.dev) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb->nemo-toolkit[asr]>=2.dev) (3.1.43)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb->nemo-toolkit[asr]>=2.dev) (4.3.6)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb->nemo-toolkit[asr]>=2.dev) (5.9.5)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb->nemo-toolkit[asr]>=2.dev) (2.18.0)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb->nemo-toolkit[asr]>=2.dev) (1.3.3)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile->nemo-toolkit[asr]>=2.dev) (2.22)\n",
            "Requirement already satisfied: toolz>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from cytoolz>=0.10.1->lhotse>=1.24.2->nemo-toolkit[asr]>=2.dev) (0.12.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->nemo-toolkit[asr]>=2.dev) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->nemo-toolkit[asr]>=2.dev) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->nemo-toolkit[asr]>=2.dev) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->nemo-toolkit[asr]>=2.dev) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->nemo-toolkit[asr]>=2.dev) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->nemo-toolkit[asr]>=2.dev) (1.17.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->nemo-toolkit[asr]>=2.dev) (4.0.3)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb->nemo-toolkit[asr]>=2.dev) (4.0.11)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.0.0->pyannote.metrics->nemo-toolkit[asr]>=2.dev) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.0.0->pyannote.metrics->nemo-toolkit[asr]>=2.dev) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.0.0->pyannote.metrics->nemo-toolkit[asr]>=2.dev) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.0.0->pyannote.metrics->nemo-toolkit[asr]>=2.dev) (1.4.7)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.0.0->pyannote.metrics->nemo-toolkit[asr]>=2.dev) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.0.0->pyannote.metrics->nemo-toolkit[asr]>=2.dev) (3.2.0)\n",
            "Requirement already satisfied: typer>=0.12.1 in /usr/local/lib/python3.10/dist-packages (from pyannote.database>=4.0.1->pyannote.metrics->nemo-toolkit[asr]>=2.dev) (0.13.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.24->nemo-toolkit>=2.dev->nemo-toolkit[asr]>=2.dev) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.24->nemo-toolkit>=2.dev->nemo-toolkit[asr]>=2.dev) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.24->nemo-toolkit>=2.dev->nemo-toolkit[asr]>=2.dev) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.24->nemo-toolkit>=2.dev->nemo-toolkit[asr]>=2.dev) (2024.8.30)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard->nemo-toolkit>=2.dev->nemo-toolkit[asr]>=2.dev) (3.0.2)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb->nemo-toolkit[asr]>=2.dev) (5.0.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.12.1->pyannote.database>=4.0.1->pyannote.metrics->nemo-toolkit[asr]>=2.dev) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.12.1->pyannote.database>=4.0.1->pyannote.metrics->nemo-toolkit[asr]>=2.dev) (13.9.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp->datasets->nemo-toolkit[asr]>=2.dev) (0.2.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer>=0.12.1->pyannote.database>=4.0.1->pyannote.metrics->nemo-toolkit[asr]>=2.dev) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer>=0.12.1->pyannote.database>=4.0.1->pyannote.metrics->nemo-toolkit[asr]>=2.dev) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer>=0.12.1->pyannote.database>=4.0.1->pyannote.metrics->nemo-toolkit[asr]>=2.dev) (0.1.2)\n",
            "Collecting git+https://github.com/MahmoudAshraf97/demucs.git\n",
            "  Cloning https://github.com/MahmoudAshraf97/demucs.git to /tmp/pip-req-build-69_g6dwl\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/MahmoudAshraf97/demucs.git /tmp/pip-req-build-69_g6dwl\n",
            "  Resolved https://github.com/MahmoudAshraf97/demucs.git to commit 4273070a70ded308ddfd0879d267bbd06f89a1b7\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: dora-search in /usr/local/lib/python3.10/dist-packages (from demucs==4.1.0a3) (0.1.12)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (from demucs==4.1.0a3) (0.8.0)\n",
            "Requirement already satisfied: julius>=0.2.3 in /usr/local/lib/python3.10/dist-packages (from demucs==4.1.0a3) (0.2.7)\n",
            "Requirement already satisfied: lameenc>=1.2 in /usr/local/lib/python3.10/dist-packages (from demucs==4.1.0a3) (1.7.0)\n",
            "Requirement already satisfied: openunmix in /usr/local/lib/python3.10/dist-packages (from demucs==4.1.0a3) (1.3.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from demucs==4.1.0a3) (6.0.2)\n",
            "Requirement already satisfied: torch>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from demucs==4.1.0a3) (2.5.0+cu121)\n",
            "Requirement already satisfied: torchaudio>=0.8 in /usr/local/lib/python3.10/dist-packages (from demucs==4.1.0a3) (2.5.0+cu121)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from demucs==4.1.0a3) (4.66.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->demucs==4.1.0a3) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->demucs==4.1.0a3) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->demucs==4.1.0a3) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->demucs==4.1.0a3) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->demucs==4.1.0a3) (2024.9.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->demucs==4.1.0a3) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.8.1->demucs==4.1.0a3) (1.3.0)\n",
            "Requirement already satisfied: omegaconf in /usr/local/lib/python3.10/dist-packages (from dora-search->demucs==4.1.0a3) (2.3.0)\n",
            "Requirement already satisfied: retrying in /usr/local/lib/python3.10/dist-packages (from dora-search->demucs==4.1.0a3) (1.3.4)\n",
            "Requirement already satisfied: submitit in /usr/local/lib/python3.10/dist-packages (from dora-search->demucs==4.1.0a3) (1.5.2)\n",
            "Requirement already satisfied: treetable in /usr/local/lib/python3.10/dist-packages (from dora-search->demucs==4.1.0a3) (0.2.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from openunmix->demucs==4.1.0a3) (1.26.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.1->demucs==4.1.0a3) (3.0.2)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.10/dist-packages (from omegaconf->dora-search->demucs==4.1.0a3) (4.9.3)\n",
            "Requirement already satisfied: six>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from retrying->dora-search->demucs==4.1.0a3) (1.16.0)\n",
            "Requirement already satisfied: cloudpickle>=1.2.1 in /usr/local/lib/python3.10/dist-packages (from submitit->dora-search->demucs==4.1.0a3) (3.1.0)\n",
            "Collecting git+https://github.com/oliverguhr/deepmultilingualpunctuation.git\n",
            "  Cloning https://github.com/oliverguhr/deepmultilingualpunctuation.git to /tmp/pip-req-build-rlcuth1x\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/oliverguhr/deepmultilingualpunctuation.git /tmp/pip-req-build-rlcuth1x\n",
            "  Resolved https://github.com/oliverguhr/deepmultilingualpunctuation.git to commit 5a0dd7f4fd56687f59405aa8eba1144393d8b74b\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from deepmultilingualpunctuation==1.0.1) (4.46.2)\n",
            "Requirement already satisfied: torch>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from deepmultilingualpunctuation==1.0.1) (2.5.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->deepmultilingualpunctuation==1.0.1) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->deepmultilingualpunctuation==1.0.1) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->deepmultilingualpunctuation==1.0.1) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->deepmultilingualpunctuation==1.0.1) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->deepmultilingualpunctuation==1.0.1) (2024.9.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->deepmultilingualpunctuation==1.0.1) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.8.1->deepmultilingualpunctuation==1.0.1) (1.3.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers->deepmultilingualpunctuation==1.0.1) (0.26.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers->deepmultilingualpunctuation==1.0.1) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers->deepmultilingualpunctuation==1.0.1) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers->deepmultilingualpunctuation==1.0.1) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->deepmultilingualpunctuation==1.0.1) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers->deepmultilingualpunctuation==1.0.1) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers->deepmultilingualpunctuation==1.0.1) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers->deepmultilingualpunctuation==1.0.1) (0.20.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers->deepmultilingualpunctuation==1.0.1) (4.66.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.1->deepmultilingualpunctuation==1.0.1) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->deepmultilingualpunctuation==1.0.1) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->deepmultilingualpunctuation==1.0.1) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->deepmultilingualpunctuation==1.0.1) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->deepmultilingualpunctuation==1.0.1) (2024.8.30)\n",
            "Collecting git+https://github.com/MahmoudAshraf97/ctc-forced-aligner.git\n",
            "  Cloning https://github.com/MahmoudAshraf97/ctc-forced-aligner.git to /tmp/pip-req-build-yyhalnao\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/MahmoudAshraf97/ctc-forced-aligner.git /tmp/pip-req-build-yyhalnao\n",
            "  Resolved https://github.com/MahmoudAshraf97/ctc-forced-aligner.git to commit c7cc7ce609e5f8f1f553fbd1e53124447ffe46d8\n",
            "  Running command git submodule update --init --recursive -q\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from ctc-forced-aligner==0.2) (3.9.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from ctc-forced-aligner==0.2) (2.5.0+cu121)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (from ctc-forced-aligner==0.2) (2.5.0+cu121)\n",
            "Requirement already satisfied: transformers>=4.34 in /usr/local/lib/python3.10/dist-packages (from ctc-forced-aligner==0.2) (4.46.2)\n",
            "Requirement already satisfied: Unidecode in /usr/local/lib/python3.10/dist-packages (from ctc-forced-aligner==0.2) (1.3.8)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers>=4.34->ctc-forced-aligner==0.2) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.34->ctc-forced-aligner==0.2) (0.26.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.34->ctc-forced-aligner==0.2) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.34->ctc-forced-aligner==0.2) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.34->ctc-forced-aligner==0.2) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.34->ctc-forced-aligner==0.2) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers>=4.34->ctc-forced-aligner==0.2) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.34->ctc-forced-aligner==0.2) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.34->ctc-forced-aligner==0.2) (0.20.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.34->ctc-forced-aligner==0.2) (4.66.6)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->ctc-forced-aligner==0.2) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->ctc-forced-aligner==0.2) (1.4.2)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->ctc-forced-aligner==0.2) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->ctc-forced-aligner==0.2) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->ctc-forced-aligner==0.2) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->ctc-forced-aligner==0.2) (2024.9.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->ctc-forced-aligner==0.2) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->ctc-forced-aligner==0.2) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->ctc-forced-aligner==0.2) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.34->ctc-forced-aligner==0.2) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.34->ctc-forced-aligner==0.2) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.34->ctc-forced-aligner==0.2) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.34->ctc-forced-aligner==0.2) (2024.8.30)\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/SYSTRAN/faster-whisper.git ctranslate2==4.4.0\n",
        "!pip install \"nemo-toolkit[asr]>=2.dev\"\n",
        "!pip install git+https://github.com/MahmoudAshraf97/demucs.git\n",
        "!pip install git+https://github.com/oliverguhr/deepmultilingualpunctuation.git\n",
        "!pip install git+https://github.com/MahmoudAshraf97/ctc-forced-aligner.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "YzhncHP0ytbQ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import wget\n",
        "from omegaconf import OmegaConf\n",
        "import json\n",
        "import shutil\n",
        "import torch\n",
        "import torchaudio\n",
        "from nemo.collections.asr.models.msdd_models import NeuralDiarizer\n",
        "from deepmultilingualpunctuation import PunctuationModel\n",
        "import re\n",
        "import logging\n",
        "import nltk\n",
        "import faster_whisper\n",
        "from ctc_forced_aligner import (\n",
        "    load_alignment_model,\n",
        "    generate_emissions,\n",
        "    preprocess_text,\n",
        "    get_alignments,\n",
        "    get_spans,\n",
        "    postprocess_results,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jbsUt3SwyhjD"
      },
      "source": [
        "# Helper Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Se6Hc7CZygxu"
      },
      "outputs": [],
      "source": [
        "punct_model_langs = [\n",
        "    \"en\",\n",
        "    \"fr\",\n",
        "    \"de\",\n",
        "    \"es\",\n",
        "    \"it\",\n",
        "    \"nl\",\n",
        "    \"pt\",\n",
        "    \"bg\",\n",
        "    \"pl\",\n",
        "    \"cs\",\n",
        "    \"sk\",\n",
        "    \"sl\",\n",
        "]\n",
        "\n",
        "LANGUAGES = {\n",
        "    \"en\": \"english\",\n",
        "    \"zh\": \"chinese\",\n",
        "    \"de\": \"german\",\n",
        "    \"es\": \"spanish\",\n",
        "    \"ru\": \"russian\",\n",
        "    \"ko\": \"korean\",\n",
        "    \"fr\": \"french\",\n",
        "    \"ja\": \"japanese\",\n",
        "    \"pt\": \"portuguese\",\n",
        "    \"tr\": \"turkish\",\n",
        "    \"pl\": \"polish\",\n",
        "    \"ca\": \"catalan\",\n",
        "    \"nl\": \"dutch\",\n",
        "    \"ar\": \"arabic\",\n",
        "    \"sv\": \"swedish\",\n",
        "    \"it\": \"italian\",\n",
        "    \"id\": \"indonesian\",\n",
        "    \"hi\": \"hindi\",\n",
        "    \"fi\": \"finnish\",\n",
        "    \"vi\": \"vietnamese\",\n",
        "    \"he\": \"hebrew\",\n",
        "    \"uk\": \"ukrainian\",\n",
        "    \"el\": \"greek\",\n",
        "    \"ms\": \"malay\",\n",
        "    \"cs\": \"czech\",\n",
        "    \"ro\": \"romanian\",\n",
        "    \"da\": \"danish\",\n",
        "    \"hu\": \"hungarian\",\n",
        "    \"ta\": \"tamil\",\n",
        "    \"no\": \"norwegian\",\n",
        "    \"th\": \"thai\",\n",
        "    \"ur\": \"urdu\",\n",
        "    \"hr\": \"croatian\",\n",
        "    \"bg\": \"bulgarian\",\n",
        "    \"lt\": \"lithuanian\",\n",
        "    \"la\": \"latin\",\n",
        "    \"mi\": \"maori\",\n",
        "    \"ml\": \"malayalam\",\n",
        "    \"cy\": \"welsh\",\n",
        "    \"sk\": \"slovak\",\n",
        "    \"te\": \"telugu\",\n",
        "    \"fa\": \"persian\",\n",
        "    \"lv\": \"latvian\",\n",
        "    \"bn\": \"bengali\",\n",
        "    \"sr\": \"serbian\",\n",
        "    \"az\": \"azerbaijani\",\n",
        "    \"sl\": \"slovenian\",\n",
        "    \"kn\": \"kannada\",\n",
        "    \"et\": \"estonian\",\n",
        "    \"mk\": \"macedonian\",\n",
        "    \"br\": \"breton\",\n",
        "    \"eu\": \"basque\",\n",
        "    \"is\": \"icelandic\",\n",
        "    \"hy\": \"armenian\",\n",
        "    \"ne\": \"nepali\",\n",
        "    \"mn\": \"mongolian\",\n",
        "    \"bs\": \"bosnian\",\n",
        "    \"kk\": \"kazakh\",\n",
        "    \"sq\": \"albanian\",\n",
        "    \"sw\": \"swahili\",\n",
        "    \"gl\": \"galician\",\n",
        "    \"mr\": \"marathi\",\n",
        "    \"pa\": \"punjabi\",\n",
        "    \"si\": \"sinhala\",\n",
        "    \"km\": \"khmer\",\n",
        "    \"sn\": \"shona\",\n",
        "    \"yo\": \"yoruba\",\n",
        "    \"so\": \"somali\",\n",
        "    \"af\": \"afrikaans\",\n",
        "    \"oc\": \"occitan\",\n",
        "    \"ka\": \"georgian\",\n",
        "    \"be\": \"belarusian\",\n",
        "    \"tg\": \"tajik\",\n",
        "    \"sd\": \"sindhi\",\n",
        "    \"gu\": \"gujarati\",\n",
        "    \"am\": \"amharic\",\n",
        "    \"yi\": \"yiddish\",\n",
        "    \"lo\": \"lao\",\n",
        "    \"uz\": \"uzbek\",\n",
        "    \"fo\": \"faroese\",\n",
        "    \"ht\": \"haitian creole\",\n",
        "    \"ps\": \"pashto\",\n",
        "    \"tk\": \"turkmen\",\n",
        "    \"nn\": \"nynorsk\",\n",
        "    \"mt\": \"maltese\",\n",
        "    \"sa\": \"sanskrit\",\n",
        "    \"lb\": \"luxembourgish\",\n",
        "    \"my\": \"myanmar\",\n",
        "    \"bo\": \"tibetan\",\n",
        "    \"tl\": \"tagalog\",\n",
        "    \"mg\": \"malagasy\",\n",
        "    \"as\": \"assamese\",\n",
        "    \"tt\": \"tatar\",\n",
        "    \"haw\": \"hawaiian\",\n",
        "    \"ln\": \"lingala\",\n",
        "    \"ha\": \"hausa\",\n",
        "    \"ba\": \"bashkir\",\n",
        "    \"jw\": \"javanese\",\n",
        "    \"su\": \"sundanese\",\n",
        "    \"yue\": \"cantonese\",\n",
        "}\n",
        "\n",
        "# language code lookup by name, with a few language aliases\n",
        "TO_LANGUAGE_CODE = {\n",
        "    **{language: code for code, language in LANGUAGES.items()},\n",
        "    \"burmese\": \"my\",\n",
        "    \"valencian\": \"ca\",\n",
        "    \"flemish\": \"nl\",\n",
        "    \"haitian\": \"ht\",\n",
        "    \"letzeburgesch\": \"lb\",\n",
        "    \"pushto\": \"ps\",\n",
        "    \"panjabi\": \"pa\",\n",
        "    \"moldavian\": \"ro\",\n",
        "    \"moldovan\": \"ro\",\n",
        "    \"sinhalese\": \"si\",\n",
        "    \"castilian\": \"es\",\n",
        "}\n",
        "\n",
        "\n",
        "langs_to_iso = {\n",
        "    \"af\": \"afr\",\n",
        "    \"am\": \"amh\",\n",
        "    \"ar\": \"ara\",\n",
        "    \"as\": \"asm\",\n",
        "    \"az\": \"aze\",\n",
        "    \"ba\": \"bak\",\n",
        "    \"be\": \"bel\",\n",
        "    \"bg\": \"bul\",\n",
        "    \"bn\": \"ben\",\n",
        "    \"bo\": \"tib\",\n",
        "    \"br\": \"bre\",\n",
        "    \"bs\": \"bos\",\n",
        "    \"ca\": \"cat\",\n",
        "    \"cs\": \"cze\",\n",
        "    \"cy\": \"wel\",\n",
        "    \"da\": \"dan\",\n",
        "    \"de\": \"ger\",\n",
        "    \"el\": \"gre\",\n",
        "    \"en\": \"eng\",\n",
        "    \"es\": \"spa\",\n",
        "    \"et\": \"est\",\n",
        "    \"eu\": \"baq\",\n",
        "    \"fa\": \"per\",\n",
        "    \"fi\": \"fin\",\n",
        "    \"fo\": \"fao\",\n",
        "    \"fr\": \"fre\",\n",
        "    \"gl\": \"glg\",\n",
        "    \"gu\": \"guj\",\n",
        "    \"ha\": \"hau\",\n",
        "    \"haw\": \"haw\",\n",
        "    \"he\": \"heb\",\n",
        "    \"hi\": \"hin\",\n",
        "    \"hr\": \"hrv\",\n",
        "    \"ht\": \"hat\",\n",
        "    \"hu\": \"hun\",\n",
        "    \"hy\": \"arm\",\n",
        "    \"id\": \"ind\",\n",
        "    \"is\": \"ice\",\n",
        "    \"it\": \"ita\",\n",
        "    \"ja\": \"jpn\",\n",
        "    \"jw\": \"jav\",\n",
        "    \"ka\": \"geo\",\n",
        "    \"kk\": \"kaz\",\n",
        "    \"km\": \"khm\",\n",
        "    \"kn\": \"kan\",\n",
        "    \"ko\": \"kor\",\n",
        "    \"la\": \"lat\",\n",
        "    \"lb\": \"ltz\",\n",
        "    \"ln\": \"lin\",\n",
        "    \"lo\": \"lao\",\n",
        "    \"lt\": \"lit\",\n",
        "    \"lv\": \"lav\",\n",
        "    \"mg\": \"mlg\",\n",
        "    \"mi\": \"mao\",\n",
        "    \"mk\": \"mac\",\n",
        "    \"ml\": \"mal\",\n",
        "    \"mn\": \"mon\",\n",
        "    \"mr\": \"mar\",\n",
        "    \"ms\": \"may\",\n",
        "    \"mt\": \"mlt\",\n",
        "    \"my\": \"bur\",\n",
        "    \"ne\": \"nep\",\n",
        "    \"nl\": \"dut\",\n",
        "    \"nn\": \"nno\",\n",
        "    \"no\": \"nor\",\n",
        "    \"oc\": \"oci\",\n",
        "    \"pa\": \"pan\",\n",
        "    \"pl\": \"pol\",\n",
        "    \"ps\": \"pus\",\n",
        "    \"pt\": \"por\",\n",
        "    \"ro\": \"rum\",\n",
        "    \"ru\": \"rus\",\n",
        "    \"sa\": \"san\",\n",
        "    \"sd\": \"snd\",\n",
        "    \"si\": \"sin\",\n",
        "    \"sk\": \"slo\",\n",
        "    \"sl\": \"slv\",\n",
        "    \"sn\": \"sna\",\n",
        "    \"so\": \"som\",\n",
        "    \"sq\": \"alb\",\n",
        "    \"sr\": \"srp\",\n",
        "    \"su\": \"sun\",\n",
        "    \"sv\": \"swe\",\n",
        "    \"sw\": \"swa\",\n",
        "    \"ta\": \"tam\",\n",
        "    \"te\": \"tel\",\n",
        "    \"tg\": \"tgk\",\n",
        "    \"th\": \"tha\",\n",
        "    \"tk\": \"tuk\",\n",
        "    \"tl\": \"tgl\",\n",
        "    \"tr\": \"tur\",\n",
        "    \"tt\": \"tat\",\n",
        "    \"uk\": \"ukr\",\n",
        "    \"ur\": \"urd\",\n",
        "    \"uz\": \"uzb\",\n",
        "    \"vi\": \"vie\",\n",
        "    \"yi\": \"yid\",\n",
        "    \"yo\": \"yor\",\n",
        "    \"yue\": \"yue\",\n",
        "    \"zh\": \"chi\",\n",
        "}\n",
        "\n",
        "\n",
        "whisper_langs = sorted(LANGUAGES.keys()) + sorted(\n",
        "    [k.title() for k in TO_LANGUAGE_CODE.keys()]\n",
        ")\n",
        "\n",
        "\n",
        "def create_config(output_dir):\n",
        "    DOMAIN_TYPE = \"telephonic\"  # Can be meeting, telephonic, or general based on domain type of the audio file\n",
        "    CONFIG_FILE_NAME = f\"diar_infer_{DOMAIN_TYPE}.yaml\"\n",
        "    CONFIG_URL = f\"https://raw.githubusercontent.com/NVIDIA/NeMo/main/examples/speaker_tasks/diarization/conf/inference/{CONFIG_FILE_NAME}\"\n",
        "    MODEL_CONFIG = os.path.join(output_dir, CONFIG_FILE_NAME)\n",
        "    if not os.path.exists(MODEL_CONFIG):\n",
        "        MODEL_CONFIG = wget.download(CONFIG_URL, output_dir)\n",
        "\n",
        "    config = OmegaConf.load(MODEL_CONFIG)\n",
        "\n",
        "    data_dir = os.path.join(output_dir, \"data\")\n",
        "    os.makedirs(data_dir, exist_ok=True)\n",
        "\n",
        "    meta = {\n",
        "        \"audio_filepath\": os.path.join(output_dir, \"mono_file.wav\"),\n",
        "        \"offset\": 0,\n",
        "        \"duration\": None,\n",
        "        \"label\": \"infer\",\n",
        "        \"text\": \"-\",\n",
        "        \"rttm_filepath\": None,\n",
        "        \"uem_filepath\": None,\n",
        "    }\n",
        "    with open(os.path.join(data_dir, \"input_manifest.json\"), \"w\") as fp:\n",
        "        json.dump(meta, fp)\n",
        "        fp.write(\"\\n\")\n",
        "\n",
        "    pretrained_vad = \"vad_multilingual_marblenet\"\n",
        "    pretrained_speaker_model = \"titanet_large\"\n",
        "    config.num_workers = 0  # Workaround for multiprocessing hanging with ipython issue\n",
        "    config.diarizer.manifest_filepath = os.path.join(data_dir, \"input_manifest.json\")\n",
        "    config.diarizer.out_dir = (\n",
        "        output_dir  # Directory to store intermediate files and prediction outputs\n",
        "    )\n",
        "\n",
        "    config.diarizer.speaker_embeddings.model_path = pretrained_speaker_model\n",
        "    config.diarizer.oracle_vad = (\n",
        "        False  # compute VAD provided with model_path to vad config\n",
        "    )\n",
        "    config.diarizer.clustering.parameters.oracle_num_speakers = False\n",
        "\n",
        "    # Here, we use our in-house pretrained NeMo VAD model\n",
        "    config.diarizer.vad.model_path = pretrained_vad\n",
        "    config.diarizer.vad.parameters.onset = 0.8\n",
        "    config.diarizer.vad.parameters.offset = 0.6\n",
        "    config.diarizer.vad.parameters.pad_offset = -0.05\n",
        "    config.diarizer.msdd_model.model_path = (\n",
        "        \"diar_msdd_telephonic\"  # Telephonic speaker diarization model\n",
        "    )\n",
        "\n",
        "    return config\n",
        "\n",
        "\n",
        "def get_word_ts_anchor(s, e, option=\"start\"):\n",
        "    if option == \"end\":\n",
        "        return e\n",
        "    elif option == \"mid\":\n",
        "        return (s + e) / 2\n",
        "    return s\n",
        "\n",
        "\n",
        "def get_words_speaker_mapping(wrd_ts, spk_ts, word_anchor_option=\"start\"):\n",
        "    s, e, sp = spk_ts[0]\n",
        "    wrd_pos, turn_idx = 0, 0\n",
        "    wrd_spk_mapping = []\n",
        "    for wrd_dict in wrd_ts:\n",
        "        ws, we, wrd = (\n",
        "            int(wrd_dict[\"start\"] * 1000),\n",
        "            int(wrd_dict[\"end\"] * 1000),\n",
        "            wrd_dict[\"text\"],\n",
        "        )\n",
        "        wrd_pos = get_word_ts_anchor(ws, we, word_anchor_option)\n",
        "        while wrd_pos > float(e):\n",
        "            turn_idx += 1\n",
        "            turn_idx = min(turn_idx, len(spk_ts) - 1)\n",
        "            s, e, sp = spk_ts[turn_idx]\n",
        "            if turn_idx == len(spk_ts) - 1:\n",
        "                e = get_word_ts_anchor(ws, we, option=\"end\")\n",
        "        wrd_spk_mapping.append(\n",
        "            {\"word\": wrd, \"start_time\": ws, \"end_time\": we, \"speaker\": sp}\n",
        "        )\n",
        "    return wrd_spk_mapping\n",
        "\n",
        "\n",
        "sentence_ending_punctuations = \".?!\"\n",
        "\n",
        "\n",
        "def get_first_word_idx_of_sentence(word_idx, word_list, speaker_list, max_words):\n",
        "    is_word_sentence_end = (\n",
        "        lambda x: x >= 0 and word_list[x][-1] in sentence_ending_punctuations\n",
        "    )\n",
        "    left_idx = word_idx\n",
        "    while (\n",
        "        left_idx > 0\n",
        "        and word_idx - left_idx < max_words\n",
        "        and speaker_list[left_idx - 1] == speaker_list[left_idx]\n",
        "        and not is_word_sentence_end(left_idx - 1)\n",
        "    ):\n",
        "        left_idx -= 1\n",
        "\n",
        "    return left_idx if left_idx == 0 or is_word_sentence_end(left_idx - 1) else -1\n",
        "\n",
        "\n",
        "def get_last_word_idx_of_sentence(word_idx, word_list, max_words):\n",
        "    is_word_sentence_end = (\n",
        "        lambda x: x >= 0 and word_list[x][-1] in sentence_ending_punctuations\n",
        "    )\n",
        "    right_idx = word_idx\n",
        "    while (\n",
        "        right_idx < len(word_list) - 1\n",
        "        and right_idx - word_idx < max_words\n",
        "        and not is_word_sentence_end(right_idx)\n",
        "    ):\n",
        "        right_idx += 1\n",
        "\n",
        "    return (\n",
        "        right_idx\n",
        "        if right_idx == len(word_list) - 1 or is_word_sentence_end(right_idx)\n",
        "        else -1\n",
        "    )\n",
        "\n",
        "\n",
        "def get_realigned_ws_mapping_with_punctuation(\n",
        "    word_speaker_mapping, max_words_in_sentence=50\n",
        "):\n",
        "    is_word_sentence_end = (\n",
        "        lambda x: x >= 0\n",
        "        and word_speaker_mapping[x][\"word\"][-1] in sentence_ending_punctuations\n",
        "    )\n",
        "    wsp_len = len(word_speaker_mapping)\n",
        "\n",
        "    words_list, speaker_list = [], []\n",
        "    for k, line_dict in enumerate(word_speaker_mapping):\n",
        "        word, speaker = line_dict[\"word\"], line_dict[\"speaker\"]\n",
        "        words_list.append(word)\n",
        "        speaker_list.append(speaker)\n",
        "\n",
        "    k = 0\n",
        "    while k < len(word_speaker_mapping):\n",
        "        line_dict = word_speaker_mapping[k]\n",
        "        if (\n",
        "            k < wsp_len - 1\n",
        "            and speaker_list[k] != speaker_list[k + 1]\n",
        "            and not is_word_sentence_end(k)\n",
        "        ):\n",
        "            left_idx = get_first_word_idx_of_sentence(\n",
        "                k, words_list, speaker_list, max_words_in_sentence\n",
        "            )\n",
        "            right_idx = (\n",
        "                get_last_word_idx_of_sentence(\n",
        "                    k, words_list, max_words_in_sentence - k + left_idx - 1\n",
        "                )\n",
        "                if left_idx > -1\n",
        "                else -1\n",
        "            )\n",
        "            if min(left_idx, right_idx) == -1:\n",
        "                k += 1\n",
        "                continue\n",
        "\n",
        "            spk_labels = speaker_list[left_idx : right_idx + 1]\n",
        "            mod_speaker = max(set(spk_labels), key=spk_labels.count)\n",
        "            if spk_labels.count(mod_speaker) < len(spk_labels) // 2:\n",
        "                k += 1\n",
        "                continue\n",
        "\n",
        "            speaker_list[left_idx : right_idx + 1] = [mod_speaker] * (\n",
        "                right_idx - left_idx + 1\n",
        "            )\n",
        "            k = right_idx\n",
        "\n",
        "        k += 1\n",
        "\n",
        "    k, realigned_list = 0, []\n",
        "    while k < len(word_speaker_mapping):\n",
        "        line_dict = word_speaker_mapping[k].copy()\n",
        "        line_dict[\"speaker\"] = speaker_list[k]\n",
        "        realigned_list.append(line_dict)\n",
        "        k += 1\n",
        "\n",
        "    return realigned_list\n",
        "\n",
        "\n",
        "def get_sentences_speaker_mapping(word_speaker_mapping, spk_ts):\n",
        "    sentence_checker = nltk.tokenize.PunktSentenceTokenizer().text_contains_sentbreak\n",
        "    s, e, spk = spk_ts[0]\n",
        "    prev_spk = spk\n",
        "\n",
        "    snts = []\n",
        "    snt = {\"speaker\": f\"Speaker {spk}\", \"start_time\": s, \"end_time\": e, \"text\": \"\"}\n",
        "\n",
        "    for wrd_dict in word_speaker_mapping:\n",
        "        wrd, spk = wrd_dict[\"word\"], wrd_dict[\"speaker\"]\n",
        "        s, e = wrd_dict[\"start_time\"], wrd_dict[\"end_time\"]\n",
        "        if spk != prev_spk or sentence_checker(snt[\"text\"] + \" \" + wrd):\n",
        "            snts.append(snt)\n",
        "            snt = {\n",
        "                \"speaker\": f\"Speaker {spk}\",\n",
        "                \"start_time\": s,\n",
        "                \"end_time\": e,\n",
        "                \"text\": \"\",\n",
        "            }\n",
        "        else:\n",
        "            snt[\"end_time\"] = e\n",
        "        snt[\"text\"] += wrd + \" \"\n",
        "        prev_spk = spk\n",
        "\n",
        "    snts.append(snt)\n",
        "    return snts\n",
        "\n",
        "\n",
        "def get_speaker_aware_transcript(sentences_speaker_mapping, f):\n",
        "    previous_speaker = sentences_speaker_mapping[0][\"speaker\"]\n",
        "    f.write(f\"{previous_speaker}: \")\n",
        "\n",
        "    for sentence_dict in sentences_speaker_mapping:\n",
        "        speaker = sentence_dict[\"speaker\"]\n",
        "        sentence = sentence_dict[\"text\"]\n",
        "\n",
        "        # If this speaker doesn't match the previous one, start a new paragraph\n",
        "        if speaker != previous_speaker:\n",
        "            f.write(f\"\\n\\n{speaker}: \")\n",
        "            previous_speaker = speaker\n",
        "\n",
        "        # No matter what, write the current sentence\n",
        "        f.write(sentence + \" \")\n",
        "\n",
        "\n",
        "def format_timestamp(\n",
        "    milliseconds: float, always_include_hours: bool = False, decimal_marker: str = \".\"\n",
        "):\n",
        "    assert milliseconds >= 0, \"non-negative timestamp expected\"\n",
        "\n",
        "    hours = milliseconds // 3_600_000\n",
        "    milliseconds -= hours * 3_600_000\n",
        "\n",
        "    minutes = milliseconds // 60_000\n",
        "    milliseconds -= minutes * 60_000\n",
        "\n",
        "    seconds = milliseconds // 1_000\n",
        "    milliseconds -= seconds * 1_000\n",
        "\n",
        "    hours_marker = f\"{hours:02d}:\" if always_include_hours or hours > 0 else \"\"\n",
        "    return (\n",
        "        f\"{hours_marker}{minutes:02d}:{seconds:02d}{decimal_marker}{milliseconds:03d}\"\n",
        "    )\n",
        "\n",
        "\n",
        "def write_srt(transcript, file):\n",
        "    \"\"\"\n",
        "    Write a transcript to a file in SRT format.\n",
        "\n",
        "    \"\"\"\n",
        "    for i, segment in enumerate(transcript, start=1):\n",
        "        # write srt lines\n",
        "        print(\n",
        "            f\"{i}\\n\"\n",
        "            f\"{format_timestamp(segment['start_time'], always_include_hours=True, decimal_marker=',')} --> \"\n",
        "            f\"{format_timestamp(segment['end_time'], always_include_hours=True, decimal_marker=',')}\\n\"\n",
        "            f\"{segment['speaker']}: {segment['text'].strip().replace('-->', '->')}\\n\",\n",
        "            file=file,\n",
        "            flush=True,\n",
        "        )\n",
        "\n",
        "\n",
        "def find_numeral_symbol_tokens(tokenizer):\n",
        "    numeral_symbol_tokens = [\n",
        "        -1,\n",
        "    ]\n",
        "    for token, token_id in tokenizer.get_vocab().items():\n",
        "        has_numeral_symbol = any(c in \"0123456789%$\" for c in token)\n",
        "        if has_numeral_symbol:\n",
        "            numeral_symbol_tokens.append(token_id)\n",
        "    return numeral_symbol_tokens\n",
        "\n",
        "\n",
        "def _get_next_start_timestamp(word_timestamps, current_word_index, final_timestamp):\n",
        "    # if current word is the last word\n",
        "    if current_word_index == len(word_timestamps) - 1:\n",
        "        return word_timestamps[current_word_index][\"start\"]\n",
        "\n",
        "    next_word_index = current_word_index + 1\n",
        "    while current_word_index < len(word_timestamps) - 1:\n",
        "        if word_timestamps[next_word_index].get(\"start\") is None:\n",
        "            # if next word doesn't have a start timestamp\n",
        "            # merge it with the current word and delete it\n",
        "            word_timestamps[current_word_index][\"word\"] += (\n",
        "                \" \" + word_timestamps[next_word_index][\"word\"]\n",
        "            )\n",
        "\n",
        "            word_timestamps[next_word_index][\"word\"] = None\n",
        "            next_word_index += 1\n",
        "            if next_word_index == len(word_timestamps):\n",
        "                return final_timestamp\n",
        "\n",
        "        else:\n",
        "            return word_timestamps[next_word_index][\"start\"]\n",
        "\n",
        "\n",
        "def filter_missing_timestamps(\n",
        "    word_timestamps, initial_timestamp=0, final_timestamp=None\n",
        "):\n",
        "    # handle the first and last word\n",
        "    if word_timestamps[0].get(\"start\") is None:\n",
        "        word_timestamps[0][\"start\"] = (\n",
        "            initial_timestamp if initial_timestamp is not None else 0\n",
        "        )\n",
        "        word_timestamps[0][\"end\"] = _get_next_start_timestamp(\n",
        "            word_timestamps, 0, final_timestamp\n",
        "        )\n",
        "\n",
        "    result = [\n",
        "        word_timestamps[0],\n",
        "    ]\n",
        "\n",
        "    for i, ws in enumerate(word_timestamps[1:], start=1):\n",
        "        # if ws doesn't have a start and end\n",
        "        # use the previous end as start and next start as end\n",
        "        if ws.get(\"start\") is None and ws.get(\"word\") is not None:\n",
        "            ws[\"start\"] = word_timestamps[i - 1][\"end\"]\n",
        "            ws[\"end\"] = _get_next_start_timestamp(word_timestamps, i, final_timestamp)\n",
        "\n",
        "        if ws[\"word\"] is not None:\n",
        "            result.append(ws)\n",
        "    return result\n",
        "\n",
        "\n",
        "def cleanup(path: str):\n",
        "    \"\"\"path could either be relative or absolute.\"\"\"\n",
        "    # check if file or directory exists\n",
        "    if os.path.isfile(path) or os.path.islink(path):\n",
        "        # remove file\n",
        "        os.remove(path)\n",
        "    elif os.path.isdir(path):\n",
        "        # remove directory and all its content\n",
        "        shutil.rmtree(path)\n",
        "    else:\n",
        "        raise ValueError(\"Path {} is not a file or dir.\".format(path))\n",
        "\n",
        "\n",
        "def process_language_arg(language: str, model_name: str):\n",
        "    \"\"\"\n",
        "    Process the language argument to make sure it's valid and convert language names to language codes.\n",
        "    \"\"\"\n",
        "    if language is not None:\n",
        "        language = language.lower()\n",
        "    if language not in LANGUAGES:\n",
        "        if language in TO_LANGUAGE_CODE:\n",
        "            language = TO_LANGUAGE_CODE[language]\n",
        "        else:\n",
        "            raise ValueError(f\"Unsupported language: {language}\")\n",
        "\n",
        "    if model_name.endswith(\".en\") and language != \"en\":\n",
        "        if language is not None:\n",
        "            logging.warning(\n",
        "                f\"{model_name} is an English-only model but received '{language}'; using English instead.\"\n",
        "            )\n",
        "        language = \"en\"\n",
        "    return language"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B7qWQb--1Xcw"
      },
      "source": [
        "# Options"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ONlFrSnD0FOp"
      },
      "outputs": [],
      "source": [
        "# Whether to enable music removal from speech, helps increase diarization quality but uses alot of ram\n",
        "enable_stemming = True\n",
        "\n",
        "# (choose from 'tiny.en', 'tiny', 'base.en', 'base', 'small.en', 'small', 'medium.en', 'medium', 'large-v1', 'large-v2', 'large-v3', 'large')\n",
        "whisper_model_name = \"large-v2\"\n",
        "\n",
        "# replaces numerical digits with their pronounciation, increases diarization accuracy\n",
        "suppress_numerals = True\n",
        "\n",
        "batch_size = 8\n",
        "\n",
        "language = None  # autodetect language\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h-cY1ZEy2KVI"
      },
      "source": [
        "# Processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ZS4xXmE2NGP"
      },
      "source": [
        "## Separating music from speech using Demucs\n",
        "\n",
        "---\n",
        "\n",
        "By isolating the vocals from the rest of the audio, it becomes easier to identify and track individual speakers based on the spectral and temporal characteristics of their speech signals. Source separation is just one of many techniques that can be used as a preprocessing step to help improve the accuracy and reliability of the overall diarization process."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HKcgQUrAzsJZ",
        "outputId": "4af26005-e4dd-4e33-9a38-d6c897dbf55f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "43"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "onlyfiles = [f for f in listdir('.') if isfile(f)]\n",
        "len(onlyfiles)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UYg9VWb22Tz8"
      },
      "source": [
        "## Transcriping audio using Whisper and realligning timestamps using Forced Alignment\n",
        "---\n",
        "This code uses two different open-source models to transcribe speech and perform forced alignment on the resulting transcription.\n",
        "\n",
        "The first model is called OpenAI Whisper, which is a speech recognition model that can transcribe speech with high accuracy. The code loads the whisper model and uses it to transcribe the vocal_target file.\n",
        "\n",
        "The output of the transcription process is a set of text segments with corresponding timestamps indicating when each segment was spoken.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5-VKFn530oTl",
        "outputId": "ab4ca7d5-4905-4b86-c1f5-f0bedac2e5a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "c01605c21d0e47319d8cca72738b4ae1",
            "53e7265c51a146379f3973e0309c86ce",
            "a48c9d954f37468aaa5f65a8ca035cc5",
            "23fc7546cfac4a47bc351157ed4cd5b2",
            "e1e863dde53e4924a56dff040d2a0545",
            "f764375831cf43ef906b0a023e1072ef",
            "d4d6b7cca5ad487c8fa4f16cdff5bf36",
            "db3507823b9844848a180e541c72c4c7",
            "1bba856ca6194b22b70ff6743f5d5160",
            "c3ae684207894b3887f31035626bfb41",
            "e5b11bd81814497d9c9d08f964844ece",
            "c22a6f46cf2b447b8af0f62dc018ffa3",
            "0cf90816b3914e6c84b60ca89ceebd7e",
            "2afee9437d444192b30fba33d7df4d0e",
            "a83f80e518f54e788be2e7874be8f62c",
            "23a46e48c4a4449abffebf2093e79ea0",
            "705bc884c0c041b6996e6006e5ef5683",
            "e2563276abc1432fae3734e16e05ab64",
            "16d1767b2ce4415f82eba1bafd4d07c4",
            "76dc9d5391a04deaa5e7173f2ac7f202",
            "3fcafca5bb174ba38ed5a1850cbb9c4f",
            "42001f5db63443ebaf8ea21e0180e357",
            "79b71953660646609485bcda7214a19a",
            "1c5196d424e6456bbc277bea895b5d4e",
            "ba7cefcd6ed1421eaa3ffa03216dc6fe",
            "ec915f7d20c54dc2a1721ceaae9ebcf9",
            "ff0ba2ff78c847b289ef97120ba9aade",
            "8e176c6703f04677bdd369b17a3ed40f",
            "199037df7c824e50b0861e9d1d267427",
            "0ab1429dc8c4449791cf50fa4e115c5b",
            "41590a89e41c43a69cfbe64bd8e4c45d",
            "f647c5a7472346fea405d24dde2f553b",
            "f05c27bfa741438f8fadd17a5260f6bb",
            "f8b13cdea202473a97928d008332771d",
            "dc230e277b614195b22efbf363755cdd",
            "3f1615c626064219b6db7b2cd357f713",
            "4da3983480244eb89105cf7be2b9b854",
            "9d515a50029042a3b48d75c635100bd1",
            "773b7cd5e2534f67ab3ed840ec0355c0",
            "4df3e6e6cd4b47d88717bcc2e03f506a",
            "3d4ea0c0c68c421e876de354c7b82cf3",
            "73c4f19c40794dafba009119ce485ea6",
            "3a0c96c89a4345c4b9e7ed432b8ff8c7",
            "bd7a11f3535b4455bb3b0a280cc87b9f",
            "b1fc50be6c3b40c4bd4b5e8df6bd6ede",
            "32df6a61cd44478c8cacef20c06d6360",
            "d763f50447434f2b873fcfd73c2f5547",
            "174da3b8b94b477d8775a9e72d5fcc0b",
            "ef01100af2a34e61bae9d2664d572ef1",
            "15ece113dba74581b62ecd7285fc0721",
            "85b9a91bbf9745f58a04e6e4dfd2e403",
            "9eb527d7c0024f58aec3a0d77c836084",
            "dd722ac483d241e0a0e50e886e739f03",
            "4c7ec88627ac4561b181effa3a28dedd",
            "c02eb4c6cb1a40abaefa554b7e2374bc",
            "1ea3e8f9b8034860b12bb921628d7246",
            "2da5cb10605d4a8cb0caa41403505b97",
            "a9121b0fdddf489da8dcc48d510f1795",
            "0ce95ae460664cfb8125bb54b0cbe5f7",
            "75258c54351642cda949fb3ba49a153c",
            "894c4e1cbdea441f8e53deb9c32f16d7",
            "ab26f6828c4e4a5ea734c311668f91c2",
            "8efdbd73a76c4203a17737b357eb7995",
            "929b0993b47a4066bb211dc3d453c90f",
            "ecdf1d0ec7cb4a0f87866dec32fe335c",
            "ab2a58e7a44a4669892a71084dc53706",
            "d78903f68adf4f9d9fba031c168217c1",
            "64161521d69a495ba066855c2749bbcd",
            "2fa83df0a9194f13bc4989ef15e0e726",
            "22b33a5afdfd4282ba6d8d7910a0e74f",
            "d030eca7d22448818e63e488fda7e2e1",
            "8f16b93b2108483096e9189576b79d19",
            "93bb87ca8dae44569e3f7c8f79c4c99a",
            "a0fc4c16f0ff406ea27e292dfd0e2a29",
            "50783815a7994fe485462bf3495add5a",
            "e6ae77b9d83644e6a296a8872b7505d3",
            "2d9ec28ec588404197736b159465c787",
            "fd4fbee16ebb4ba4aa7d4bd1c41db824",
            "3f97be094182405ca671d5dde629eeb0",
            "b50a448d4a484e40a41115050a99dd93",
            "b39584fa09964a1a99e5b4b62656f3c9",
            "e749d1a6e2774079a376a86cd42f1812",
            "289921a0df0e4cc2b819e3683cdd0e06",
            "db4aa6d29c4f40edbef48226a874300f",
            "d26c9e28aed14216b8c0bcc6558b2799",
            "1165d84159a9427b9fc4482004e2b0cb",
            "7f99aa512e484a96a27b0623e15dc959",
            "be11badf142f4c3082effe8c1ef18246",
            "b342a1fc3362490b8cf61207fb4a22c9",
            "5f9d82e19c6b4ce485d97833d7bea61a",
            "d50689ebff53459db173299f71433198",
            "fecba4998bf3499c83e9e61527f55802",
            "d3ff2b5046b342ed8dde8eeb790e11ca",
            "5747c85621fe4ea091ea70969ff19be0",
            "af3c7d71c6fd42ab9c90cd1734e2524f",
            "f6bdefa4997c4c6ebc0e2f95b8be90ef",
            "d0edf36ff9184a9aa03c83c2640af3e1",
            "a20298c46e1e49bc814ab5ddd18bb3e2",
            "fc99ee7a55d64cc4ac6e23d317f833ad"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/2.20M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c01605c21d0e47319d8cca72738b4ae1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.bin:   0%|          | 0.00/3.09G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c22a6f46cf2b447b8af0f62dc018ffa3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocabulary.txt:   0%|          | 0.00/460k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "79b71953660646609485bcda7214a19a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/2.80k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f8b13cdea202473a97928d008332771d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/2.08k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b1fc50be6c3b40c4bd4b5e8df6bd6ede"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/1.26G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1ea3e8f9b8034860b12bb921628d7246"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/1.05k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d78903f68adf4f9d9fba031c168217c1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/286 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fd4fbee16ebb4ba4aa7d4bd1c41db824"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/74.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b342a1fc3362490b8cf61207fb4a22c9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:00:15 msdd_models:1097] Loading pretrained diar_msdd_telephonic model from NGC\n",
            "[NeMo I 2024-11-13 13:00:15 cloud:68] Downloading from: https://api.ngc.nvidia.com/v2/models/nvidia/nemo/diar_msdd_telephonic/versions/1.0.1/files/diar_msdd_telephonic.nemo to /root/.cache/torch/NeMo/NeMo_2.0.0rc1/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo\n",
            "[NeMo I 2024-11-13 13:00:16 common:826] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-11-13 13:00:18 modelPT:176] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: true\n",
            "    \n",
            "[NeMo W 2024-11-13 13:00:18 modelPT:183] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    \n",
            "[NeMo W 2024-11-13 13:00:18 modelPT:189] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    seq_eval_mode: false\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:00:18 features:305] PADDING: 16\n",
            "[NeMo I 2024-11-13 13:00:18 features:305] PADDING: 16\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-11-13 13:00:19 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/core/connectors/save_restore_connector.py:617: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "      return torch.load(model_weights, map_location='cpu')\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:00:19 save_restore_connector:272] Model EncDecDiarLabelModel was successfully restored from /root/.cache/torch/NeMo/NeMo_2.0.0rc1/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
            "[NeMo I 2024-11-13 13:00:19 features:305] PADDING: 16\n",
            "[NeMo I 2024-11-13 13:00:19 clustering_diarizer:127] Loading pretrained vad_multilingual_marblenet model from NGC\n",
            "[NeMo I 2024-11-13 13:00:20 cloud:68] Downloading from: https://api.ngc.nvidia.com/v2/models/nvidia/nemo/vad_multilingual_marblenet/versions/1.10.0/files/vad_multilingual_marblenet.nemo to /root/.cache/torch/NeMo/NeMo_2.0.0rc1/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo\n",
            "[NeMo I 2024-11-13 13:00:20 common:826] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-11-13 13:00:20 modelPT:176] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: /manifests/ami_train_0.63.json,/manifests/freesound_background_train.json,/manifests/freesound_laughter_train.json,/manifests/fisher_2004_background.json,/manifests/fisher_2004_speech_sampled.json,/manifests/google_train_manifest.json,/manifests/icsi_all_0.63.json,/manifests/musan_freesound_train.json,/manifests/musan_music_train.json,/manifests/musan_soundbible_train.json,/manifests/mandarin_train_sample.json,/manifests/german_train_sample.json,/manifests/spanish_train_sample.json,/manifests/french_train_sample.json,/manifests/russian_train_sample.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: true\n",
            "    is_tarred: false\n",
            "    tarred_audio_filepaths: null\n",
            "    tarred_shard_strategy: scatter\n",
            "    augmentor:\n",
            "      shift:\n",
            "        prob: 0.5\n",
            "        min_shift_ms: -10.0\n",
            "        max_shift_ms: 10.0\n",
            "      white_noise:\n",
            "        prob: 0.5\n",
            "        min_level: -90\n",
            "        max_level: -46\n",
            "        norm: true\n",
            "      noise:\n",
            "        prob: 0.5\n",
            "        manifest_path: /manifests/noise_0_1_musan_fs.json\n",
            "        min_snr_db: 0\n",
            "        max_snr_db: 30\n",
            "        max_gain_db: 300.0\n",
            "        norm: true\n",
            "      gain:\n",
            "        prob: 0.5\n",
            "        min_gain_dbfs: -10.0\n",
            "        max_gain_dbfs: 10.0\n",
            "        norm: true\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2024-11-13 13:00:20 modelPT:183] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: /manifests/ami_dev_0.63.json,/manifests/freesound_background_dev.json,/manifests/freesound_laughter_dev.json,/manifests/ch120_moved_0.63.json,/manifests/fisher_2005_500_speech_sampled.json,/manifests/google_dev_manifest.json,/manifests/musan_music_dev.json,/manifests/mandarin_dev.json,/manifests/german_dev.json,/manifests/spanish_dev.json,/manifests/french_dev.json,/manifests/russian_dev.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: false\n",
            "    val_loss_idx: 0\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2024-11-13 13:00:20 modelPT:189] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 128\n",
            "    shuffle: false\n",
            "    test_loss_idx: 0\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:00:20 features:305] PADDING: 16\n",
            "[NeMo I 2024-11-13 13:00:20 save_restore_connector:272] Model EncDecClassificationModel was successfully restored from /root/.cache/torch/NeMo/NeMo_2.0.0rc1/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
            "[NeMo I 2024-11-13 13:00:20 msdd_models:870] Multiscale Weights: [1, 1, 1, 1, 1]\n",
            "[NeMo I 2024-11-13 13:00:20 msdd_models:871] Clustering Parameters: {\n",
            "        \"oracle_num_speakers\": false,\n",
            "        \"max_num_speakers\": 8,\n",
            "        \"enhanced_count_thres\": 80,\n",
            "        \"max_rp_threshold\": 0.25,\n",
            "        \"sparse_search_volume\": 30,\n",
            "        \"maj_vote_spk_count\": false,\n",
            "        \"chunk_cluster_count\": 50,\n",
            "        \"embeddings_per_chunk\": 10000\n",
            "    }\n",
            "[NeMo I 2024-11-13 13:00:20 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2024-11-13 13:00:20 clustering_diarizer:313] Split long audio file to avoid CUDA memory issue\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "splitting manifest: 100%|| 1/1 [00:11<00:00, 11.41s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:00:32 classification_models:293] Perform streaming frame-level VAD\n",
            "[NeMo I 2024-11-13 13:00:32 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-11-13 13:00:32 collections:741] Dataset successfully loaded with 25 items and total duration provided from manifest is  0.34 hours.\n",
            "[NeMo I 2024-11-13 13:00:32 collections:746] # 25 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "vad:   0%|          | 0/25 [00:00<?, ?it/s][NeMo W 2024-11-13 13:00:32 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/collections/asr/models/clustering_diarizer.py:226: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "      with autocast():\n",
            "    \n",
            "[NeMo W 2024-11-13 13:00:32 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/collections/asr/parts/preprocessing/features.py:436: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "      with torch.cuda.amp.autocast(enabled=False):\n",
            "    \n",
            "vad: 100%|| 25/25 [00:07<00:00,  3.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:00:39 clustering_diarizer:254] Generating predictions with overlapping input segments\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "                                                               "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:00:53 clustering_diarizer:266] Converting frame level prediction to speech/no-speech segment in start and end times format.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "creating speech segments: 100%|| 1/1 [00:02<00:00,  2.04s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:00:56 clustering_diarizer:291] Subsegmentation for embedding extraction: scale0, /content/temp_outputs/speaker_outputs/subsegments_scale0.json\n",
            "[NeMo I 2024-11-13 13:00:56 clustering_diarizer:347] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-11-13 13:00:56 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-11-13 13:00:56 collections:741] Dataset successfully loaded with 863 items and total duration provided from manifest is  0.13 hours.\n",
            "[NeMo I 2024-11-13 13:00:56 collections:746] # 863 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[1/5] extract embeddings:   0%|          | 0/14 [00:00<?, ?it/s][NeMo W 2024-11-13 13:00:56 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/collections/asr/models/clustering_diarizer.py:362: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "      with autocast():\n",
            "    \n",
            "[NeMo W 2024-11-13 13:00:56 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/collections/asr/parts/submodules/jasper.py:476: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "      with torch.cuda.amp.autocast(enabled=False):\n",
            "    \n",
            "[1/5] extract embeddings: 100%|| 14/14 [00:01<00:00,  9.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:00:57 clustering_diarizer:393] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-11-13 13:00:57 clustering_diarizer:291] Subsegmentation for embedding extraction: scale1, /content/temp_outputs/speaker_outputs/subsegments_scale1.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:00:57 clustering_diarizer:347] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-11-13 13:00:57 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-11-13 13:00:57 collections:741] Dataset successfully loaded with 921 items and total duration provided from manifest is  0.14 hours.\n",
            "[NeMo I 2024-11-13 13:00:57 collections:746] # 921 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[2/5] extract embeddings: 100%|| 15/15 [00:01<00:00, 13.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:00:58 clustering_diarizer:393] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-11-13 13:00:58 clustering_diarizer:291] Subsegmentation for embedding extraction: scale2, /content/temp_outputs/speaker_outputs/subsegments_scale2.json\n",
            "[NeMo I 2024-11-13 13:00:58 clustering_diarizer:347] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-11-13 13:00:58 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-11-13 13:00:58 collections:741] Dataset successfully loaded with 994 items and total duration provided from manifest is  0.14 hours.\n",
            "[NeMo I 2024-11-13 13:00:58 collections:746] # 994 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[3/5] extract embeddings: 100%|| 16/16 [00:01<00:00, 13.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:01:00 clustering_diarizer:393] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-11-13 13:01:00 clustering_diarizer:291] Subsegmentation for embedding extraction: scale3, /content/temp_outputs/speaker_outputs/subsegments_scale3.json\n",
            "[NeMo I 2024-11-13 13:01:00 clustering_diarizer:347] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-11-13 13:01:00 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-11-13 13:01:00 collections:741] Dataset successfully loaded with 1168 items and total duration provided from manifest is  0.16 hours.\n",
            "[NeMo I 2024-11-13 13:01:00 collections:746] # 1168 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[4/5] extract embeddings: 100%|| 19/19 [00:01<00:00, 15.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:01:01 clustering_diarizer:393] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-11-13 13:01:01 clustering_diarizer:291] Subsegmentation for embedding extraction: scale4, /content/temp_outputs/speaker_outputs/subsegments_scale4.json\n",
            "[NeMo I 2024-11-13 13:01:01 clustering_diarizer:347] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-11-13 13:01:01 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-11-13 13:01:01 collections:741] Dataset successfully loaded with 1586 items and total duration provided from manifest is  0.17 hours.\n",
            "[NeMo I 2024-11-13 13:01:01 collections:746] # 1586 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[5/5] extract embeddings: 100%|| 25/25 [00:01<00:00, 15.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:01:03 clustering_diarizer:393] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "clustering: 100%|| 1/1 [00:01<00:00,  1.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:01:04 clustering_diarizer:461] Outputs are saved in /content/temp_outputs directory\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[NeMo W 2024-11-13 13:01:04 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:01:04 msdd_models:966] Loading embedding pickle file of scale:0 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale0_embeddings.pkl\n",
            "[NeMo I 2024-11-13 13:01:04 msdd_models:966] Loading embedding pickle file of scale:1 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale1_embeddings.pkl\n",
            "[NeMo I 2024-11-13 13:01:04 msdd_models:966] Loading embedding pickle file of scale:2 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale2_embeddings.pkl\n",
            "[NeMo I 2024-11-13 13:01:04 msdd_models:966] Loading embedding pickle file of scale:3 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale3_embeddings.pkl\n",
            "[NeMo I 2024-11-13 13:01:04 msdd_models:966] Loading embedding pickle file of scale:4 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale4_embeddings.pkl\n",
            "[NeMo I 2024-11-13 13:01:04 msdd_models:944] Loading cluster label file from /content/temp_outputs/speaker_outputs/subsegments_scale4_cluster.label\n",
            "[NeMo I 2024-11-13 13:01:05 collections:1067] Filtered duration for loading collection is 0.000000.\n",
            "[NeMo I 2024-11-13 13:01:05 collections:1071] Total 1 session files loaded accounting to # 1 audio clips\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/1 [00:00<?, ?it/s][NeMo W 2024-11-13 13:01:05 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/collections/asr/models/msdd_models.py:1333: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "      with autocast():\n",
            "    \n",
            "100%|| 1/1 [00:00<00:00,  7.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:01:05 msdd_models:1407]      [Threshold: 0.7000] [use_clus_as_main=False] [diar_window=50]\n",
            "[NeMo I 2024-11-13 13:01:05 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2024-11-13 13:01:05 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[NeMo W 2024-11-13 13:01:05 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:01:05 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-11-13 13:01:05 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:01:05 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-11-13 13:01:05 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:01:05 msdd_models:1435]   \n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Punctuation restoration is not available for ru language. Using the original punctuation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:04:10 msdd_models:1097] Loading pretrained diar_msdd_telephonic model from NGC\n",
            "[NeMo I 2024-11-13 13:04:10 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_2.0.0rc1/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
            "[NeMo I 2024-11-13 13:04:10 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_2.0.0rc1/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo\n",
            "[NeMo I 2024-11-13 13:04:10 common:826] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-11-13 13:04:12 modelPT:176] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: true\n",
            "    \n",
            "[NeMo W 2024-11-13 13:04:12 modelPT:183] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    \n",
            "[NeMo W 2024-11-13 13:04:12 modelPT:189] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    seq_eval_mode: false\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:04:12 features:305] PADDING: 16\n",
            "[NeMo I 2024-11-13 13:04:13 features:305] PADDING: 16\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-11-13 13:04:13 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/core/connectors/save_restore_connector.py:617: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "      return torch.load(model_weights, map_location='cpu')\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:04:13 save_restore_connector:272] Model EncDecDiarLabelModel was successfully restored from /root/.cache/torch/NeMo/NeMo_2.0.0rc1/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
            "[NeMo I 2024-11-13 13:04:13 features:305] PADDING: 16\n",
            "[NeMo I 2024-11-13 13:04:14 clustering_diarizer:127] Loading pretrained vad_multilingual_marblenet model from NGC\n",
            "[NeMo I 2024-11-13 13:04:14 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_2.0.0rc1/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
            "[NeMo I 2024-11-13 13:04:14 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_2.0.0rc1/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo\n",
            "[NeMo I 2024-11-13 13:04:14 common:826] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-11-13 13:04:14 modelPT:176] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: /manifests/ami_train_0.63.json,/manifests/freesound_background_train.json,/manifests/freesound_laughter_train.json,/manifests/fisher_2004_background.json,/manifests/fisher_2004_speech_sampled.json,/manifests/google_train_manifest.json,/manifests/icsi_all_0.63.json,/manifests/musan_freesound_train.json,/manifests/musan_music_train.json,/manifests/musan_soundbible_train.json,/manifests/mandarin_train_sample.json,/manifests/german_train_sample.json,/manifests/spanish_train_sample.json,/manifests/french_train_sample.json,/manifests/russian_train_sample.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: true\n",
            "    is_tarred: false\n",
            "    tarred_audio_filepaths: null\n",
            "    tarred_shard_strategy: scatter\n",
            "    augmentor:\n",
            "      shift:\n",
            "        prob: 0.5\n",
            "        min_shift_ms: -10.0\n",
            "        max_shift_ms: 10.0\n",
            "      white_noise:\n",
            "        prob: 0.5\n",
            "        min_level: -90\n",
            "        max_level: -46\n",
            "        norm: true\n",
            "      noise:\n",
            "        prob: 0.5\n",
            "        manifest_path: /manifests/noise_0_1_musan_fs.json\n",
            "        min_snr_db: 0\n",
            "        max_snr_db: 30\n",
            "        max_gain_db: 300.0\n",
            "        norm: true\n",
            "      gain:\n",
            "        prob: 0.5\n",
            "        min_gain_dbfs: -10.0\n",
            "        max_gain_dbfs: 10.0\n",
            "        norm: true\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2024-11-13 13:04:14 modelPT:183] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: /manifests/ami_dev_0.63.json,/manifests/freesound_background_dev.json,/manifests/freesound_laughter_dev.json,/manifests/ch120_moved_0.63.json,/manifests/fisher_2005_500_speech_sampled.json,/manifests/google_dev_manifest.json,/manifests/musan_music_dev.json,/manifests/mandarin_dev.json,/manifests/german_dev.json,/manifests/spanish_dev.json,/manifests/french_dev.json,/manifests/russian_dev.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: false\n",
            "    val_loss_idx: 0\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2024-11-13 13:04:14 modelPT:189] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 128\n",
            "    shuffle: false\n",
            "    test_loss_idx: 0\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:04:14 features:305] PADDING: 16\n",
            "[NeMo I 2024-11-13 13:04:14 save_restore_connector:272] Model EncDecClassificationModel was successfully restored from /root/.cache/torch/NeMo/NeMo_2.0.0rc1/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
            "[NeMo I 2024-11-13 13:04:14 msdd_models:870] Multiscale Weights: [1, 1, 1, 1, 1]\n",
            "[NeMo I 2024-11-13 13:04:14 msdd_models:871] Clustering Parameters: {\n",
            "        \"oracle_num_speakers\": false,\n",
            "        \"max_num_speakers\": 8,\n",
            "        \"enhanced_count_thres\": 80,\n",
            "        \"max_rp_threshold\": 0.25,\n",
            "        \"sparse_search_volume\": 30,\n",
            "        \"maj_vote_spk_count\": false,\n",
            "        \"chunk_cluster_count\": 50,\n",
            "        \"embeddings_per_chunk\": 10000\n",
            "    }\n",
            "[NeMo I 2024-11-13 13:04:14 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2024-11-13 13:04:14 clustering_diarizer:313] Split long audio file to avoid CUDA memory issue\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "splitting manifest: 100%|| 1/1 [00:00<00:00, 10.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:04:14 classification_models:293] Perform streaming frame-level VAD\n",
            "[NeMo I 2024-11-13 13:04:14 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-11-13 13:04:14 collections:741] Dataset successfully loaded with 23 items and total duration provided from manifest is  0.32 hours.\n",
            "[NeMo I 2024-11-13 13:04:14 collections:746] # 23 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "vad:   0%|          | 0/23 [00:00<?, ?it/s][NeMo W 2024-11-13 13:04:14 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/collections/asr/models/clustering_diarizer.py:226: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "      with autocast():\n",
            "    \n",
            "[NeMo W 2024-11-13 13:04:14 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/collections/asr/parts/preprocessing/features.py:436: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "      with torch.cuda.amp.autocast(enabled=False):\n",
            "    \n",
            "vad: 100%|| 23/23 [00:04<00:00,  5.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:04:18 clustering_diarizer:254] Generating predictions with overlapping input segments\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "                                                               "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:04:29 clustering_diarizer:266] Converting frame level prediction to speech/no-speech segment in start and end times format.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "creating speech segments: 100%|| 1/1 [00:00<00:00,  1.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:04:30 clustering_diarizer:291] Subsegmentation for embedding extraction: scale0, /content/temp_outputs/speaker_outputs/subsegments_scale0.json\n",
            "[NeMo I 2024-11-13 13:04:30 clustering_diarizer:347] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-11-13 13:04:30 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-11-13 13:04:30 collections:741] Dataset successfully loaded with 807 items and total duration provided from manifest is  0.09 hours.\n",
            "[NeMo I 2024-11-13 13:04:30 collections:746] # 807 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[1/5] extract embeddings:   0%|          | 0/13 [00:00<?, ?it/s][NeMo W 2024-11-13 13:04:30 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/collections/asr/models/clustering_diarizer.py:362: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "      with autocast():\n",
            "    \n",
            "[NeMo W 2024-11-13 13:04:30 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/collections/asr/parts/submodules/jasper.py:476: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "      with torch.cuda.amp.autocast(enabled=False):\n",
            "    \n",
            "[1/5] extract embeddings: 100%|| 13/13 [00:01<00:00, 10.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:04:31 clustering_diarizer:393] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-11-13 13:04:31 clustering_diarizer:291] Subsegmentation for embedding extraction: scale1, /content/temp_outputs/speaker_outputs/subsegments_scale1.json\n",
            "[NeMo I 2024-11-13 13:04:31 clustering_diarizer:347] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-11-13 13:04:31 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-11-13 13:04:31 collections:741] Dataset successfully loaded with 830 items and total duration provided from manifest is  0.10 hours.\n",
            "[NeMo I 2024-11-13 13:04:31 collections:746] # 830 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[2/5] extract embeddings: 100%|| 13/13 [00:01<00:00, 12.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:04:33 clustering_diarizer:393] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-11-13 13:04:33 clustering_diarizer:291] Subsegmentation for embedding extraction: scale2, /content/temp_outputs/speaker_outputs/subsegments_scale2.json\n",
            "[NeMo I 2024-11-13 13:04:33 clustering_diarizer:347] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-11-13 13:04:33 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-11-13 13:04:33 collections:741] Dataset successfully loaded with 866 items and total duration provided from manifest is  0.10 hours.\n",
            "[NeMo I 2024-11-13 13:04:33 collections:746] # 866 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[3/5] extract embeddings: 100%|| 14/14 [00:01<00:00, 13.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:04:34 clustering_diarizer:393] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-11-13 13:04:34 clustering_diarizer:291] Subsegmentation for embedding extraction: scale3, /content/temp_outputs/speaker_outputs/subsegments_scale3.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:04:34 clustering_diarizer:347] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-11-13 13:04:34 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-11-13 13:04:34 collections:741] Dataset successfully loaded with 959 items and total duration provided from manifest is  0.11 hours.\n",
            "[NeMo I 2024-11-13 13:04:34 collections:746] # 959 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[4/5] extract embeddings: 100%|| 15/15 [00:00<00:00, 16.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:04:35 clustering_diarizer:393] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-11-13 13:04:35 clustering_diarizer:291] Subsegmentation for embedding extraction: scale4, /content/temp_outputs/speaker_outputs/subsegments_scale4.json\n",
            "[NeMo I 2024-11-13 13:04:35 clustering_diarizer:347] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-11-13 13:04:35 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-11-13 13:04:35 collections:741] Dataset successfully loaded with 1216 items and total duration provided from manifest is  0.12 hours.\n",
            "[NeMo I 2024-11-13 13:04:35 collections:746] # 1216 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[5/5] extract embeddings: 100%|| 19/19 [00:01<00:00, 15.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:04:36 clustering_diarizer:393] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "clustering: 100%|| 1/1 [00:00<00:00,  1.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:04:37 clustering_diarizer:461] Outputs are saved in /content/temp_outputs directory\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[NeMo W 2024-11-13 13:04:37 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:04:38 msdd_models:966] Loading embedding pickle file of scale:0 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale0_embeddings.pkl\n",
            "[NeMo I 2024-11-13 13:04:38 msdd_models:966] Loading embedding pickle file of scale:1 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale1_embeddings.pkl\n",
            "[NeMo I 2024-11-13 13:04:38 msdd_models:966] Loading embedding pickle file of scale:2 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale2_embeddings.pkl\n",
            "[NeMo I 2024-11-13 13:04:38 msdd_models:966] Loading embedding pickle file of scale:3 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale3_embeddings.pkl\n",
            "[NeMo I 2024-11-13 13:04:38 msdd_models:966] Loading embedding pickle file of scale:4 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale4_embeddings.pkl\n",
            "[NeMo I 2024-11-13 13:04:38 msdd_models:944] Loading cluster label file from /content/temp_outputs/speaker_outputs/subsegments_scale4_cluster.label\n",
            "[NeMo I 2024-11-13 13:04:38 collections:1067] Filtered duration for loading collection is 0.000000.\n",
            "[NeMo I 2024-11-13 13:04:38 collections:1071] Total 1 session files loaded accounting to # 1 audio clips\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/1 [00:00<?, ?it/s][NeMo W 2024-11-13 13:04:39 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/collections/asr/models/msdd_models.py:1333: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "      with autocast():\n",
            "    \n",
            "100%|| 1/1 [00:00<00:00,  1.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:04:39 msdd_models:1407]      [Threshold: 0.7000] [use_clus_as_main=False] [diar_window=50]\n",
            "[NeMo I 2024-11-13 13:04:39 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2024-11-13 13:04:39 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[NeMo W 2024-11-13 13:04:39 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:04:39 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-11-13 13:04:39 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:04:39 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-11-13 13:04:39 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:04:39 msdd_models:1435]   \n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Punctuation restoration is not available for ru language. Using the original punctuation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:06:26 msdd_models:1097] Loading pretrained diar_msdd_telephonic model from NGC\n",
            "[NeMo I 2024-11-13 13:06:26 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_2.0.0rc1/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
            "[NeMo I 2024-11-13 13:06:26 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_2.0.0rc1/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo\n",
            "[NeMo I 2024-11-13 13:06:26 common:826] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-11-13 13:06:29 modelPT:176] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: true\n",
            "    \n",
            "[NeMo W 2024-11-13 13:06:29 modelPT:183] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    \n",
            "[NeMo W 2024-11-13 13:06:29 modelPT:189] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    seq_eval_mode: false\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:06:29 features:305] PADDING: 16\n",
            "[NeMo I 2024-11-13 13:06:29 features:305] PADDING: 16\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-11-13 13:06:29 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/core/connectors/save_restore_connector.py:617: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "      return torch.load(model_weights, map_location='cpu')\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:06:29 save_restore_connector:272] Model EncDecDiarLabelModel was successfully restored from /root/.cache/torch/NeMo/NeMo_2.0.0rc1/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
            "[NeMo I 2024-11-13 13:06:29 features:305] PADDING: 16\n",
            "[NeMo I 2024-11-13 13:06:30 clustering_diarizer:127] Loading pretrained vad_multilingual_marblenet model from NGC\n",
            "[NeMo I 2024-11-13 13:06:30 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_2.0.0rc1/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
            "[NeMo I 2024-11-13 13:06:30 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_2.0.0rc1/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo\n",
            "[NeMo I 2024-11-13 13:06:30 common:826] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-11-13 13:06:30 modelPT:176] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: /manifests/ami_train_0.63.json,/manifests/freesound_background_train.json,/manifests/freesound_laughter_train.json,/manifests/fisher_2004_background.json,/manifests/fisher_2004_speech_sampled.json,/manifests/google_train_manifest.json,/manifests/icsi_all_0.63.json,/manifests/musan_freesound_train.json,/manifests/musan_music_train.json,/manifests/musan_soundbible_train.json,/manifests/mandarin_train_sample.json,/manifests/german_train_sample.json,/manifests/spanish_train_sample.json,/manifests/french_train_sample.json,/manifests/russian_train_sample.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: true\n",
            "    is_tarred: false\n",
            "    tarred_audio_filepaths: null\n",
            "    tarred_shard_strategy: scatter\n",
            "    augmentor:\n",
            "      shift:\n",
            "        prob: 0.5\n",
            "        min_shift_ms: -10.0\n",
            "        max_shift_ms: 10.0\n",
            "      white_noise:\n",
            "        prob: 0.5\n",
            "        min_level: -90\n",
            "        max_level: -46\n",
            "        norm: true\n",
            "      noise:\n",
            "        prob: 0.5\n",
            "        manifest_path: /manifests/noise_0_1_musan_fs.json\n",
            "        min_snr_db: 0\n",
            "        max_snr_db: 30\n",
            "        max_gain_db: 300.0\n",
            "        norm: true\n",
            "      gain:\n",
            "        prob: 0.5\n",
            "        min_gain_dbfs: -10.0\n",
            "        max_gain_dbfs: 10.0\n",
            "        norm: true\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2024-11-13 13:06:30 modelPT:183] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: /manifests/ami_dev_0.63.json,/manifests/freesound_background_dev.json,/manifests/freesound_laughter_dev.json,/manifests/ch120_moved_0.63.json,/manifests/fisher_2005_500_speech_sampled.json,/manifests/google_dev_manifest.json,/manifests/musan_music_dev.json,/manifests/mandarin_dev.json,/manifests/german_dev.json,/manifests/spanish_dev.json,/manifests/french_dev.json,/manifests/russian_dev.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: false\n",
            "    val_loss_idx: 0\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2024-11-13 13:06:30 modelPT:189] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 128\n",
            "    shuffle: false\n",
            "    test_loss_idx: 0\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:06:30 features:305] PADDING: 16\n",
            "[NeMo I 2024-11-13 13:06:30 save_restore_connector:272] Model EncDecClassificationModel was successfully restored from /root/.cache/torch/NeMo/NeMo_2.0.0rc1/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
            "[NeMo I 2024-11-13 13:06:30 msdd_models:870] Multiscale Weights: [1, 1, 1, 1, 1]\n",
            "[NeMo I 2024-11-13 13:06:30 msdd_models:871] Clustering Parameters: {\n",
            "        \"oracle_num_speakers\": false,\n",
            "        \"max_num_speakers\": 8,\n",
            "        \"enhanced_count_thres\": 80,\n",
            "        \"max_rp_threshold\": 0.25,\n",
            "        \"sparse_search_volume\": 30,\n",
            "        \"maj_vote_spk_count\": false,\n",
            "        \"chunk_cluster_count\": 50,\n",
            "        \"embeddings_per_chunk\": 10000\n",
            "    }\n",
            "[NeMo I 2024-11-13 13:06:30 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2024-11-13 13:06:30 clustering_diarizer:313] Split long audio file to avoid CUDA memory issue\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "splitting manifest: 100%|| 1/1 [00:00<00:00, 25.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:06:30 classification_models:293] Perform streaming frame-level VAD\n",
            "[NeMo I 2024-11-13 13:06:30 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-11-13 13:06:30 collections:741] Dataset successfully loaded with 11 items and total duration provided from manifest is  0.15 hours.\n",
            "[NeMo I 2024-11-13 13:06:30 collections:746] # 11 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "vad:   0%|          | 0/11 [00:00<?, ?it/s][NeMo W 2024-11-13 13:06:30 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/collections/asr/models/clustering_diarizer.py:226: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "      with autocast():\n",
            "    \n",
            "[NeMo W 2024-11-13 13:06:30 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/collections/asr/parts/preprocessing/features.py:436: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "      with torch.cuda.amp.autocast(enabled=False):\n",
            "    \n",
            "vad: 100%|| 11/11 [00:02<00:00,  4.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:06:33 clustering_diarizer:254] Generating predictions with overlapping input segments\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "                                                               "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:06:37 clustering_diarizer:266] Converting frame level prediction to speech/no-speech segment in start and end times format.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "creating speech segments: 100%|| 1/1 [00:00<00:00,  2.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:06:37 clustering_diarizer:291] Subsegmentation for embedding extraction: scale0, /content/temp_outputs/speaker_outputs/subsegments_scale0.json\n",
            "[NeMo I 2024-11-13 13:06:37 clustering_diarizer:347] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-11-13 13:06:37 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-11-13 13:06:37 collections:741] Dataset successfully loaded with 297 items and total duration provided from manifest is  0.03 hours.\n",
            "[NeMo I 2024-11-13 13:06:37 collections:746] # 297 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[1/5] extract embeddings:   0%|          | 0/5 [00:00<?, ?it/s][NeMo W 2024-11-13 13:06:37 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/collections/asr/models/clustering_diarizer.py:362: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "      with autocast():\n",
            "    \n",
            "[NeMo W 2024-11-13 13:06:37 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/collections/asr/parts/submodules/jasper.py:476: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "      with torch.cuda.amp.autocast(enabled=False):\n",
            "    \n",
            "[1/5] extract embeddings: 100%|| 5/5 [00:00<00:00,  9.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:06:38 clustering_diarizer:393] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-11-13 13:06:38 clustering_diarizer:291] Subsegmentation for embedding extraction: scale1, /content/temp_outputs/speaker_outputs/subsegments_scale1.json\n",
            "[NeMo I 2024-11-13 13:06:38 clustering_diarizer:347] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-11-13 13:06:38 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-11-13 13:06:38 collections:741] Dataset successfully loaded with 302 items and total duration provided from manifest is  0.03 hours.\n",
            "[NeMo I 2024-11-13 13:06:38 collections:746] # 302 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[2/5] extract embeddings: 100%|| 5/5 [00:00<00:00, 13.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:06:38 clustering_diarizer:393] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-11-13 13:06:38 clustering_diarizer:291] Subsegmentation for embedding extraction: scale2, /content/temp_outputs/speaker_outputs/subsegments_scale2.json\n",
            "[NeMo I 2024-11-13 13:06:38 clustering_diarizer:347] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-11-13 13:06:38 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-11-13 13:06:38 collections:741] Dataset successfully loaded with 313 items and total duration provided from manifest is  0.03 hours.\n",
            "[NeMo I 2024-11-13 13:06:38 collections:746] # 313 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[3/5] extract embeddings: 100%|| 5/5 [00:00<00:00, 12.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:06:39 clustering_diarizer:393] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-11-13 13:06:39 clustering_diarizer:291] Subsegmentation for embedding extraction: scale3, /content/temp_outputs/speaker_outputs/subsegments_scale3.json\n",
            "[NeMo I 2024-11-13 13:06:39 clustering_diarizer:347] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-11-13 13:06:39 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-11-13 13:06:39 collections:741] Dataset successfully loaded with 337 items and total duration provided from manifest is  0.03 hours.\n",
            "[NeMo I 2024-11-13 13:06:39 collections:746] # 337 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[4/5] extract embeddings: 100%|| 6/6 [00:00<00:00, 14.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:06:39 clustering_diarizer:393] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-11-13 13:06:39 clustering_diarizer:291] Subsegmentation for embedding extraction: scale4, /content/temp_outputs/speaker_outputs/subsegments_scale4.json\n",
            "[NeMo I 2024-11-13 13:06:39 clustering_diarizer:347] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-11-13 13:06:39 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-11-13 13:06:39 collections:741] Dataset successfully loaded with 404 items and total duration provided from manifest is  0.04 hours.\n",
            "[NeMo I 2024-11-13 13:06:39 collections:746] # 404 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[5/5] extract embeddings: 100%|| 7/7 [00:00<00:00, 14.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:06:40 clustering_diarizer:393] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "clustering: 100%|| 1/1 [00:00<00:00,  1.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:06:41 clustering_diarizer:461] Outputs are saved in /content/temp_outputs directory\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[NeMo W 2024-11-13 13:06:41 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:06:41 msdd_models:966] Loading embedding pickle file of scale:0 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale0_embeddings.pkl\n",
            "[NeMo I 2024-11-13 13:06:41 msdd_models:966] Loading embedding pickle file of scale:1 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale1_embeddings.pkl\n",
            "[NeMo I 2024-11-13 13:06:41 msdd_models:966] Loading embedding pickle file of scale:2 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale2_embeddings.pkl\n",
            "[NeMo I 2024-11-13 13:06:41 msdd_models:966] Loading embedding pickle file of scale:3 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale3_embeddings.pkl\n",
            "[NeMo I 2024-11-13 13:06:41 msdd_models:966] Loading embedding pickle file of scale:4 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale4_embeddings.pkl\n",
            "[NeMo I 2024-11-13 13:06:41 msdd_models:944] Loading cluster label file from /content/temp_outputs/speaker_outputs/subsegments_scale4_cluster.label\n",
            "[NeMo I 2024-11-13 13:06:41 collections:1067] Filtered duration for loading collection is 0.000000.\n",
            "[NeMo I 2024-11-13 13:06:41 collections:1071] Total 1 session files loaded accounting to # 1 audio clips\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/1 [00:00<?, ?it/s][NeMo W 2024-11-13 13:06:41 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/collections/asr/models/msdd_models.py:1333: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "      with autocast():\n",
            "    \n",
            "100%|| 1/1 [00:00<00:00,  1.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:06:41 msdd_models:1407]      [Threshold: 0.7000] [use_clus_as_main=False] [diar_window=50]\n",
            "[NeMo I 2024-11-13 13:06:41 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2024-11-13 13:06:41 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[NeMo W 2024-11-13 13:06:41 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:06:41 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-11-13 13:06:41 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:06:41 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-11-13 13:06:41 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:06:41 msdd_models:1435]   \n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Punctuation restoration is not available for ru language. Using the original punctuation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:08:14 msdd_models:1097] Loading pretrained diar_msdd_telephonic model from NGC\n",
            "[NeMo I 2024-11-13 13:08:14 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_2.0.0rc1/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
            "[NeMo I 2024-11-13 13:08:14 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_2.0.0rc1/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo\n",
            "[NeMo I 2024-11-13 13:08:14 common:826] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-11-13 13:08:16 modelPT:176] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: true\n",
            "    \n",
            "[NeMo W 2024-11-13 13:08:16 modelPT:183] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    \n",
            "[NeMo W 2024-11-13 13:08:16 modelPT:189] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    seq_eval_mode: false\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:08:16 features:305] PADDING: 16\n",
            "[NeMo I 2024-11-13 13:08:17 features:305] PADDING: 16\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-11-13 13:08:17 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/core/connectors/save_restore_connector.py:617: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "      return torch.load(model_weights, map_location='cpu')\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:08:17 save_restore_connector:272] Model EncDecDiarLabelModel was successfully restored from /root/.cache/torch/NeMo/NeMo_2.0.0rc1/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
            "[NeMo I 2024-11-13 13:08:17 features:305] PADDING: 16\n",
            "[NeMo I 2024-11-13 13:08:18 clustering_diarizer:127] Loading pretrained vad_multilingual_marblenet model from NGC\n",
            "[NeMo I 2024-11-13 13:08:18 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_2.0.0rc1/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
            "[NeMo I 2024-11-13 13:08:18 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_2.0.0rc1/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo\n",
            "[NeMo I 2024-11-13 13:08:18 common:826] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-11-13 13:08:18 modelPT:176] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: /manifests/ami_train_0.63.json,/manifests/freesound_background_train.json,/manifests/freesound_laughter_train.json,/manifests/fisher_2004_background.json,/manifests/fisher_2004_speech_sampled.json,/manifests/google_train_manifest.json,/manifests/icsi_all_0.63.json,/manifests/musan_freesound_train.json,/manifests/musan_music_train.json,/manifests/musan_soundbible_train.json,/manifests/mandarin_train_sample.json,/manifests/german_train_sample.json,/manifests/spanish_train_sample.json,/manifests/french_train_sample.json,/manifests/russian_train_sample.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: true\n",
            "    is_tarred: false\n",
            "    tarred_audio_filepaths: null\n",
            "    tarred_shard_strategy: scatter\n",
            "    augmentor:\n",
            "      shift:\n",
            "        prob: 0.5\n",
            "        min_shift_ms: -10.0\n",
            "        max_shift_ms: 10.0\n",
            "      white_noise:\n",
            "        prob: 0.5\n",
            "        min_level: -90\n",
            "        max_level: -46\n",
            "        norm: true\n",
            "      noise:\n",
            "        prob: 0.5\n",
            "        manifest_path: /manifests/noise_0_1_musan_fs.json\n",
            "        min_snr_db: 0\n",
            "        max_snr_db: 30\n",
            "        max_gain_db: 300.0\n",
            "        norm: true\n",
            "      gain:\n",
            "        prob: 0.5\n",
            "        min_gain_dbfs: -10.0\n",
            "        max_gain_dbfs: 10.0\n",
            "        norm: true\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2024-11-13 13:08:18 modelPT:183] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: /manifests/ami_dev_0.63.json,/manifests/freesound_background_dev.json,/manifests/freesound_laughter_dev.json,/manifests/ch120_moved_0.63.json,/manifests/fisher_2005_500_speech_sampled.json,/manifests/google_dev_manifest.json,/manifests/musan_music_dev.json,/manifests/mandarin_dev.json,/manifests/german_dev.json,/manifests/spanish_dev.json,/manifests/french_dev.json,/manifests/russian_dev.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: false\n",
            "    val_loss_idx: 0\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2024-11-13 13:08:18 modelPT:189] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 128\n",
            "    shuffle: false\n",
            "    test_loss_idx: 0\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:08:18 features:305] PADDING: 16\n",
            "[NeMo I 2024-11-13 13:08:18 save_restore_connector:272] Model EncDecClassificationModel was successfully restored from /root/.cache/torch/NeMo/NeMo_2.0.0rc1/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
            "[NeMo I 2024-11-13 13:08:18 msdd_models:870] Multiscale Weights: [1, 1, 1, 1, 1]\n",
            "[NeMo I 2024-11-13 13:08:18 msdd_models:871] Clustering Parameters: {\n",
            "        \"oracle_num_speakers\": false,\n",
            "        \"max_num_speakers\": 8,\n",
            "        \"enhanced_count_thres\": 80,\n",
            "        \"max_rp_threshold\": 0.25,\n",
            "        \"sparse_search_volume\": 30,\n",
            "        \"maj_vote_spk_count\": false,\n",
            "        \"chunk_cluster_count\": 50,\n",
            "        \"embeddings_per_chunk\": 10000\n",
            "    }\n",
            "[NeMo I 2024-11-13 13:08:18 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2024-11-13 13:08:18 clustering_diarizer:313] Split long audio file to avoid CUDA memory issue\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "splitting manifest: 100%|| 1/1 [00:00<00:00, 30.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:08:18 classification_models:293] Perform streaming frame-level VAD\n",
            "[NeMo I 2024-11-13 13:08:18 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-11-13 13:08:18 collections:741] Dataset successfully loaded with 9 items and total duration provided from manifest is  0.12 hours.\n",
            "[NeMo I 2024-11-13 13:08:18 collections:746] # 9 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "vad:   0%|          | 0/9 [00:00<?, ?it/s][NeMo W 2024-11-13 13:08:18 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/collections/asr/models/clustering_diarizer.py:226: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "      with autocast():\n",
            "    \n",
            "[NeMo W 2024-11-13 13:08:18 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/collections/asr/parts/preprocessing/features.py:436: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "      with torch.cuda.amp.autocast(enabled=False):\n",
            "    \n",
            "vad: 100%|| 9/9 [00:02<00:00,  3.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:08:20 clustering_diarizer:254] Generating predictions with overlapping input segments\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "                                                               "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:08:24 clustering_diarizer:266] Converting frame level prediction to speech/no-speech segment in start and end times format.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "creating speech segments: 100%|| 1/1 [00:00<00:00,  3.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:08:24 clustering_diarizer:291] Subsegmentation for embedding extraction: scale0, /content/temp_outputs/speaker_outputs/subsegments_scale0.json\n",
            "[NeMo I 2024-11-13 13:08:24 clustering_diarizer:347] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-11-13 13:08:24 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-11-13 13:08:24 collections:741] Dataset successfully loaded with 339 items and total duration provided from manifest is  0.05 hours.\n",
            "[NeMo I 2024-11-13 13:08:24 collections:746] # 339 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[1/5] extract embeddings:   0%|          | 0/6 [00:00<?, ?it/s][NeMo W 2024-11-13 13:08:24 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/collections/asr/models/clustering_diarizer.py:362: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "      with autocast():\n",
            "    \n",
            "[NeMo W 2024-11-13 13:08:24 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/collections/asr/parts/submodules/jasper.py:476: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "      with torch.cuda.amp.autocast(enabled=False):\n",
            "    \n",
            "[1/5] extract embeddings: 100%|| 6/6 [00:00<00:00,  9.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:08:25 clustering_diarizer:393] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-11-13 13:08:25 clustering_diarizer:291] Subsegmentation for embedding extraction: scale1, /content/temp_outputs/speaker_outputs/subsegments_scale1.json\n",
            "[NeMo I 2024-11-13 13:08:25 clustering_diarizer:347] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-11-13 13:08:25 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-11-13 13:08:25 collections:741] Dataset successfully loaded with 354 items and total duration provided from manifest is  0.05 hours.\n",
            "[NeMo I 2024-11-13 13:08:25 collections:746] # 354 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[2/5] extract embeddings: 100%|| 6/6 [00:00<00:00, 13.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:08:25 clustering_diarizer:393] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-11-13 13:08:25 clustering_diarizer:291] Subsegmentation for embedding extraction: scale2, /content/temp_outputs/speaker_outputs/subsegments_scale2.json\n",
            "[NeMo I 2024-11-13 13:08:25 clustering_diarizer:347] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-11-13 13:08:25 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-11-13 13:08:25 collections:741] Dataset successfully loaded with 386 items and total duration provided from manifest is  0.06 hours.\n",
            "[NeMo I 2024-11-13 13:08:25 collections:746] # 386 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[3/5] extract embeddings: 100%|| 7/7 [00:00<00:00, 11.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:08:26 clustering_diarizer:393] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-11-13 13:08:26 clustering_diarizer:291] Subsegmentation for embedding extraction: scale3, /content/temp_outputs/speaker_outputs/subsegments_scale3.json\n",
            "[NeMo I 2024-11-13 13:08:26 clustering_diarizer:347] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-11-13 13:08:26 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-11-13 13:08:26 collections:741] Dataset successfully loaded with 453 items and total duration provided from manifest is  0.06 hours.\n",
            "[NeMo I 2024-11-13 13:08:26 collections:746] # 453 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[4/5] extract embeddings: 100%|| 8/8 [00:00<00:00, 12.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:08:27 clustering_diarizer:393] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-11-13 13:08:27 clustering_diarizer:291] Subsegmentation for embedding extraction: scale4, /content/temp_outputs/speaker_outputs/subsegments_scale4.json\n",
            "[NeMo I 2024-11-13 13:08:27 clustering_diarizer:347] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-11-13 13:08:27 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-11-13 13:08:27 collections:741] Dataset successfully loaded with 617 items and total duration provided from manifest is  0.07 hours.\n",
            "[NeMo I 2024-11-13 13:08:27 collections:746] # 617 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[5/5] extract embeddings: 100%|| 10/10 [00:00<00:00, 14.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:08:28 clustering_diarizer:393] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "clustering: 100%|| 1/1 [00:00<00:00,  1.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:08:28 clustering_diarizer:461] Outputs are saved in /content/temp_outputs directory\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[NeMo W 2024-11-13 13:08:28 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:08:28 msdd_models:966] Loading embedding pickle file of scale:0 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale0_embeddings.pkl\n",
            "[NeMo I 2024-11-13 13:08:28 msdd_models:966] Loading embedding pickle file of scale:1 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale1_embeddings.pkl\n",
            "[NeMo I 2024-11-13 13:08:28 msdd_models:966] Loading embedding pickle file of scale:2 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale2_embeddings.pkl\n",
            "[NeMo I 2024-11-13 13:08:28 msdd_models:966] Loading embedding pickle file of scale:3 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale3_embeddings.pkl\n",
            "[NeMo I 2024-11-13 13:08:28 msdd_models:966] Loading embedding pickle file of scale:4 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale4_embeddings.pkl\n",
            "[NeMo I 2024-11-13 13:08:28 msdd_models:944] Loading cluster label file from /content/temp_outputs/speaker_outputs/subsegments_scale4_cluster.label\n",
            "[NeMo I 2024-11-13 13:08:28 collections:1067] Filtered duration for loading collection is 0.000000.\n",
            "[NeMo I 2024-11-13 13:08:28 collections:1071] Total 1 session files loaded accounting to # 1 audio clips\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/1 [00:00<?, ?it/s][NeMo W 2024-11-13 13:08:28 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/collections/asr/models/msdd_models.py:1333: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "      with autocast():\n",
            "    \n",
            "100%|| 1/1 [00:00<00:00, 35.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:08:28 msdd_models:1407]      [Threshold: 0.7000] [use_clus_as_main=False] [diar_window=50]\n",
            "[NeMo I 2024-11-13 13:08:28 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2024-11-13 13:08:28 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[NeMo W 2024-11-13 13:08:28 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:08:28 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-11-13 13:08:28 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:08:28 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-11-13 13:08:28 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:08:28 msdd_models:1435]   \n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Punctuation restoration is not available for ru language. Using the original punctuation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:12:27 msdd_models:1097] Loading pretrained diar_msdd_telephonic model from NGC\n",
            "[NeMo I 2024-11-13 13:12:27 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_2.0.0rc1/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
            "[NeMo I 2024-11-13 13:12:27 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_2.0.0rc1/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo\n",
            "[NeMo I 2024-11-13 13:12:27 common:826] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-11-13 13:12:29 modelPT:176] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: true\n",
            "    \n",
            "[NeMo W 2024-11-13 13:12:29 modelPT:183] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    \n",
            "[NeMo W 2024-11-13 13:12:29 modelPT:189] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    seq_eval_mode: false\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:12:29 features:305] PADDING: 16\n",
            "[NeMo I 2024-11-13 13:12:29 features:305] PADDING: 16\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-11-13 13:12:29 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/core/connectors/save_restore_connector.py:617: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "      return torch.load(model_weights, map_location='cpu')\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:12:29 save_restore_connector:272] Model EncDecDiarLabelModel was successfully restored from /root/.cache/torch/NeMo/NeMo_2.0.0rc1/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
            "[NeMo I 2024-11-13 13:12:29 features:305] PADDING: 16\n",
            "[NeMo I 2024-11-13 13:12:30 clustering_diarizer:127] Loading pretrained vad_multilingual_marblenet model from NGC\n",
            "[NeMo I 2024-11-13 13:12:30 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_2.0.0rc1/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
            "[NeMo I 2024-11-13 13:12:30 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_2.0.0rc1/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo\n",
            "[NeMo I 2024-11-13 13:12:30 common:826] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-11-13 13:12:30 modelPT:176] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: /manifests/ami_train_0.63.json,/manifests/freesound_background_train.json,/manifests/freesound_laughter_train.json,/manifests/fisher_2004_background.json,/manifests/fisher_2004_speech_sampled.json,/manifests/google_train_manifest.json,/manifests/icsi_all_0.63.json,/manifests/musan_freesound_train.json,/manifests/musan_music_train.json,/manifests/musan_soundbible_train.json,/manifests/mandarin_train_sample.json,/manifests/german_train_sample.json,/manifests/spanish_train_sample.json,/manifests/french_train_sample.json,/manifests/russian_train_sample.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: true\n",
            "    is_tarred: false\n",
            "    tarred_audio_filepaths: null\n",
            "    tarred_shard_strategy: scatter\n",
            "    augmentor:\n",
            "      shift:\n",
            "        prob: 0.5\n",
            "        min_shift_ms: -10.0\n",
            "        max_shift_ms: 10.0\n",
            "      white_noise:\n",
            "        prob: 0.5\n",
            "        min_level: -90\n",
            "        max_level: -46\n",
            "        norm: true\n",
            "      noise:\n",
            "        prob: 0.5\n",
            "        manifest_path: /manifests/noise_0_1_musan_fs.json\n",
            "        min_snr_db: 0\n",
            "        max_snr_db: 30\n",
            "        max_gain_db: 300.0\n",
            "        norm: true\n",
            "      gain:\n",
            "        prob: 0.5\n",
            "        min_gain_dbfs: -10.0\n",
            "        max_gain_dbfs: 10.0\n",
            "        norm: true\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2024-11-13 13:12:30 modelPT:183] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: /manifests/ami_dev_0.63.json,/manifests/freesound_background_dev.json,/manifests/freesound_laughter_dev.json,/manifests/ch120_moved_0.63.json,/manifests/fisher_2005_500_speech_sampled.json,/manifests/google_dev_manifest.json,/manifests/musan_music_dev.json,/manifests/mandarin_dev.json,/manifests/german_dev.json,/manifests/spanish_dev.json,/manifests/french_dev.json,/manifests/russian_dev.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: false\n",
            "    val_loss_idx: 0\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2024-11-13 13:12:30 modelPT:189] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 128\n",
            "    shuffle: false\n",
            "    test_loss_idx: 0\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:12:30 features:305] PADDING: 16\n",
            "[NeMo I 2024-11-13 13:12:30 save_restore_connector:272] Model EncDecClassificationModel was successfully restored from /root/.cache/torch/NeMo/NeMo_2.0.0rc1/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
            "[NeMo I 2024-11-13 13:12:30 msdd_models:870] Multiscale Weights: [1, 1, 1, 1, 1]\n",
            "[NeMo I 2024-11-13 13:12:30 msdd_models:871] Clustering Parameters: {\n",
            "        \"oracle_num_speakers\": false,\n",
            "        \"max_num_speakers\": 8,\n",
            "        \"enhanced_count_thres\": 80,\n",
            "        \"max_rp_threshold\": 0.25,\n",
            "        \"sparse_search_volume\": 30,\n",
            "        \"maj_vote_spk_count\": false,\n",
            "        \"chunk_cluster_count\": 50,\n",
            "        \"embeddings_per_chunk\": 10000\n",
            "    }\n",
            "[NeMo I 2024-11-13 13:12:30 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2024-11-13 13:12:30 clustering_diarizer:313] Split long audio file to avoid CUDA memory issue\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "splitting manifest: 100%|| 1/1 [00:00<00:00,  6.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:12:30 classification_models:293] Perform streaming frame-level VAD\n",
            "[NeMo I 2024-11-13 13:12:30 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-11-13 13:12:30 collections:741] Dataset successfully loaded with 30 items and total duration provided from manifest is  0.40 hours.\n",
            "[NeMo I 2024-11-13 13:12:30 collections:746] # 30 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "vad:   0%|          | 0/30 [00:00<?, ?it/s][NeMo W 2024-11-13 13:12:30 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/collections/asr/models/clustering_diarizer.py:226: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "      with autocast():\n",
            "    \n",
            "[NeMo W 2024-11-13 13:12:30 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/collections/asr/parts/preprocessing/features.py:436: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "      with torch.cuda.amp.autocast(enabled=False):\n",
            "    \n",
            "vad: 100%|| 30/30 [00:07<00:00,  4.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:12:38 clustering_diarizer:254] Generating predictions with overlapping input segments\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "                                                               "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:12:52 clustering_diarizer:266] Converting frame level prediction to speech/no-speech segment in start and end times format.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "creating speech segments: 100%|| 1/1 [00:01<00:00,  1.01s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:12:53 clustering_diarizer:291] Subsegmentation for embedding extraction: scale0, /content/temp_outputs/speaker_outputs/subsegments_scale0.json\n",
            "[NeMo I 2024-11-13 13:12:53 clustering_diarizer:347] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-11-13 13:12:53 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-11-13 13:12:53 collections:741] Dataset successfully loaded with 1154 items and total duration provided from manifest is  0.20 hours.\n",
            "[NeMo I 2024-11-13 13:12:53 collections:746] # 1154 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[1/5] extract embeddings:   0%|          | 0/19 [00:00<?, ?it/s][NeMo W 2024-11-13 13:12:53 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/collections/asr/models/clustering_diarizer.py:362: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "      with autocast():\n",
            "    \n",
            "[NeMo W 2024-11-13 13:12:53 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/collections/asr/parts/submodules/jasper.py:476: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "      with torch.cuda.amp.autocast(enabled=False):\n",
            "    \n",
            "[1/5] extract embeddings: 100%|| 19/19 [00:01<00:00,  9.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:12:55 clustering_diarizer:393] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-11-13 13:12:55 clustering_diarizer:291] Subsegmentation for embedding extraction: scale1, /content/temp_outputs/speaker_outputs/subsegments_scale1.json\n",
            "[NeMo I 2024-11-13 13:12:55 clustering_diarizer:347] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-11-13 13:12:55 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-11-13 13:12:55 collections:741] Dataset successfully loaded with 1240 items and total duration provided from manifest is  0.21 hours.\n",
            "[NeMo I 2024-11-13 13:12:55 collections:746] # 1240 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[2/5] extract embeddings: 100%|| 20/20 [00:01<00:00, 12.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:12:57 clustering_diarizer:393] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-11-13 13:12:57 clustering_diarizer:291] Subsegmentation for embedding extraction: scale2, /content/temp_outputs/speaker_outputs/subsegments_scale2.json\n",
            "[NeMo I 2024-11-13 13:12:57 clustering_diarizer:347] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-11-13 13:12:57 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-11-13 13:12:57 collections:741] Dataset successfully loaded with 1378 items and total duration provided from manifest is  0.23 hours.\n",
            "[NeMo I 2024-11-13 13:12:57 collections:746] # 1378 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[3/5] extract embeddings: 100%|| 22/22 [00:01<00:00, 13.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:12:58 clustering_diarizer:393] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-11-13 13:12:58 clustering_diarizer:291] Subsegmentation for embedding extraction: scale3, /content/temp_outputs/speaker_outputs/subsegments_scale3.json\n",
            "[NeMo I 2024-11-13 13:12:58 clustering_diarizer:347] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-11-13 13:12:59 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-11-13 13:12:59 collections:741] Dataset successfully loaded with 1644 items and total duration provided from manifest is  0.24 hours.\n",
            "[NeMo I 2024-11-13 13:12:59 collections:746] # 1644 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[4/5] extract embeddings: 100%|| 26/26 [00:01<00:00, 14.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:13:01 clustering_diarizer:393] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-11-13 13:13:01 clustering_diarizer:291] Subsegmentation for embedding extraction: scale4, /content/temp_outputs/speaker_outputs/subsegments_scale4.json\n",
            "[NeMo I 2024-11-13 13:13:01 clustering_diarizer:347] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-11-13 13:13:01 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-11-13 13:13:01 collections:741] Dataset successfully loaded with 2322 items and total duration provided from manifest is  0.27 hours.\n",
            "[NeMo I 2024-11-13 13:13:01 collections:746] # 2322 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[5/5] extract embeddings: 100%|| 37/37 [00:02<00:00, 12.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:13:04 clustering_diarizer:393] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "clustering: 100%|| 1/1 [00:00<00:00,  1.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:13:05 clustering_diarizer:461] Outputs are saved in /content/temp_outputs directory\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[NeMo W 2024-11-13 13:13:05 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:13:05 msdd_models:966] Loading embedding pickle file of scale:0 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale0_embeddings.pkl\n",
            "[NeMo I 2024-11-13 13:13:05 msdd_models:966] Loading embedding pickle file of scale:1 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale1_embeddings.pkl\n",
            "[NeMo I 2024-11-13 13:13:05 msdd_models:966] Loading embedding pickle file of scale:2 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale2_embeddings.pkl\n",
            "[NeMo I 2024-11-13 13:13:05 msdd_models:966] Loading embedding pickle file of scale:3 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale3_embeddings.pkl\n",
            "[NeMo I 2024-11-13 13:13:05 msdd_models:966] Loading embedding pickle file of scale:4 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale4_embeddings.pkl\n",
            "[NeMo I 2024-11-13 13:13:05 msdd_models:944] Loading cluster label file from /content/temp_outputs/speaker_outputs/subsegments_scale4_cluster.label\n",
            "[NeMo I 2024-11-13 13:13:05 collections:1067] Filtered duration for loading collection is 0.000000.\n",
            "[NeMo I 2024-11-13 13:13:05 collections:1071] Total 6 session files loaded accounting to # 6 audio clips\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/1 [00:00<?, ?it/s][NeMo W 2024-11-13 13:13:06 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/collections/asr/models/msdd_models.py:1333: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "      with autocast():\n",
            "    \n",
            "100%|| 1/1 [00:00<00:00,  2.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:13:06 msdd_models:1407]      [Threshold: 0.7000] [use_clus_as_main=False] [diar_window=50]\n",
            "[NeMo I 2024-11-13 13:13:06 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2024-11-13 13:13:06 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[NeMo W 2024-11-13 13:13:06 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:13:06 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-11-13 13:13:06 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:13:06 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-11-13 13:13:06 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:13:06 msdd_models:1435]   \n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Punctuation restoration is not available for ru language. Using the original punctuation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:19:06 msdd_models:1097] Loading pretrained diar_msdd_telephonic model from NGC\n",
            "[NeMo I 2024-11-13 13:19:06 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_2.0.0rc1/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
            "[NeMo I 2024-11-13 13:19:06 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_2.0.0rc1/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo\n",
            "[NeMo I 2024-11-13 13:19:06 common:826] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-11-13 13:19:10 modelPT:176] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: true\n",
            "    \n",
            "[NeMo W 2024-11-13 13:19:10 modelPT:183] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    \n",
            "[NeMo W 2024-11-13 13:19:10 modelPT:189] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    seq_eval_mode: false\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:19:10 features:305] PADDING: 16\n",
            "[NeMo I 2024-11-13 13:19:11 features:305] PADDING: 16\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-11-13 13:19:11 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/core/connectors/save_restore_connector.py:617: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "      return torch.load(model_weights, map_location='cpu')\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:19:11 save_restore_connector:272] Model EncDecDiarLabelModel was successfully restored from /root/.cache/torch/NeMo/NeMo_2.0.0rc1/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
            "[NeMo I 2024-11-13 13:19:11 features:305] PADDING: 16\n",
            "[NeMo I 2024-11-13 13:19:12 clustering_diarizer:127] Loading pretrained vad_multilingual_marblenet model from NGC\n",
            "[NeMo I 2024-11-13 13:19:12 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_2.0.0rc1/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
            "[NeMo I 2024-11-13 13:19:12 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_2.0.0rc1/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo\n",
            "[NeMo I 2024-11-13 13:19:12 common:826] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-11-13 13:19:12 modelPT:176] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: /manifests/ami_train_0.63.json,/manifests/freesound_background_train.json,/manifests/freesound_laughter_train.json,/manifests/fisher_2004_background.json,/manifests/fisher_2004_speech_sampled.json,/manifests/google_train_manifest.json,/manifests/icsi_all_0.63.json,/manifests/musan_freesound_train.json,/manifests/musan_music_train.json,/manifests/musan_soundbible_train.json,/manifests/mandarin_train_sample.json,/manifests/german_train_sample.json,/manifests/spanish_train_sample.json,/manifests/french_train_sample.json,/manifests/russian_train_sample.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: true\n",
            "    is_tarred: false\n",
            "    tarred_audio_filepaths: null\n",
            "    tarred_shard_strategy: scatter\n",
            "    augmentor:\n",
            "      shift:\n",
            "        prob: 0.5\n",
            "        min_shift_ms: -10.0\n",
            "        max_shift_ms: 10.0\n",
            "      white_noise:\n",
            "        prob: 0.5\n",
            "        min_level: -90\n",
            "        max_level: -46\n",
            "        norm: true\n",
            "      noise:\n",
            "        prob: 0.5\n",
            "        manifest_path: /manifests/noise_0_1_musan_fs.json\n",
            "        min_snr_db: 0\n",
            "        max_snr_db: 30\n",
            "        max_gain_db: 300.0\n",
            "        norm: true\n",
            "      gain:\n",
            "        prob: 0.5\n",
            "        min_gain_dbfs: -10.0\n",
            "        max_gain_dbfs: 10.0\n",
            "        norm: true\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2024-11-13 13:19:12 modelPT:183] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: /manifests/ami_dev_0.63.json,/manifests/freesound_background_dev.json,/manifests/freesound_laughter_dev.json,/manifests/ch120_moved_0.63.json,/manifests/fisher_2005_500_speech_sampled.json,/manifests/google_dev_manifest.json,/manifests/musan_music_dev.json,/manifests/mandarin_dev.json,/manifests/german_dev.json,/manifests/spanish_dev.json,/manifests/french_dev.json,/manifests/russian_dev.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: false\n",
            "    val_loss_idx: 0\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2024-11-13 13:19:12 modelPT:189] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 128\n",
            "    shuffle: false\n",
            "    test_loss_idx: 0\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:19:12 features:305] PADDING: 16\n",
            "[NeMo I 2024-11-13 13:19:12 save_restore_connector:272] Model EncDecClassificationModel was successfully restored from /root/.cache/torch/NeMo/NeMo_2.0.0rc1/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
            "[NeMo I 2024-11-13 13:19:12 msdd_models:870] Multiscale Weights: [1, 1, 1, 1, 1]\n",
            "[NeMo I 2024-11-13 13:19:12 msdd_models:871] Clustering Parameters: {\n",
            "        \"oracle_num_speakers\": false,\n",
            "        \"max_num_speakers\": 8,\n",
            "        \"enhanced_count_thres\": 80,\n",
            "        \"max_rp_threshold\": 0.25,\n",
            "        \"sparse_search_volume\": 30,\n",
            "        \"maj_vote_spk_count\": false,\n",
            "        \"chunk_cluster_count\": 50,\n",
            "        \"embeddings_per_chunk\": 10000\n",
            "    }\n",
            "[NeMo I 2024-11-13 13:19:12 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2024-11-13 13:19:12 clustering_diarizer:313] Split long audio file to avoid CUDA memory issue\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "splitting manifest: 100%|| 1/1 [00:00<00:00,  5.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:19:12 classification_models:293] Perform streaming frame-level VAD\n",
            "[NeMo I 2024-11-13 13:19:12 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-11-13 13:19:12 collections:741] Dataset successfully loaded with 43 items and total duration provided from manifest is  0.60 hours.\n",
            "[NeMo I 2024-11-13 13:19:12 collections:746] # 43 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rvad:   0%|          | 0/43 [00:00<?, ?it/s][NeMo W 2024-11-13 13:19:12 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/collections/asr/models/clustering_diarizer.py:226: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "      with autocast():\n",
            "    \n",
            "[NeMo W 2024-11-13 13:19:12 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/collections/asr/parts/preprocessing/features.py:436: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "      with torch.cuda.amp.autocast(enabled=False):\n",
            "    \n",
            "vad: 100%|| 43/43 [00:09<00:00,  4.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:19:22 clustering_diarizer:254] Generating predictions with overlapping input segments\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "                                                               "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:19:41 clustering_diarizer:266] Converting frame level prediction to speech/no-speech segment in start and end times format.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "creating speech segments: 100%|| 1/1 [00:03<00:00,  3.51s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:19:45 clustering_diarizer:291] Subsegmentation for embedding extraction: scale0, /content/temp_outputs/speaker_outputs/subsegments_scale0.json\n",
            "[NeMo I 2024-11-13 13:19:45 clustering_diarizer:347] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-11-13 13:19:45 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-11-13 13:19:45 collections:741] Dataset successfully loaded with 1630 items and total duration provided from manifest is  0.24 hours.\n",
            "[NeMo I 2024-11-13 13:19:45 collections:746] # 1630 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[1/5] extract embeddings:   0%|          | 0/26 [00:00<?, ?it/s][NeMo W 2024-11-13 13:19:45 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/collections/asr/models/clustering_diarizer.py:362: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "      with autocast():\n",
            "    \n",
            "[NeMo W 2024-11-13 13:19:45 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/collections/asr/parts/submodules/jasper.py:476: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "      with torch.cuda.amp.autocast(enabled=False):\n",
            "    \n",
            "[1/5] extract embeddings: 100%|| 26/26 [00:02<00:00, 10.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:19:48 clustering_diarizer:393] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-11-13 13:19:48 clustering_diarizer:291] Subsegmentation for embedding extraction: scale1, /content/temp_outputs/speaker_outputs/subsegments_scale1.json\n",
            "[NeMo I 2024-11-13 13:19:48 clustering_diarizer:347] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-11-13 13:19:48 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-11-13 13:19:48 collections:741] Dataset successfully loaded with 1711 items and total duration provided from manifest is  0.25 hours.\n",
            "[NeMo I 2024-11-13 13:19:48 collections:746] # 1711 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[2/5] extract embeddings: 100%|| 27/27 [00:02<00:00, 12.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:19:50 clustering_diarizer:393] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-11-13 13:19:50 clustering_diarizer:291] Subsegmentation for embedding extraction: scale2, /content/temp_outputs/speaker_outputs/subsegments_scale2.json\n",
            "[NeMo I 2024-11-13 13:19:50 clustering_diarizer:347] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-11-13 13:19:50 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-11-13 13:19:50 collections:741] Dataset successfully loaded with 1849 items and total duration provided from manifest is  0.26 hours.\n",
            "[NeMo I 2024-11-13 13:19:50 collections:746] # 1849 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[3/5] extract embeddings: 100%|| 29/29 [00:02<00:00, 13.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:19:53 clustering_diarizer:393] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-11-13 13:19:53 clustering_diarizer:291] Subsegmentation for embedding extraction: scale3, /content/temp_outputs/speaker_outputs/subsegments_scale3.json\n",
            "[NeMo I 2024-11-13 13:19:53 clustering_diarizer:347] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-11-13 13:19:53 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-11-13 13:19:53 collections:741] Dataset successfully loaded with 2125 items and total duration provided from manifest is  0.28 hours.\n",
            "[NeMo I 2024-11-13 13:19:53 collections:746] # 2125 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[4/5] extract embeddings: 100%|| 34/34 [00:02<00:00, 16.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:19:56 clustering_diarizer:393] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-11-13 13:19:56 clustering_diarizer:291] Subsegmentation for embedding extraction: scale4, /content/temp_outputs/speaker_outputs/subsegments_scale4.json\n",
            "[NeMo I 2024-11-13 13:19:56 clustering_diarizer:347] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-11-13 13:19:56 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-11-13 13:19:56 collections:741] Dataset successfully loaded with 2888 items and total duration provided from manifest is  0.31 hours.\n",
            "[NeMo I 2024-11-13 13:19:56 collections:746] # 2888 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[5/5] extract embeddings: 100%|| 46/46 [00:03<00:00, 13.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:20:00 clustering_diarizer:393] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "clustering: 100%|| 1/1 [00:01<00:00,  1.30s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:20:01 clustering_diarizer:461] Outputs are saved in /content/temp_outputs directory\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[NeMo W 2024-11-13 13:20:01 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:20:01 msdd_models:966] Loading embedding pickle file of scale:0 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale0_embeddings.pkl\n",
            "[NeMo I 2024-11-13 13:20:01 msdd_models:966] Loading embedding pickle file of scale:1 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale1_embeddings.pkl\n",
            "[NeMo I 2024-11-13 13:20:01 msdd_models:966] Loading embedding pickle file of scale:2 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale2_embeddings.pkl\n",
            "[NeMo I 2024-11-13 13:20:01 msdd_models:966] Loading embedding pickle file of scale:3 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale3_embeddings.pkl\n",
            "[NeMo I 2024-11-13 13:20:01 msdd_models:966] Loading embedding pickle file of scale:4 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale4_embeddings.pkl\n",
            "[NeMo I 2024-11-13 13:20:01 msdd_models:944] Loading cluster label file from /content/temp_outputs/speaker_outputs/subsegments_scale4_cluster.label\n",
            "[NeMo I 2024-11-13 13:20:02 collections:1067] Filtered duration for loading collection is 0.000000.\n",
            "[NeMo I 2024-11-13 13:20:02 collections:1071] Total 1 session files loaded accounting to # 1 audio clips\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/1 [00:00<?, ?it/s][NeMo W 2024-11-13 13:20:02 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/collections/asr/models/msdd_models.py:1333: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "      with autocast():\n",
            "    \n",
            "100%|| 1/1 [00:00<00:00,  7.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:20:02 msdd_models:1407]      [Threshold: 0.7000] [use_clus_as_main=False] [diar_window=50]\n",
            "[NeMo I 2024-11-13 13:20:02 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2024-11-13 13:20:02 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[NeMo W 2024-11-13 13:20:02 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:20:02 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-11-13 13:20:02 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:20:02 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-11-13 13:20:02 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:20:02 msdd_models:1435]   \n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Punctuation restoration is not available for ru language. Using the original punctuation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:23:32 msdd_models:1097] Loading pretrained diar_msdd_telephonic model from NGC\n",
            "[NeMo I 2024-11-13 13:23:32 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_2.0.0rc1/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
            "[NeMo I 2024-11-13 13:23:32 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_2.0.0rc1/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo\n",
            "[NeMo I 2024-11-13 13:23:32 common:826] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-11-13 13:23:33 modelPT:176] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: true\n",
            "    \n",
            "[NeMo W 2024-11-13 13:23:33 modelPT:183] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    \n",
            "[NeMo W 2024-11-13 13:23:33 modelPT:189] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    seq_eval_mode: false\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:23:36 features:305] PADDING: 16\n",
            "[NeMo I 2024-11-13 13:23:36 features:305] PADDING: 16\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-11-13 13:23:37 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/core/connectors/save_restore_connector.py:617: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "      return torch.load(model_weights, map_location='cpu')\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:23:37 save_restore_connector:272] Model EncDecDiarLabelModel was successfully restored from /root/.cache/torch/NeMo/NeMo_2.0.0rc1/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
            "[NeMo I 2024-11-13 13:23:37 features:305] PADDING: 16\n",
            "[NeMo I 2024-11-13 13:23:38 clustering_diarizer:127] Loading pretrained vad_multilingual_marblenet model from NGC\n",
            "[NeMo I 2024-11-13 13:23:38 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_2.0.0rc1/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
            "[NeMo I 2024-11-13 13:23:38 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_2.0.0rc1/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo\n",
            "[NeMo I 2024-11-13 13:23:38 common:826] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-11-13 13:23:38 modelPT:176] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: /manifests/ami_train_0.63.json,/manifests/freesound_background_train.json,/manifests/freesound_laughter_train.json,/manifests/fisher_2004_background.json,/manifests/fisher_2004_speech_sampled.json,/manifests/google_train_manifest.json,/manifests/icsi_all_0.63.json,/manifests/musan_freesound_train.json,/manifests/musan_music_train.json,/manifests/musan_soundbible_train.json,/manifests/mandarin_train_sample.json,/manifests/german_train_sample.json,/manifests/spanish_train_sample.json,/manifests/french_train_sample.json,/manifests/russian_train_sample.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: true\n",
            "    is_tarred: false\n",
            "    tarred_audio_filepaths: null\n",
            "    tarred_shard_strategy: scatter\n",
            "    augmentor:\n",
            "      shift:\n",
            "        prob: 0.5\n",
            "        min_shift_ms: -10.0\n",
            "        max_shift_ms: 10.0\n",
            "      white_noise:\n",
            "        prob: 0.5\n",
            "        min_level: -90\n",
            "        max_level: -46\n",
            "        norm: true\n",
            "      noise:\n",
            "        prob: 0.5\n",
            "        manifest_path: /manifests/noise_0_1_musan_fs.json\n",
            "        min_snr_db: 0\n",
            "        max_snr_db: 30\n",
            "        max_gain_db: 300.0\n",
            "        norm: true\n",
            "      gain:\n",
            "        prob: 0.5\n",
            "        min_gain_dbfs: -10.0\n",
            "        max_gain_dbfs: 10.0\n",
            "        norm: true\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2024-11-13 13:23:38 modelPT:183] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: /manifests/ami_dev_0.63.json,/manifests/freesound_background_dev.json,/manifests/freesound_laughter_dev.json,/manifests/ch120_moved_0.63.json,/manifests/fisher_2005_500_speech_sampled.json,/manifests/google_dev_manifest.json,/manifests/musan_music_dev.json,/manifests/mandarin_dev.json,/manifests/german_dev.json,/manifests/spanish_dev.json,/manifests/french_dev.json,/manifests/russian_dev.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: false\n",
            "    val_loss_idx: 0\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2024-11-13 13:23:38 modelPT:189] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 128\n",
            "    shuffle: false\n",
            "    test_loss_idx: 0\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:23:38 features:305] PADDING: 16\n",
            "[NeMo I 2024-11-13 13:23:38 save_restore_connector:272] Model EncDecClassificationModel was successfully restored from /root/.cache/torch/NeMo/NeMo_2.0.0rc1/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
            "[NeMo I 2024-11-13 13:23:38 msdd_models:870] Multiscale Weights: [1, 1, 1, 1, 1]\n",
            "[NeMo I 2024-11-13 13:23:38 msdd_models:871] Clustering Parameters: {\n",
            "        \"oracle_num_speakers\": false,\n",
            "        \"max_num_speakers\": 8,\n",
            "        \"enhanced_count_thres\": 80,\n",
            "        \"max_rp_threshold\": 0.25,\n",
            "        \"sparse_search_volume\": 30,\n",
            "        \"maj_vote_spk_count\": false,\n",
            "        \"chunk_cluster_count\": 50,\n",
            "        \"embeddings_per_chunk\": 10000\n",
            "    }\n",
            "[NeMo I 2024-11-13 13:23:38 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2024-11-13 13:23:38 clustering_diarizer:313] Split long audio file to avoid CUDA memory issue\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "splitting manifest: 100%|| 1/1 [00:00<00:00,  9.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:23:38 classification_models:293] Perform streaming frame-level VAD\n",
            "[NeMo I 2024-11-13 13:23:38 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-11-13 13:23:38 collections:741] Dataset successfully loaded with 25 items and total duration provided from manifest is  0.34 hours.\n",
            "[NeMo I 2024-11-13 13:23:38 collections:746] # 25 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "vad:   0%|          | 0/25 [00:00<?, ?it/s][NeMo W 2024-11-13 13:23:38 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/collections/asr/models/clustering_diarizer.py:226: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "      with autocast():\n",
            "    \n",
            "[NeMo W 2024-11-13 13:23:38 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/collections/asr/parts/preprocessing/features.py:436: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "      with torch.cuda.amp.autocast(enabled=False):\n",
            "    \n",
            "vad: 100%|| 25/25 [00:05<00:00,  4.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:23:43 clustering_diarizer:254] Generating predictions with overlapping input segments\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "                                                               "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:23:55 clustering_diarizer:266] Converting frame level prediction to speech/no-speech segment in start and end times format.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "creating speech segments: 100%|| 1/1 [00:00<00:00,  1.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:23:56 clustering_diarizer:291] Subsegmentation for embedding extraction: scale0, /content/temp_outputs/speaker_outputs/subsegments_scale0.json\n",
            "[NeMo I 2024-11-13 13:23:56 clustering_diarizer:347] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-11-13 13:23:56 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-11-13 13:23:56 collections:741] Dataset successfully loaded with 1010 items and total duration provided from manifest is  0.20 hours.\n",
            "[NeMo I 2024-11-13 13:23:56 collections:746] # 1010 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[1/5] extract embeddings:   0%|          | 0/16 [00:00<?, ?it/s][NeMo W 2024-11-13 13:23:56 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/collections/asr/models/clustering_diarizer.py:362: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "      with autocast():\n",
            "    \n",
            "[NeMo W 2024-11-13 13:23:56 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/collections/asr/parts/submodules/jasper.py:476: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "      with torch.cuda.amp.autocast(enabled=False):\n",
            "    \n",
            "[1/5] extract embeddings: 100%|| 16/16 [00:01<00:00,  9.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:23:58 clustering_diarizer:393] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-11-13 13:23:58 clustering_diarizer:291] Subsegmentation for embedding extraction: scale1, /content/temp_outputs/speaker_outputs/subsegments_scale1.json\n",
            "[NeMo I 2024-11-13 13:23:58 clustering_diarizer:347] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-11-13 13:23:58 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-11-13 13:23:58 collections:741] Dataset successfully loaded with 1106 items and total duration provided from manifest is  0.21 hours.\n",
            "[NeMo I 2024-11-13 13:23:58 collections:746] # 1106 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[2/5] extract embeddings: 100%|| 18/18 [00:01<00:00, 12.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:23:59 clustering_diarizer:393] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-11-13 13:23:59 clustering_diarizer:291] Subsegmentation for embedding extraction: scale2, /content/temp_outputs/speaker_outputs/subsegments_scale2.json\n",
            "[NeMo I 2024-11-13 13:23:59 clustering_diarizer:347] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-11-13 13:23:59 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-11-13 13:23:59 collections:741] Dataset successfully loaded with 1254 items and total duration provided from manifest is  0.22 hours.\n",
            "[NeMo I 2024-11-13 13:23:59 collections:746] # 1254 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[3/5] extract embeddings: 100%|| 20/20 [00:01<00:00, 11.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:24:03 clustering_diarizer:393] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-11-13 13:24:03 clustering_diarizer:291] Subsegmentation for embedding extraction: scale3, /content/temp_outputs/speaker_outputs/subsegments_scale3.json\n",
            "[NeMo I 2024-11-13 13:24:03 clustering_diarizer:347] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-11-13 13:24:03 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-11-13 13:24:03 collections:741] Dataset successfully loaded with 1536 items and total duration provided from manifest is  0.24 hours.\n",
            "[NeMo I 2024-11-13 13:24:03 collections:746] # 1536 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[4/5] extract embeddings: 100%|| 24/24 [00:01<00:00, 15.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:24:04 clustering_diarizer:393] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-11-13 13:24:04 clustering_diarizer:291] Subsegmentation for embedding extraction: scale4, /content/temp_outputs/speaker_outputs/subsegments_scale4.json\n",
            "[NeMo I 2024-11-13 13:24:04 clustering_diarizer:347] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-11-13 13:24:04 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-11-13 13:24:04 collections:741] Dataset successfully loaded with 2203 items and total duration provided from manifest is  0.26 hours.\n",
            "[NeMo I 2024-11-13 13:24:04 collections:746] # 2203 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[5/5] extract embeddings: 100%|| 35/35 [00:01<00:00, 17.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:24:07 clustering_diarizer:393] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "clustering: 100%|| 1/1 [00:00<00:00,  1.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:24:07 clustering_diarizer:461] Outputs are saved in /content/temp_outputs directory\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[NeMo W 2024-11-13 13:24:07 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:24:08 msdd_models:966] Loading embedding pickle file of scale:0 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale0_embeddings.pkl\n",
            "[NeMo I 2024-11-13 13:24:08 msdd_models:966] Loading embedding pickle file of scale:1 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale1_embeddings.pkl\n",
            "[NeMo I 2024-11-13 13:24:08 msdd_models:966] Loading embedding pickle file of scale:2 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale2_embeddings.pkl\n",
            "[NeMo I 2024-11-13 13:24:08 msdd_models:966] Loading embedding pickle file of scale:3 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale3_embeddings.pkl\n",
            "[NeMo I 2024-11-13 13:24:08 msdd_models:966] Loading embedding pickle file of scale:4 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale4_embeddings.pkl\n",
            "[NeMo I 2024-11-13 13:24:08 msdd_models:944] Loading cluster label file from /content/temp_outputs/speaker_outputs/subsegments_scale4_cluster.label\n",
            "[NeMo I 2024-11-13 13:24:08 collections:1067] Filtered duration for loading collection is 0.000000.\n",
            "[NeMo I 2024-11-13 13:24:08 collections:1071] Total 10 session files loaded accounting to # 10 audio clips\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/1 [00:00<?, ?it/s][NeMo W 2024-11-13 13:24:09 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/collections/asr/models/msdd_models.py:1333: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "      with autocast():\n",
            "    \n",
            "100%|| 1/1 [00:00<00:00,  1.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:24:09 msdd_models:1407]      [Threshold: 0.7000] [use_clus_as_main=False] [diar_window=50]\n",
            "[NeMo I 2024-11-13 13:24:09 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2024-11-13 13:24:09 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[NeMo W 2024-11-13 13:24:09 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:24:09 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-11-13 13:24:09 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:24:09 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-11-13 13:24:09 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:24:09 msdd_models:1435]   \n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Punctuation restoration is not available for ru language. Using the original punctuation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:27:15 msdd_models:1097] Loading pretrained diar_msdd_telephonic model from NGC\n",
            "[NeMo I 2024-11-13 13:27:15 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_2.0.0rc1/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
            "[NeMo I 2024-11-13 13:27:15 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_2.0.0rc1/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo\n",
            "[NeMo I 2024-11-13 13:27:15 common:826] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-11-13 13:27:17 modelPT:176] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: true\n",
            "    \n",
            "[NeMo W 2024-11-13 13:27:17 modelPT:183] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    \n",
            "[NeMo W 2024-11-13 13:27:17 modelPT:189] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    seq_eval_mode: false\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:27:17 features:305] PADDING: 16\n",
            "[NeMo I 2024-11-13 13:27:17 features:305] PADDING: 16\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-11-13 13:27:17 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/core/connectors/save_restore_connector.py:617: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "      return torch.load(model_weights, map_location='cpu')\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:27:19 save_restore_connector:272] Model EncDecDiarLabelModel was successfully restored from /root/.cache/torch/NeMo/NeMo_2.0.0rc1/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
            "[NeMo I 2024-11-13 13:27:19 features:305] PADDING: 16\n",
            "[NeMo I 2024-11-13 13:27:20 clustering_diarizer:127] Loading pretrained vad_multilingual_marblenet model from NGC\n",
            "[NeMo I 2024-11-13 13:27:20 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_2.0.0rc1/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
            "[NeMo I 2024-11-13 13:27:20 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_2.0.0rc1/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo\n",
            "[NeMo I 2024-11-13 13:27:20 common:826] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-11-13 13:27:20 modelPT:176] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: /manifests/ami_train_0.63.json,/manifests/freesound_background_train.json,/manifests/freesound_laughter_train.json,/manifests/fisher_2004_background.json,/manifests/fisher_2004_speech_sampled.json,/manifests/google_train_manifest.json,/manifests/icsi_all_0.63.json,/manifests/musan_freesound_train.json,/manifests/musan_music_train.json,/manifests/musan_soundbible_train.json,/manifests/mandarin_train_sample.json,/manifests/german_train_sample.json,/manifests/spanish_train_sample.json,/manifests/french_train_sample.json,/manifests/russian_train_sample.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: true\n",
            "    is_tarred: false\n",
            "    tarred_audio_filepaths: null\n",
            "    tarred_shard_strategy: scatter\n",
            "    augmentor:\n",
            "      shift:\n",
            "        prob: 0.5\n",
            "        min_shift_ms: -10.0\n",
            "        max_shift_ms: 10.0\n",
            "      white_noise:\n",
            "        prob: 0.5\n",
            "        min_level: -90\n",
            "        max_level: -46\n",
            "        norm: true\n",
            "      noise:\n",
            "        prob: 0.5\n",
            "        manifest_path: /manifests/noise_0_1_musan_fs.json\n",
            "        min_snr_db: 0\n",
            "        max_snr_db: 30\n",
            "        max_gain_db: 300.0\n",
            "        norm: true\n",
            "      gain:\n",
            "        prob: 0.5\n",
            "        min_gain_dbfs: -10.0\n",
            "        max_gain_dbfs: 10.0\n",
            "        norm: true\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2024-11-13 13:27:20 modelPT:183] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: /manifests/ami_dev_0.63.json,/manifests/freesound_background_dev.json,/manifests/freesound_laughter_dev.json,/manifests/ch120_moved_0.63.json,/manifests/fisher_2005_500_speech_sampled.json,/manifests/google_dev_manifest.json,/manifests/musan_music_dev.json,/manifests/mandarin_dev.json,/manifests/german_dev.json,/manifests/spanish_dev.json,/manifests/french_dev.json,/manifests/russian_dev.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: false\n",
            "    val_loss_idx: 0\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2024-11-13 13:27:20 modelPT:189] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 128\n",
            "    shuffle: false\n",
            "    test_loss_idx: 0\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:27:20 features:305] PADDING: 16\n",
            "[NeMo I 2024-11-13 13:27:20 save_restore_connector:272] Model EncDecClassificationModel was successfully restored from /root/.cache/torch/NeMo/NeMo_2.0.0rc1/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
            "[NeMo I 2024-11-13 13:27:20 msdd_models:870] Multiscale Weights: [1, 1, 1, 1, 1]\n",
            "[NeMo I 2024-11-13 13:27:20 msdd_models:871] Clustering Parameters: {\n",
            "        \"oracle_num_speakers\": false,\n",
            "        \"max_num_speakers\": 8,\n",
            "        \"enhanced_count_thres\": 80,\n",
            "        \"max_rp_threshold\": 0.25,\n",
            "        \"sparse_search_volume\": 30,\n",
            "        \"maj_vote_spk_count\": false,\n",
            "        \"chunk_cluster_count\": 50,\n",
            "        \"embeddings_per_chunk\": 10000\n",
            "    }\n",
            "[NeMo I 2024-11-13 13:27:20 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2024-11-13 13:27:20 clustering_diarizer:313] Split long audio file to avoid CUDA memory issue\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "splitting manifest: 100%|| 1/1 [00:00<00:00, 11.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:27:20 classification_models:293] Perform streaming frame-level VAD\n",
            "[NeMo I 2024-11-13 13:27:20 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-11-13 13:27:20 collections:741] Dataset successfully loaded with 22 items and total duration provided from manifest is  0.29 hours.\n",
            "[NeMo I 2024-11-13 13:27:20 collections:746] # 22 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "vad:   0%|          | 0/22 [00:00<?, ?it/s][NeMo W 2024-11-13 13:27:20 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/collections/asr/models/clustering_diarizer.py:226: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "      with autocast():\n",
            "    \n",
            "[NeMo W 2024-11-13 13:27:20 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/collections/asr/parts/preprocessing/features.py:436: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "      with torch.cuda.amp.autocast(enabled=False):\n",
            "    \n",
            "vad: 100%|| 22/22 [00:05<00:00,  4.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:27:26 clustering_diarizer:254] Generating predictions with overlapping input segments\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "                                                               "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:27:34 clustering_diarizer:266] Converting frame level prediction to speech/no-speech segment in start and end times format.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "creating speech segments: 100%|| 1/1 [00:00<00:00,  1.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:27:35 clustering_diarizer:291] Subsegmentation for embedding extraction: scale0, /content/temp_outputs/speaker_outputs/subsegments_scale0.json\n",
            "[NeMo I 2024-11-13 13:27:35 clustering_diarizer:347] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-11-13 13:27:35 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-11-13 13:27:35 collections:741] Dataset successfully loaded with 852 items and total duration provided from manifest is  0.19 hours.\n",
            "[NeMo I 2024-11-13 13:27:35 collections:746] # 852 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[1/5] extract embeddings:   0%|          | 0/14 [00:00<?, ?it/s][NeMo W 2024-11-13 13:27:35 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/collections/asr/models/clustering_diarizer.py:362: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "      with autocast():\n",
            "    \n",
            "[NeMo W 2024-11-13 13:27:35 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/collections/asr/parts/submodules/jasper.py:476: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "      with torch.cuda.amp.autocast(enabled=False):\n",
            "    \n",
            "[1/5] extract embeddings: 100%|| 14/14 [00:01<00:00,  8.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:27:37 clustering_diarizer:393] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-11-13 13:27:37 clustering_diarizer:291] Subsegmentation for embedding extraction: scale1, /content/temp_outputs/speaker_outputs/subsegments_scale1.json\n",
            "[NeMo I 2024-11-13 13:27:37 clustering_diarizer:347] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-11-13 13:27:37 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-11-13 13:27:37 collections:741] Dataset successfully loaded with 949 items and total duration provided from manifest is  0.20 hours.\n",
            "[NeMo I 2024-11-13 13:27:37 collections:746] # 949 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[2/5] extract embeddings: 100%|| 15/15 [00:01<00:00,  9.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:27:39 clustering_diarizer:393] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-11-13 13:27:39 clustering_diarizer:291] Subsegmentation for embedding extraction: scale2, /content/temp_outputs/speaker_outputs/subsegments_scale2.json\n",
            "[NeMo I 2024-11-13 13:27:39 clustering_diarizer:347] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-11-13 13:27:39 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-11-13 13:27:39 collections:741] Dataset successfully loaded with 1096 items and total duration provided from manifest is  0.21 hours.\n",
            "[NeMo I 2024-11-13 13:27:39 collections:746] # 1096 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[3/5] extract embeddings: 100%|| 18/18 [00:01<00:00, 13.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:27:40 clustering_diarizer:393] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:27:40 clustering_diarizer:291] Subsegmentation for embedding extraction: scale3, /content/temp_outputs/speaker_outputs/subsegments_scale3.json\n",
            "[NeMo I 2024-11-13 13:27:40 clustering_diarizer:347] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-11-13 13:27:40 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-11-13 13:27:40 collections:741] Dataset successfully loaded with 1390 items and total duration provided from manifest is  0.23 hours.\n",
            "[NeMo I 2024-11-13 13:27:40 collections:746] # 1390 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[4/5] extract embeddings: 100%|| 22/22 [00:01<00:00, 16.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:27:42 clustering_diarizer:393] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-11-13 13:27:42 clustering_diarizer:291] Subsegmentation for embedding extraction: scale4, /content/temp_outputs/speaker_outputs/subsegments_scale4.json\n",
            "[NeMo I 2024-11-13 13:27:42 clustering_diarizer:347] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-11-13 13:27:42 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-11-13 13:27:42 collections:741] Dataset successfully loaded with 2055 items and total duration provided from manifest is  0.25 hours.\n",
            "[NeMo I 2024-11-13 13:27:42 collections:746] # 2055 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[5/5] extract embeddings: 100%|| 33/33 [00:01<00:00, 17.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:27:44 clustering_diarizer:393] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "clustering: 100%|| 1/1 [00:00<00:00,  1.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:27:45 clustering_diarizer:461] Outputs are saved in /content/temp_outputs directory\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[NeMo W 2024-11-13 13:27:45 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:27:45 msdd_models:966] Loading embedding pickle file of scale:0 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale0_embeddings.pkl\n",
            "[NeMo I 2024-11-13 13:27:45 msdd_models:966] Loading embedding pickle file of scale:1 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale1_embeddings.pkl\n",
            "[NeMo I 2024-11-13 13:27:45 msdd_models:966] Loading embedding pickle file of scale:2 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale2_embeddings.pkl\n",
            "[NeMo I 2024-11-13 13:27:45 msdd_models:966] Loading embedding pickle file of scale:3 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale3_embeddings.pkl\n",
            "[NeMo I 2024-11-13 13:27:45 msdd_models:966] Loading embedding pickle file of scale:4 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale4_embeddings.pkl\n",
            "[NeMo I 2024-11-13 13:27:45 msdd_models:944] Loading cluster label file from /content/temp_outputs/speaker_outputs/subsegments_scale4_cluster.label\n",
            "[NeMo I 2024-11-13 13:27:45 collections:1067] Filtered duration for loading collection is 0.000000.\n",
            "[NeMo I 2024-11-13 13:27:45 collections:1071] Total 1 session files loaded accounting to # 1 audio clips\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/1 [00:00<?, ?it/s][NeMo W 2024-11-13 13:27:45 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/collections/asr/models/msdd_models.py:1333: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "      with autocast():\n",
            "    \n",
            "100%|| 1/1 [00:00<00:00, 14.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:27:45 msdd_models:1407]      [Threshold: 0.7000] [use_clus_as_main=False] [diar_window=50]\n",
            "[NeMo I 2024-11-13 13:27:45 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2024-11-13 13:27:45 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[NeMo W 2024-11-13 13:27:45 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:27:45 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-11-13 13:27:45 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:27:45 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-11-13 13:27:45 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:27:45 msdd_models:1435]   \n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Punctuation restoration is not available for ru language. Using the original punctuation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:29:54 msdd_models:1097] Loading pretrained diar_msdd_telephonic model from NGC\n",
            "[NeMo I 2024-11-13 13:29:54 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_2.0.0rc1/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
            "[NeMo I 2024-11-13 13:29:54 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_2.0.0rc1/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo\n",
            "[NeMo I 2024-11-13 13:29:54 common:826] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-11-13 13:29:56 modelPT:176] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: true\n",
            "    \n",
            "[NeMo W 2024-11-13 13:29:56 modelPT:183] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    \n",
            "[NeMo W 2024-11-13 13:29:56 modelPT:189] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    seq_eval_mode: false\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:29:56 features:305] PADDING: 16\n",
            "[NeMo I 2024-11-13 13:29:56 features:305] PADDING: 16\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-11-13 13:29:57 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/core/connectors/save_restore_connector.py:617: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "      return torch.load(model_weights, map_location='cpu')\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:29:57 save_restore_connector:272] Model EncDecDiarLabelModel was successfully restored from /root/.cache/torch/NeMo/NeMo_2.0.0rc1/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
            "[NeMo I 2024-11-13 13:29:57 features:305] PADDING: 16\n",
            "[NeMo I 2024-11-13 13:29:57 clustering_diarizer:127] Loading pretrained vad_multilingual_marblenet model from NGC\n",
            "[NeMo I 2024-11-13 13:29:57 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_2.0.0rc1/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
            "[NeMo I 2024-11-13 13:29:57 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_2.0.0rc1/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo\n",
            "[NeMo I 2024-11-13 13:29:57 common:826] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-11-13 13:29:57 modelPT:176] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: /manifests/ami_train_0.63.json,/manifests/freesound_background_train.json,/manifests/freesound_laughter_train.json,/manifests/fisher_2004_background.json,/manifests/fisher_2004_speech_sampled.json,/manifests/google_train_manifest.json,/manifests/icsi_all_0.63.json,/manifests/musan_freesound_train.json,/manifests/musan_music_train.json,/manifests/musan_soundbible_train.json,/manifests/mandarin_train_sample.json,/manifests/german_train_sample.json,/manifests/spanish_train_sample.json,/manifests/french_train_sample.json,/manifests/russian_train_sample.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: true\n",
            "    is_tarred: false\n",
            "    tarred_audio_filepaths: null\n",
            "    tarred_shard_strategy: scatter\n",
            "    augmentor:\n",
            "      shift:\n",
            "        prob: 0.5\n",
            "        min_shift_ms: -10.0\n",
            "        max_shift_ms: 10.0\n",
            "      white_noise:\n",
            "        prob: 0.5\n",
            "        min_level: -90\n",
            "        max_level: -46\n",
            "        norm: true\n",
            "      noise:\n",
            "        prob: 0.5\n",
            "        manifest_path: /manifests/noise_0_1_musan_fs.json\n",
            "        min_snr_db: 0\n",
            "        max_snr_db: 30\n",
            "        max_gain_db: 300.0\n",
            "        norm: true\n",
            "      gain:\n",
            "        prob: 0.5\n",
            "        min_gain_dbfs: -10.0\n",
            "        max_gain_dbfs: 10.0\n",
            "        norm: true\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2024-11-13 13:29:57 modelPT:183] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: /manifests/ami_dev_0.63.json,/manifests/freesound_background_dev.json,/manifests/freesound_laughter_dev.json,/manifests/ch120_moved_0.63.json,/manifests/fisher_2005_500_speech_sampled.json,/manifests/google_dev_manifest.json,/manifests/musan_music_dev.json,/manifests/mandarin_dev.json,/manifests/german_dev.json,/manifests/spanish_dev.json,/manifests/french_dev.json,/manifests/russian_dev.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: false\n",
            "    val_loss_idx: 0\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2024-11-13 13:29:57 modelPT:189] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 128\n",
            "    shuffle: false\n",
            "    test_loss_idx: 0\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:29:58 features:305] PADDING: 16\n",
            "[NeMo I 2024-11-13 13:29:58 save_restore_connector:272] Model EncDecClassificationModel was successfully restored from /root/.cache/torch/NeMo/NeMo_2.0.0rc1/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
            "[NeMo I 2024-11-13 13:29:58 msdd_models:870] Multiscale Weights: [1, 1, 1, 1, 1]\n",
            "[NeMo I 2024-11-13 13:29:58 msdd_models:871] Clustering Parameters: {\n",
            "        \"oracle_num_speakers\": false,\n",
            "        \"max_num_speakers\": 8,\n",
            "        \"enhanced_count_thres\": 80,\n",
            "        \"max_rp_threshold\": 0.25,\n",
            "        \"sparse_search_volume\": 30,\n",
            "        \"maj_vote_spk_count\": false,\n",
            "        \"chunk_cluster_count\": 50,\n",
            "        \"embeddings_per_chunk\": 10000\n",
            "    }\n",
            "[NeMo I 2024-11-13 13:29:58 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2024-11-13 13:29:58 clustering_diarizer:313] Split long audio file to avoid CUDA memory issue\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "splitting manifest: 100%|| 1/1 [00:00<00:00, 16.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:29:58 classification_models:293] Perform streaming frame-level VAD\n",
            "[NeMo I 2024-11-13 13:29:58 collections:740] Filtered duration for loading collection is  0.00 hours.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:29:58 collections:741] Dataset successfully loaded with 14 items and total duration provided from manifest is  0.19 hours.\n",
            "[NeMo I 2024-11-13 13:29:58 collections:746] # 14 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rvad:   0%|          | 0/14 [00:00<?, ?it/s][NeMo W 2024-11-13 13:29:58 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/collections/asr/models/clustering_diarizer.py:226: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "      with autocast():\n",
            "    \n",
            "[NeMo W 2024-11-13 13:29:58 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/collections/asr/parts/preprocessing/features.py:436: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "      with torch.cuda.amp.autocast(enabled=False):\n",
            "    \n",
            "vad: 100%|| 14/14 [00:02<00:00,  4.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:30:01 clustering_diarizer:254] Generating predictions with overlapping input segments\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "                                                               "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:30:08 clustering_diarizer:266] Converting frame level prediction to speech/no-speech segment in start and end times format.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "creating speech segments: 100%|| 1/1 [00:00<00:00,  2.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:30:08 clustering_diarizer:291] Subsegmentation for embedding extraction: scale0, /content/temp_outputs/speaker_outputs/subsegments_scale0.json\n",
            "[NeMo I 2024-11-13 13:30:08 clustering_diarizer:347] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-11-13 13:30:08 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-11-13 13:30:08 collections:741] Dataset successfully loaded with 503 items and total duration provided from manifest is  0.07 hours.\n",
            "[NeMo I 2024-11-13 13:30:08 collections:746] # 503 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[1/5] extract embeddings:   0%|          | 0/8 [00:00<?, ?it/s][NeMo W 2024-11-13 13:30:08 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/collections/asr/models/clustering_diarizer.py:362: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "      with autocast():\n",
            "    \n",
            "[NeMo W 2024-11-13 13:30:08 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/collections/asr/parts/submodules/jasper.py:476: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "      with torch.cuda.amp.autocast(enabled=False):\n",
            "    \n",
            "[1/5] extract embeddings: 100%|| 8/8 [00:00<00:00,  9.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:30:09 clustering_diarizer:393] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-11-13 13:30:09 clustering_diarizer:291] Subsegmentation for embedding extraction: scale1, /content/temp_outputs/speaker_outputs/subsegments_scale1.json\n",
            "[NeMo I 2024-11-13 13:30:09 clustering_diarizer:347] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-11-13 13:30:09 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-11-13 13:30:09 collections:741] Dataset successfully loaded with 526 items and total duration provided from manifest is  0.08 hours.\n",
            "[NeMo I 2024-11-13 13:30:09 collections:746] # 526 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[2/5] extract embeddings: 100%|| 9/9 [00:00<00:00, 13.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:30:10 clustering_diarizer:393] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-11-13 13:30:10 clustering_diarizer:291] Subsegmentation for embedding extraction: scale2, /content/temp_outputs/speaker_outputs/subsegments_scale2.json\n",
            "[NeMo I 2024-11-13 13:30:10 clustering_diarizer:347] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-11-13 13:30:10 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-11-13 13:30:10 collections:741] Dataset successfully loaded with 571 items and total duration provided from manifest is  0.08 hours.\n",
            "[NeMo I 2024-11-13 13:30:10 collections:746] # 571 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[3/5] extract embeddings: 100%|| 9/9 [00:00<00:00, 12.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:30:11 clustering_diarizer:393] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-11-13 13:30:11 clustering_diarizer:291] Subsegmentation for embedding extraction: scale3, /content/temp_outputs/speaker_outputs/subsegments_scale3.json\n",
            "[NeMo I 2024-11-13 13:30:11 clustering_diarizer:347] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-11-13 13:30:11 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-11-13 13:30:11 collections:741] Dataset successfully loaded with 657 items and total duration provided from manifest is  0.09 hours.\n",
            "[NeMo I 2024-11-13 13:30:11 collections:746] # 657 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[4/5] extract embeddings: 100%|| 11/11 [00:00<00:00, 17.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:30:11 clustering_diarizer:393] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-11-13 13:30:11 clustering_diarizer:291] Subsegmentation for embedding extraction: scale4, /content/temp_outputs/speaker_outputs/subsegments_scale4.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:30:11 clustering_diarizer:347] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-11-13 13:30:11 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-11-13 13:30:11 collections:741] Dataset successfully loaded with 880 items and total duration provided from manifest is  0.09 hours.\n",
            "[NeMo I 2024-11-13 13:30:11 collections:746] # 880 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[5/5] extract embeddings: 100%|| 14/14 [00:00<00:00, 17.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:30:12 clustering_diarizer:393] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "clustering: 100%|| 1/1 [00:00<00:00,  1.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:30:13 clustering_diarizer:461] Outputs are saved in /content/temp_outputs directory\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[NeMo W 2024-11-13 13:30:13 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:30:13 msdd_models:966] Loading embedding pickle file of scale:0 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale0_embeddings.pkl\n",
            "[NeMo I 2024-11-13 13:30:13 msdd_models:966] Loading embedding pickle file of scale:1 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale1_embeddings.pkl\n",
            "[NeMo I 2024-11-13 13:30:13 msdd_models:966] Loading embedding pickle file of scale:2 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale2_embeddings.pkl\n",
            "[NeMo I 2024-11-13 13:30:13 msdd_models:966] Loading embedding pickle file of scale:3 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale3_embeddings.pkl\n",
            "[NeMo I 2024-11-13 13:30:13 msdd_models:966] Loading embedding pickle file of scale:4 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale4_embeddings.pkl\n",
            "[NeMo I 2024-11-13 13:30:13 msdd_models:944] Loading cluster label file from /content/temp_outputs/speaker_outputs/subsegments_scale4_cluster.label\n",
            "[NeMo I 2024-11-13 13:30:13 collections:1067] Filtered duration for loading collection is 0.000000.\n",
            "[NeMo I 2024-11-13 13:30:13 collections:1071] Total 1 session files loaded accounting to # 1 audio clips\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/1 [00:00<?, ?it/s][NeMo W 2024-11-13 13:30:13 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/collections/asr/models/msdd_models.py:1333: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "      with autocast():\n",
            "    \n",
            "100%|| 1/1 [00:00<00:00, 23.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:30:13 msdd_models:1407]      [Threshold: 0.7000] [use_clus_as_main=False] [diar_window=50]\n",
            "[NeMo I 2024-11-13 13:30:13 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2024-11-13 13:30:13 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[NeMo W 2024-11-13 13:30:13 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:30:13 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-11-13 13:30:13 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:30:13 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-11-13 13:30:13 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:30:13 msdd_models:1435]   \n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Punctuation restoration is not available for ru language. Using the original punctuation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:31:35 msdd_models:1097] Loading pretrained diar_msdd_telephonic model from NGC\n",
            "[NeMo I 2024-11-13 13:31:35 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_2.0.0rc1/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
            "[NeMo I 2024-11-13 13:31:35 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_2.0.0rc1/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo\n",
            "[NeMo I 2024-11-13 13:31:35 common:826] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-11-13 13:31:37 modelPT:176] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: true\n",
            "    \n",
            "[NeMo W 2024-11-13 13:31:37 modelPT:183] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    \n",
            "[NeMo W 2024-11-13 13:31:37 modelPT:189] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    seq_eval_mode: false\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:31:37 features:305] PADDING: 16\n",
            "[NeMo I 2024-11-13 13:31:37 features:305] PADDING: 16\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-11-13 13:31:38 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/core/connectors/save_restore_connector.py:617: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "      return torch.load(model_weights, map_location='cpu')\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:31:38 save_restore_connector:272] Model EncDecDiarLabelModel was successfully restored from /root/.cache/torch/NeMo/NeMo_2.0.0rc1/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
            "[NeMo I 2024-11-13 13:31:39 features:305] PADDING: 16\n",
            "[NeMo I 2024-11-13 13:31:39 clustering_diarizer:127] Loading pretrained vad_multilingual_marblenet model from NGC\n",
            "[NeMo I 2024-11-13 13:31:39 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_2.0.0rc1/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
            "[NeMo I 2024-11-13 13:31:39 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_2.0.0rc1/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo\n",
            "[NeMo I 2024-11-13 13:31:39 common:826] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-11-13 13:31:40 modelPT:176] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: /manifests/ami_train_0.63.json,/manifests/freesound_background_train.json,/manifests/freesound_laughter_train.json,/manifests/fisher_2004_background.json,/manifests/fisher_2004_speech_sampled.json,/manifests/google_train_manifest.json,/manifests/icsi_all_0.63.json,/manifests/musan_freesound_train.json,/manifests/musan_music_train.json,/manifests/musan_soundbible_train.json,/manifests/mandarin_train_sample.json,/manifests/german_train_sample.json,/manifests/spanish_train_sample.json,/manifests/french_train_sample.json,/manifests/russian_train_sample.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: true\n",
            "    is_tarred: false\n",
            "    tarred_audio_filepaths: null\n",
            "    tarred_shard_strategy: scatter\n",
            "    augmentor:\n",
            "      shift:\n",
            "        prob: 0.5\n",
            "        min_shift_ms: -10.0\n",
            "        max_shift_ms: 10.0\n",
            "      white_noise:\n",
            "        prob: 0.5\n",
            "        min_level: -90\n",
            "        max_level: -46\n",
            "        norm: true\n",
            "      noise:\n",
            "        prob: 0.5\n",
            "        manifest_path: /manifests/noise_0_1_musan_fs.json\n",
            "        min_snr_db: 0\n",
            "        max_snr_db: 30\n",
            "        max_gain_db: 300.0\n",
            "        norm: true\n",
            "      gain:\n",
            "        prob: 0.5\n",
            "        min_gain_dbfs: -10.0\n",
            "        max_gain_dbfs: 10.0\n",
            "        norm: true\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2024-11-13 13:31:40 modelPT:183] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: /manifests/ami_dev_0.63.json,/manifests/freesound_background_dev.json,/manifests/freesound_laughter_dev.json,/manifests/ch120_moved_0.63.json,/manifests/fisher_2005_500_speech_sampled.json,/manifests/google_dev_manifest.json,/manifests/musan_music_dev.json,/manifests/mandarin_dev.json,/manifests/german_dev.json,/manifests/spanish_dev.json,/manifests/french_dev.json,/manifests/russian_dev.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: false\n",
            "    val_loss_idx: 0\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2024-11-13 13:31:40 modelPT:189] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 128\n",
            "    shuffle: false\n",
            "    test_loss_idx: 0\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:31:40 features:305] PADDING: 16\n",
            "[NeMo I 2024-11-13 13:31:40 save_restore_connector:272] Model EncDecClassificationModel was successfully restored from /root/.cache/torch/NeMo/NeMo_2.0.0rc1/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
            "[NeMo I 2024-11-13 13:31:40 msdd_models:870] Multiscale Weights: [1, 1, 1, 1, 1]\n",
            "[NeMo I 2024-11-13 13:31:40 msdd_models:871] Clustering Parameters: {\n",
            "        \"oracle_num_speakers\": false,\n",
            "        \"max_num_speakers\": 8,\n",
            "        \"enhanced_count_thres\": 80,\n",
            "        \"max_rp_threshold\": 0.25,\n",
            "        \"sparse_search_volume\": 30,\n",
            "        \"maj_vote_spk_count\": false,\n",
            "        \"chunk_cluster_count\": 50,\n",
            "        \"embeddings_per_chunk\": 10000\n",
            "    }\n",
            "[NeMo I 2024-11-13 13:31:40 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2024-11-13 13:31:40 clustering_diarizer:313] Split long audio file to avoid CUDA memory issue\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "splitting manifest: 100%|| 1/1 [00:00<00:00, 25.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:31:40 classification_models:293] Perform streaming frame-level VAD\n",
            "[NeMo I 2024-11-13 13:31:40 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-11-13 13:31:40 collections:741] Dataset successfully loaded with 8 items and total duration provided from manifest is  0.10 hours.\n",
            "[NeMo I 2024-11-13 13:31:40 collections:746] # 8 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rvad:   0%|          | 0/8 [00:00<?, ?it/s][NeMo W 2024-11-13 13:31:40 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/collections/asr/models/clustering_diarizer.py:226: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "      with autocast():\n",
            "    \n",
            "[NeMo W 2024-11-13 13:31:40 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/collections/asr/parts/preprocessing/features.py:436: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "      with torch.cuda.amp.autocast(enabled=False):\n",
            "    \n",
            "vad: 100%|| 8/8 [00:01<00:00,  4.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:31:41 clustering_diarizer:254] Generating predictions with overlapping input segments\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "                                                               "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:31:44 clustering_diarizer:266] Converting frame level prediction to speech/no-speech segment in start and end times format.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "creating speech segments: 100%|| 1/1 [00:00<00:00,  3.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:31:45 clustering_diarizer:291] Subsegmentation for embedding extraction: scale0, /content/temp_outputs/speaker_outputs/subsegments_scale0.json\n",
            "[NeMo I 2024-11-13 13:31:45 clustering_diarizer:347] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-11-13 13:31:45 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-11-13 13:31:45 collections:741] Dataset successfully loaded with 297 items and total duration provided from manifest is  0.06 hours.\n",
            "[NeMo I 2024-11-13 13:31:45 collections:746] # 297 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[1/5] extract embeddings:   0%|          | 0/5 [00:00<?, ?it/s][NeMo W 2024-11-13 13:31:45 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/collections/asr/models/clustering_diarizer.py:362: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "      with autocast():\n",
            "    \n",
            "[NeMo W 2024-11-13 13:31:45 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/collections/asr/parts/submodules/jasper.py:476: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "      with torch.cuda.amp.autocast(enabled=False):\n",
            "    \n",
            "[1/5] extract embeddings: 100%|| 5/5 [00:00<00:00,  8.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:31:45 clustering_diarizer:393] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-11-13 13:31:45 clustering_diarizer:291] Subsegmentation for embedding extraction: scale1, /content/temp_outputs/speaker_outputs/subsegments_scale1.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:31:45 clustering_diarizer:347] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-11-13 13:31:45 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-11-13 13:31:45 collections:741] Dataset successfully loaded with 326 items and total duration provided from manifest is  0.07 hours.\n",
            "[NeMo I 2024-11-13 13:31:45 collections:746] # 326 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[2/5] extract embeddings: 100%|| 6/6 [00:00<00:00, 13.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:31:46 clustering_diarizer:393] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-11-13 13:31:46 clustering_diarizer:291] Subsegmentation for embedding extraction: scale2, /content/temp_outputs/speaker_outputs/subsegments_scale2.json\n",
            "[NeMo I 2024-11-13 13:31:46 clustering_diarizer:347] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-11-13 13:31:46 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-11-13 13:31:46 collections:741] Dataset successfully loaded with 382 items and total duration provided from manifest is  0.07 hours.\n",
            "[NeMo I 2024-11-13 13:31:46 collections:746] # 382 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[3/5] extract embeddings: 100%|| 6/6 [00:00<00:00, 12.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:31:46 clustering_diarizer:393] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-11-13 13:31:46 clustering_diarizer:291] Subsegmentation for embedding extraction: scale3, /content/temp_outputs/speaker_outputs/subsegments_scale3.json\n",
            "[NeMo I 2024-11-13 13:31:46 clustering_diarizer:347] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-11-13 13:31:46 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-11-13 13:31:46 collections:741] Dataset successfully loaded with 470 items and total duration provided from manifest is  0.08 hours.\n",
            "[NeMo I 2024-11-13 13:31:46 collections:746] # 470 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[4/5] extract embeddings: 100%|| 8/8 [00:00<00:00, 16.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:31:47 clustering_diarizer:393] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-11-13 13:31:47 clustering_diarizer:291] Subsegmentation for embedding extraction: scale4, /content/temp_outputs/speaker_outputs/subsegments_scale4.json\n",
            "[NeMo I 2024-11-13 13:31:47 clustering_diarizer:347] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-11-13 13:31:47 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-11-13 13:31:47 collections:741] Dataset successfully loaded with 692 items and total duration provided from manifest is  0.08 hours.\n",
            "[NeMo I 2024-11-13 13:31:47 collections:746] # 692 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[5/5] extract embeddings: 100%|| 11/11 [00:00<00:00, 17.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:31:47 clustering_diarizer:393] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "clustering: 100%|| 1/1 [00:00<00:00,  2.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:31:48 clustering_diarizer:461] Outputs are saved in /content/temp_outputs directory\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[NeMo W 2024-11-13 13:31:48 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:31:48 msdd_models:966] Loading embedding pickle file of scale:0 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale0_embeddings.pkl\n",
            "[NeMo I 2024-11-13 13:31:48 msdd_models:966] Loading embedding pickle file of scale:1 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale1_embeddings.pkl\n",
            "[NeMo I 2024-11-13 13:31:48 msdd_models:966] Loading embedding pickle file of scale:2 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale2_embeddings.pkl\n",
            "[NeMo I 2024-11-13 13:31:48 msdd_models:966] Loading embedding pickle file of scale:3 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale3_embeddings.pkl\n",
            "[NeMo I 2024-11-13 13:31:48 msdd_models:966] Loading embedding pickle file of scale:4 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale4_embeddings.pkl\n",
            "[NeMo I 2024-11-13 13:31:48 msdd_models:944] Loading cluster label file from /content/temp_outputs/speaker_outputs/subsegments_scale4_cluster.label\n",
            "[NeMo I 2024-11-13 13:31:48 collections:1067] Filtered duration for loading collection is 0.000000.\n",
            "[NeMo I 2024-11-13 13:31:48 collections:1071] Total 1 session files loaded accounting to # 1 audio clips\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/1 [00:00<?, ?it/s][NeMo W 2024-11-13 13:31:48 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/collections/asr/models/msdd_models.py:1333: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "      with autocast():\n",
            "    \n",
            "100%|| 1/1 [00:00<00:00, 23.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:31:48 msdd_models:1407]      [Threshold: 0.7000] [use_clus_as_main=False] [diar_window=50]\n",
            "[NeMo I 2024-11-13 13:31:48 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2024-11-13 13:31:48 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[NeMo W 2024-11-13 13:31:48 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:31:48 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-11-13 13:31:48 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:31:48 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-11-13 13:31:48 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:31:48 msdd_models:1435]   \n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Punctuation restoration is not available for ru language. Using the original punctuation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:33:49 msdd_models:1097] Loading pretrained diar_msdd_telephonic model from NGC\n",
            "[NeMo I 2024-11-13 13:33:49 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_2.0.0rc1/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
            "[NeMo I 2024-11-13 13:33:49 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_2.0.0rc1/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo\n",
            "[NeMo I 2024-11-13 13:33:49 common:826] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-11-13 13:33:51 modelPT:176] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: true\n",
            "    \n",
            "[NeMo W 2024-11-13 13:33:51 modelPT:183] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    \n",
            "[NeMo W 2024-11-13 13:33:51 modelPT:189] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    seq_eval_mode: false\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:33:51 features:305] PADDING: 16\n",
            "[NeMo I 2024-11-13 13:33:51 features:305] PADDING: 16\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-11-13 13:33:52 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/core/connectors/save_restore_connector.py:617: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "      return torch.load(model_weights, map_location='cpu')\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:33:52 save_restore_connector:272] Model EncDecDiarLabelModel was successfully restored from /root/.cache/torch/NeMo/NeMo_2.0.0rc1/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
            "[NeMo I 2024-11-13 13:33:52 features:305] PADDING: 16\n",
            "[NeMo I 2024-11-13 13:33:53 clustering_diarizer:127] Loading pretrained vad_multilingual_marblenet model from NGC\n",
            "[NeMo I 2024-11-13 13:33:53 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_2.0.0rc1/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
            "[NeMo I 2024-11-13 13:33:53 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_2.0.0rc1/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo\n",
            "[NeMo I 2024-11-13 13:33:53 common:826] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-11-13 13:33:53 modelPT:176] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: /manifests/ami_train_0.63.json,/manifests/freesound_background_train.json,/manifests/freesound_laughter_train.json,/manifests/fisher_2004_background.json,/manifests/fisher_2004_speech_sampled.json,/manifests/google_train_manifest.json,/manifests/icsi_all_0.63.json,/manifests/musan_freesound_train.json,/manifests/musan_music_train.json,/manifests/musan_soundbible_train.json,/manifests/mandarin_train_sample.json,/manifests/german_train_sample.json,/manifests/spanish_train_sample.json,/manifests/french_train_sample.json,/manifests/russian_train_sample.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: true\n",
            "    is_tarred: false\n",
            "    tarred_audio_filepaths: null\n",
            "    tarred_shard_strategy: scatter\n",
            "    augmentor:\n",
            "      shift:\n",
            "        prob: 0.5\n",
            "        min_shift_ms: -10.0\n",
            "        max_shift_ms: 10.0\n",
            "      white_noise:\n",
            "        prob: 0.5\n",
            "        min_level: -90\n",
            "        max_level: -46\n",
            "        norm: true\n",
            "      noise:\n",
            "        prob: 0.5\n",
            "        manifest_path: /manifests/noise_0_1_musan_fs.json\n",
            "        min_snr_db: 0\n",
            "        max_snr_db: 30\n",
            "        max_gain_db: 300.0\n",
            "        norm: true\n",
            "      gain:\n",
            "        prob: 0.5\n",
            "        min_gain_dbfs: -10.0\n",
            "        max_gain_dbfs: 10.0\n",
            "        norm: true\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2024-11-13 13:33:53 modelPT:183] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: /manifests/ami_dev_0.63.json,/manifests/freesound_background_dev.json,/manifests/freesound_laughter_dev.json,/manifests/ch120_moved_0.63.json,/manifests/fisher_2005_500_speech_sampled.json,/manifests/google_dev_manifest.json,/manifests/musan_music_dev.json,/manifests/mandarin_dev.json,/manifests/german_dev.json,/manifests/spanish_dev.json,/manifests/french_dev.json,/manifests/russian_dev.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: false\n",
            "    val_loss_idx: 0\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2024-11-13 13:33:53 modelPT:189] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 128\n",
            "    shuffle: false\n",
            "    test_loss_idx: 0\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:33:53 features:305] PADDING: 16\n",
            "[NeMo I 2024-11-13 13:33:54 save_restore_connector:272] Model EncDecClassificationModel was successfully restored from /root/.cache/torch/NeMo/NeMo_2.0.0rc1/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
            "[NeMo I 2024-11-13 13:33:54 msdd_models:870] Multiscale Weights: [1, 1, 1, 1, 1]\n",
            "[NeMo I 2024-11-13 13:33:54 msdd_models:871] Clustering Parameters: {\n",
            "        \"oracle_num_speakers\": false,\n",
            "        \"max_num_speakers\": 8,\n",
            "        \"enhanced_count_thres\": 80,\n",
            "        \"max_rp_threshold\": 0.25,\n",
            "        \"sparse_search_volume\": 30,\n",
            "        \"maj_vote_spk_count\": false,\n",
            "        \"chunk_cluster_count\": 50,\n",
            "        \"embeddings_per_chunk\": 10000\n",
            "    }\n",
            "[NeMo I 2024-11-13 13:33:54 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2024-11-13 13:33:54 clustering_diarizer:313] Split long audio file to avoid CUDA memory issue\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "splitting manifest: 100%|| 1/1 [00:00<00:00, 15.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:33:54 classification_models:293] Perform streaming frame-level VAD\n",
            "[NeMo I 2024-11-13 13:33:54 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-11-13 13:33:54 collections:741] Dataset successfully loaded with 13 items and total duration provided from manifest is  0.17 hours.\n",
            "[NeMo I 2024-11-13 13:33:54 collections:746] # 13 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "vad:   0%|          | 0/13 [00:00<?, ?it/s][NeMo W 2024-11-13 13:33:54 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/collections/asr/models/clustering_diarizer.py:226: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "      with autocast():\n",
            "    \n",
            "[NeMo W 2024-11-13 13:33:54 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/collections/asr/parts/preprocessing/features.py:436: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "      with torch.cuda.amp.autocast(enabled=False):\n",
            "    \n",
            "vad: 100%|| 13/13 [00:02<00:00,  4.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:33:57 clustering_diarizer:254] Generating predictions with overlapping input segments\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "                                                               "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:34:01 clustering_diarizer:266] Converting frame level prediction to speech/no-speech segment in start and end times format.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "creating speech segments: 100%|| 1/1 [00:00<00:00,  2.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:34:02 clustering_diarizer:291] Subsegmentation for embedding extraction: scale0, /content/temp_outputs/speaker_outputs/subsegments_scale0.json\n",
            "[NeMo I 2024-11-13 13:34:02 clustering_diarizer:347] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-11-13 13:34:02 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-11-13 13:34:02 collections:741] Dataset successfully loaded with 487 items and total duration provided from manifest is  0.09 hours.\n",
            "[NeMo I 2024-11-13 13:34:02 collections:746] # 487 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[1/5] extract embeddings:   0%|          | 0/8 [00:00<?, ?it/s][NeMo W 2024-11-13 13:34:02 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/collections/asr/models/clustering_diarizer.py:362: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "      with autocast():\n",
            "    \n",
            "[NeMo W 2024-11-13 13:34:02 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/collections/asr/parts/submodules/jasper.py:476: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "      with torch.cuda.amp.autocast(enabled=False):\n",
            "    \n",
            "[1/5] extract embeddings: 100%|| 8/8 [00:00<00:00,  9.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:34:03 clustering_diarizer:393] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-11-13 13:34:03 clustering_diarizer:291] Subsegmentation for embedding extraction: scale1, /content/temp_outputs/speaker_outputs/subsegments_scale1.json\n",
            "[NeMo I 2024-11-13 13:34:03 clustering_diarizer:347] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-11-13 13:34:03 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-11-13 13:34:03 collections:741] Dataset successfully loaded with 528 items and total duration provided from manifest is  0.09 hours.\n",
            "[NeMo I 2024-11-13 13:34:03 collections:746] # 528 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[2/5] extract embeddings: 100%|| 9/9 [00:00<00:00, 12.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:34:04 clustering_diarizer:393] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-11-13 13:34:04 clustering_diarizer:291] Subsegmentation for embedding extraction: scale2, /content/temp_outputs/speaker_outputs/subsegments_scale2.json\n",
            "[NeMo I 2024-11-13 13:34:04 clustering_diarizer:347] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-11-13 13:34:04 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-11-13 13:34:04 collections:741] Dataset successfully loaded with 589 items and total duration provided from manifest is  0.10 hours.\n",
            "[NeMo I 2024-11-13 13:34:04 collections:746] # 589 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[3/5] extract embeddings: 100%|| 10/10 [00:00<00:00, 12.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:34:05 clustering_diarizer:393] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-11-13 13:34:05 clustering_diarizer:291] Subsegmentation for embedding extraction: scale3, /content/temp_outputs/speaker_outputs/subsegments_scale3.json\n",
            "[NeMo I 2024-11-13 13:34:05 clustering_diarizer:347] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-11-13 13:34:05 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-11-13 13:34:05 collections:741] Dataset successfully loaded with 712 items and total duration provided from manifest is  0.11 hours.\n",
            "[NeMo I 2024-11-13 13:34:05 collections:746] # 712 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[4/5] extract embeddings: 100%|| 12/12 [00:00<00:00, 14.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:34:06 clustering_diarizer:393] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-11-13 13:34:06 clustering_diarizer:291] Subsegmentation for embedding extraction: scale4, /content/temp_outputs/speaker_outputs/subsegments_scale4.json\n",
            "[NeMo I 2024-11-13 13:34:06 clustering_diarizer:347] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-11-13 13:34:06 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-11-13 13:34:06 collections:741] Dataset successfully loaded with 1015 items and total duration provided from manifest is  0.12 hours.\n",
            "[NeMo I 2024-11-13 13:34:06 collections:746] # 1015 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[5/5] extract embeddings: 100%|| 16/16 [00:01<00:00, 12.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:34:08 clustering_diarizer:393] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "clustering: 100%|| 1/1 [00:00<00:00,  1.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:34:09 clustering_diarizer:461] Outputs are saved in /content/temp_outputs directory\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[NeMo W 2024-11-13 13:34:09 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:34:09 msdd_models:966] Loading embedding pickle file of scale:0 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale0_embeddings.pkl\n",
            "[NeMo I 2024-11-13 13:34:09 msdd_models:966] Loading embedding pickle file of scale:1 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale1_embeddings.pkl\n",
            "[NeMo I 2024-11-13 13:34:09 msdd_models:966] Loading embedding pickle file of scale:2 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale2_embeddings.pkl\n",
            "[NeMo I 2024-11-13 13:34:09 msdd_models:966] Loading embedding pickle file of scale:3 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale3_embeddings.pkl\n",
            "[NeMo I 2024-11-13 13:34:09 msdd_models:966] Loading embedding pickle file of scale:4 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale4_embeddings.pkl\n",
            "[NeMo I 2024-11-13 13:34:09 msdd_models:944] Loading cluster label file from /content/temp_outputs/speaker_outputs/subsegments_scale4_cluster.label\n",
            "[NeMo I 2024-11-13 13:34:09 collections:1067] Filtered duration for loading collection is 0.000000.\n",
            "[NeMo I 2024-11-13 13:34:09 collections:1071] Total 1 session files loaded accounting to # 1 audio clips\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/1 [00:00<?, ?it/s][NeMo W 2024-11-13 13:34:09 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/collections/asr/models/msdd_models.py:1333: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "      with autocast():\n",
            "    \n",
            "100%|| 1/1 [00:00<00:00, 16.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:34:09 msdd_models:1407]      [Threshold: 0.7000] [use_clus_as_main=False] [diar_window=50]\n",
            "[NeMo I 2024-11-13 13:34:09 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2024-11-13 13:34:09 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[NeMo W 2024-11-13 13:34:09 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:34:09 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-11-13 13:34:09 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:34:09 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-11-13 13:34:09 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:34:09 msdd_models:1435]   \n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Punctuation restoration is not available for ru language. Using the original punctuation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:40:08 msdd_models:1097] Loading pretrained diar_msdd_telephonic model from NGC\n",
            "[NeMo I 2024-11-13 13:40:08 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_2.0.0rc1/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
            "[NeMo I 2024-11-13 13:40:08 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_2.0.0rc1/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo\n",
            "[NeMo I 2024-11-13 13:40:08 common:826] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-11-13 13:40:13 modelPT:176] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: true\n",
            "    \n",
            "[NeMo W 2024-11-13 13:40:13 modelPT:183] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    \n",
            "[NeMo W 2024-11-13 13:40:13 modelPT:189] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    seq_eval_mode: false\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:40:13 features:305] PADDING: 16\n",
            "[NeMo I 2024-11-13 13:40:13 features:305] PADDING: 16\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-11-13 13:40:14 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/core/connectors/save_restore_connector.py:617: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "      return torch.load(model_weights, map_location='cpu')\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:40:14 save_restore_connector:272] Model EncDecDiarLabelModel was successfully restored from /root/.cache/torch/NeMo/NeMo_2.0.0rc1/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
            "[NeMo I 2024-11-13 13:40:14 features:305] PADDING: 16\n",
            "[NeMo I 2024-11-13 13:40:14 clustering_diarizer:127] Loading pretrained vad_multilingual_marblenet model from NGC\n",
            "[NeMo I 2024-11-13 13:40:14 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_2.0.0rc1/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
            "[NeMo I 2024-11-13 13:40:14 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_2.0.0rc1/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo\n",
            "[NeMo I 2024-11-13 13:40:14 common:826] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-11-13 13:40:15 modelPT:176] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: /manifests/ami_train_0.63.json,/manifests/freesound_background_train.json,/manifests/freesound_laughter_train.json,/manifests/fisher_2004_background.json,/manifests/fisher_2004_speech_sampled.json,/manifests/google_train_manifest.json,/manifests/icsi_all_0.63.json,/manifests/musan_freesound_train.json,/manifests/musan_music_train.json,/manifests/musan_soundbible_train.json,/manifests/mandarin_train_sample.json,/manifests/german_train_sample.json,/manifests/spanish_train_sample.json,/manifests/french_train_sample.json,/manifests/russian_train_sample.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: true\n",
            "    is_tarred: false\n",
            "    tarred_audio_filepaths: null\n",
            "    tarred_shard_strategy: scatter\n",
            "    augmentor:\n",
            "      shift:\n",
            "        prob: 0.5\n",
            "        min_shift_ms: -10.0\n",
            "        max_shift_ms: 10.0\n",
            "      white_noise:\n",
            "        prob: 0.5\n",
            "        min_level: -90\n",
            "        max_level: -46\n",
            "        norm: true\n",
            "      noise:\n",
            "        prob: 0.5\n",
            "        manifest_path: /manifests/noise_0_1_musan_fs.json\n",
            "        min_snr_db: 0\n",
            "        max_snr_db: 30\n",
            "        max_gain_db: 300.0\n",
            "        norm: true\n",
            "      gain:\n",
            "        prob: 0.5\n",
            "        min_gain_dbfs: -10.0\n",
            "        max_gain_dbfs: 10.0\n",
            "        norm: true\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2024-11-13 13:40:15 modelPT:183] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: /manifests/ami_dev_0.63.json,/manifests/freesound_background_dev.json,/manifests/freesound_laughter_dev.json,/manifests/ch120_moved_0.63.json,/manifests/fisher_2005_500_speech_sampled.json,/manifests/google_dev_manifest.json,/manifests/musan_music_dev.json,/manifests/mandarin_dev.json,/manifests/german_dev.json,/manifests/spanish_dev.json,/manifests/french_dev.json,/manifests/russian_dev.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: false\n",
            "    val_loss_idx: 0\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2024-11-13 13:40:15 modelPT:189] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 128\n",
            "    shuffle: false\n",
            "    test_loss_idx: 0\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:40:15 features:305] PADDING: 16\n",
            "[NeMo I 2024-11-13 13:40:15 save_restore_connector:272] Model EncDecClassificationModel was successfully restored from /root/.cache/torch/NeMo/NeMo_2.0.0rc1/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
            "[NeMo I 2024-11-13 13:40:15 msdd_models:870] Multiscale Weights: [1, 1, 1, 1, 1]\n",
            "[NeMo I 2024-11-13 13:40:15 msdd_models:871] Clustering Parameters: {\n",
            "        \"oracle_num_speakers\": false,\n",
            "        \"max_num_speakers\": 8,\n",
            "        \"enhanced_count_thres\": 80,\n",
            "        \"max_rp_threshold\": 0.25,\n",
            "        \"sparse_search_volume\": 30,\n",
            "        \"maj_vote_spk_count\": false,\n",
            "        \"chunk_cluster_count\": 50,\n",
            "        \"embeddings_per_chunk\": 10000\n",
            "    }\n",
            "[NeMo I 2024-11-13 13:40:15 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2024-11-13 13:40:15 clustering_diarizer:313] Split long audio file to avoid CUDA memory issue\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "splitting manifest: 100%|| 1/1 [00:00<00:00,  4.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:40:15 classification_models:293] Perform streaming frame-level VAD\n",
            "[NeMo I 2024-11-13 13:40:15 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-11-13 13:40:15 collections:741] Dataset successfully loaded with 38 items and total duration provided from manifest is  0.52 hours.\n",
            "[NeMo I 2024-11-13 13:40:15 collections:746] # 38 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "vad:   0%|          | 0/38 [00:00<?, ?it/s][NeMo W 2024-11-13 13:40:15 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/collections/asr/models/clustering_diarizer.py:226: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "      with autocast():\n",
            "    \n",
            "[NeMo W 2024-11-13 13:40:15 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/collections/asr/parts/preprocessing/features.py:436: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "      with torch.cuda.amp.autocast(enabled=False):\n",
            "    \n",
            "vad: 100%|| 38/38 [00:08<00:00,  4.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:40:24 clustering_diarizer:254] Generating predictions with overlapping input segments\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "                                                               "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:40:40 clustering_diarizer:266] Converting frame level prediction to speech/no-speech segment in start and end times format.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "creating speech segments: 100%|| 1/1 [00:01<00:00,  1.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:40:42 clustering_diarizer:291] Subsegmentation for embedding extraction: scale0, /content/temp_outputs/speaker_outputs/subsegments_scale0.json\n",
            "[NeMo I 2024-11-13 13:40:42 clustering_diarizer:347] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-11-13 13:40:42 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-11-13 13:40:42 collections:741] Dataset successfully loaded with 1407 items and total duration provided from manifest is  0.39 hours.\n",
            "[NeMo I 2024-11-13 13:40:42 collections:746] # 1407 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[1/5] extract embeddings:   0%|          | 0/22 [00:00<?, ?it/s][NeMo W 2024-11-13 13:40:42 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/collections/asr/models/clustering_diarizer.py:362: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "      with autocast():\n",
            "    \n",
            "[NeMo W 2024-11-13 13:40:42 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/collections/asr/parts/submodules/jasper.py:476: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "      with torch.cuda.amp.autocast(enabled=False):\n",
            "    \n",
            "[1/5] extract embeddings: 100%|| 22/22 [00:02<00:00,  9.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:40:44 clustering_diarizer:393] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-11-13 13:40:44 clustering_diarizer:291] Subsegmentation for embedding extraction: scale1, /content/temp_outputs/speaker_outputs/subsegments_scale1.json\n",
            "[NeMo I 2024-11-13 13:40:45 clustering_diarizer:347] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-11-13 13:40:45 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-11-13 13:40:45 collections:741] Dataset successfully loaded with 1619 items and total duration provided from manifest is  0.41 hours.\n",
            "[NeMo I 2024-11-13 13:40:45 collections:746] # 1619 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[2/5] extract embeddings: 100%|| 26/26 [00:02<00:00, 11.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:40:48 clustering_diarizer:393] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-11-13 13:40:48 clustering_diarizer:291] Subsegmentation for embedding extraction: scale2, /content/temp_outputs/speaker_outputs/subsegments_scale2.json\n",
            "[NeMo I 2024-11-13 13:40:48 clustering_diarizer:347] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-11-13 13:40:48 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-11-13 13:40:48 collections:741] Dataset successfully loaded with 1949 items and total duration provided from manifest is  0.43 hours.\n",
            "[NeMo I 2024-11-13 13:40:48 collections:746] # 1949 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[3/5] extract embeddings: 100%|| 31/31 [00:02<00:00, 10.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:40:51 clustering_diarizer:393] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-11-13 13:40:51 clustering_diarizer:291] Subsegmentation for embedding extraction: scale3, /content/temp_outputs/speaker_outputs/subsegments_scale3.json\n",
            "[NeMo I 2024-11-13 13:40:51 clustering_diarizer:347] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-11-13 13:40:51 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-11-13 13:40:51 collections:741] Dataset successfully loaded with 2558 items and total duration provided from manifest is  0.46 hours.\n",
            "[NeMo I 2024-11-13 13:40:51 collections:746] # 2558 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[4/5] extract embeddings: 100%|| 40/40 [00:02<00:00, 15.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:40:54 clustering_diarizer:393] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-11-13 13:40:54 clustering_diarizer:291] Subsegmentation for embedding extraction: scale4, /content/temp_outputs/speaker_outputs/subsegments_scale4.json\n",
            "[NeMo I 2024-11-13 13:40:54 clustering_diarizer:347] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-11-13 13:40:54 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-11-13 13:40:54 collections:741] Dataset successfully loaded with 3856 items and total duration provided from manifest is  0.49 hours.\n",
            "[NeMo I 2024-11-13 13:40:54 collections:746] # 3856 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[5/5] extract embeddings: 100%|| 61/61 [00:03<00:00, 17.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:40:58 clustering_diarizer:393] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "clustering: 100%|| 1/1 [00:01<00:00,  1.79s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:41:00 clustering_diarizer:461] Outputs are saved in /content/temp_outputs directory\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[NeMo W 2024-11-13 13:41:00 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:41:01 msdd_models:966] Loading embedding pickle file of scale:0 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale0_embeddings.pkl\n",
            "[NeMo I 2024-11-13 13:41:01 msdd_models:966] Loading embedding pickle file of scale:1 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale1_embeddings.pkl\n",
            "[NeMo I 2024-11-13 13:41:01 msdd_models:966] Loading embedding pickle file of scale:2 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale2_embeddings.pkl\n",
            "[NeMo I 2024-11-13 13:41:01 msdd_models:966] Loading embedding pickle file of scale:3 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale3_embeddings.pkl\n",
            "[NeMo I 2024-11-13 13:41:01 msdd_models:966] Loading embedding pickle file of scale:4 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale4_embeddings.pkl\n",
            "[NeMo I 2024-11-13 13:41:01 msdd_models:944] Loading cluster label file from /content/temp_outputs/speaker_outputs/subsegments_scale4_cluster.label\n",
            "[NeMo I 2024-11-13 13:41:02 collections:1067] Filtered duration for loading collection is 0.000000.\n",
            "[NeMo I 2024-11-13 13:41:02 collections:1071] Total 1 session files loaded accounting to # 1 audio clips\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/1 [00:00<?, ?it/s][NeMo W 2024-11-13 13:41:02 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/collections/asr/models/msdd_models.py:1333: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "      with autocast():\n",
            "    \n",
            "100%|| 1/1 [00:00<00:00,  2.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:41:02 msdd_models:1407]      [Threshold: 0.7000] [use_clus_as_main=False] [diar_window=50]\n",
            "[NeMo I 2024-11-13 13:41:02 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2024-11-13 13:41:02 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[NeMo W 2024-11-13 13:41:02 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:41:02 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-11-13 13:41:03 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:41:03 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-11-13 13:41:03 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:41:03 msdd_models:1435]   \n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Punctuation restoration is not available for ru language. Using the original punctuation.\n",
            "WARNING:root:Source splitting failed, using original audio file.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:47:40 msdd_models:1097] Loading pretrained diar_msdd_telephonic model from NGC\n",
            "[NeMo I 2024-11-13 13:47:40 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_2.0.0rc1/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
            "[NeMo I 2024-11-13 13:47:40 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_2.0.0rc1/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo\n",
            "[NeMo I 2024-11-13 13:47:40 common:826] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-11-13 13:47:46 modelPT:176] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: true\n",
            "    \n",
            "[NeMo W 2024-11-13 13:47:46 modelPT:183] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    \n",
            "[NeMo W 2024-11-13 13:47:46 modelPT:189] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    seq_eval_mode: false\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:47:46 features:305] PADDING: 16\n",
            "[NeMo I 2024-11-13 13:47:46 features:305] PADDING: 16\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-11-13 13:47:47 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/core/connectors/save_restore_connector.py:617: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "      return torch.load(model_weights, map_location='cpu')\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:47:47 save_restore_connector:272] Model EncDecDiarLabelModel was successfully restored from /root/.cache/torch/NeMo/NeMo_2.0.0rc1/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
            "[NeMo I 2024-11-13 13:47:47 features:305] PADDING: 16\n",
            "[NeMo I 2024-11-13 13:47:47 clustering_diarizer:127] Loading pretrained vad_multilingual_marblenet model from NGC\n",
            "[NeMo I 2024-11-13 13:47:47 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_2.0.0rc1/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
            "[NeMo I 2024-11-13 13:47:47 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_2.0.0rc1/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo\n",
            "[NeMo I 2024-11-13 13:47:47 common:826] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-11-13 13:47:48 modelPT:176] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: /manifests/ami_train_0.63.json,/manifests/freesound_background_train.json,/manifests/freesound_laughter_train.json,/manifests/fisher_2004_background.json,/manifests/fisher_2004_speech_sampled.json,/manifests/google_train_manifest.json,/manifests/icsi_all_0.63.json,/manifests/musan_freesound_train.json,/manifests/musan_music_train.json,/manifests/musan_soundbible_train.json,/manifests/mandarin_train_sample.json,/manifests/german_train_sample.json,/manifests/spanish_train_sample.json,/manifests/french_train_sample.json,/manifests/russian_train_sample.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: true\n",
            "    is_tarred: false\n",
            "    tarred_audio_filepaths: null\n",
            "    tarred_shard_strategy: scatter\n",
            "    augmentor:\n",
            "      shift:\n",
            "        prob: 0.5\n",
            "        min_shift_ms: -10.0\n",
            "        max_shift_ms: 10.0\n",
            "      white_noise:\n",
            "        prob: 0.5\n",
            "        min_level: -90\n",
            "        max_level: -46\n",
            "        norm: true\n",
            "      noise:\n",
            "        prob: 0.5\n",
            "        manifest_path: /manifests/noise_0_1_musan_fs.json\n",
            "        min_snr_db: 0\n",
            "        max_snr_db: 30\n",
            "        max_gain_db: 300.0\n",
            "        norm: true\n",
            "      gain:\n",
            "        prob: 0.5\n",
            "        min_gain_dbfs: -10.0\n",
            "        max_gain_dbfs: 10.0\n",
            "        norm: true\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2024-11-13 13:47:48 modelPT:183] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: /manifests/ami_dev_0.63.json,/manifests/freesound_background_dev.json,/manifests/freesound_laughter_dev.json,/manifests/ch120_moved_0.63.json,/manifests/fisher_2005_500_speech_sampled.json,/manifests/google_dev_manifest.json,/manifests/musan_music_dev.json,/manifests/mandarin_dev.json,/manifests/german_dev.json,/manifests/spanish_dev.json,/manifests/french_dev.json,/manifests/russian_dev.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: false\n",
            "    val_loss_idx: 0\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2024-11-13 13:47:48 modelPT:189] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 128\n",
            "    shuffle: false\n",
            "    test_loss_idx: 0\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:47:48 features:305] PADDING: 16\n",
            "[NeMo I 2024-11-13 13:47:48 save_restore_connector:272] Model EncDecClassificationModel was successfully restored from /root/.cache/torch/NeMo/NeMo_2.0.0rc1/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
            "[NeMo I 2024-11-13 13:47:48 msdd_models:870] Multiscale Weights: [1, 1, 1, 1, 1]\n",
            "[NeMo I 2024-11-13 13:47:48 msdd_models:871] Clustering Parameters: {\n",
            "        \"oracle_num_speakers\": false,\n",
            "        \"max_num_speakers\": 8,\n",
            "        \"enhanced_count_thres\": 80,\n",
            "        \"max_rp_threshold\": 0.25,\n",
            "        \"sparse_search_volume\": 30,\n",
            "        \"maj_vote_spk_count\": false,\n",
            "        \"chunk_cluster_count\": 50,\n",
            "        \"embeddings_per_chunk\": 10000\n",
            "    }\n",
            "[NeMo I 2024-11-13 13:47:48 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2024-11-13 13:47:48 clustering_diarizer:313] Split long audio file to avoid CUDA memory issue\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "splitting manifest: 100%|| 1/1 [00:00<00:00,  4.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:47:48 classification_models:293] Perform streaming frame-level VAD\n",
            "[NeMo I 2024-11-13 13:47:48 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-11-13 13:47:48 collections:741] Dataset successfully loaded with 53 items and total duration provided from manifest is  0.73 hours.\n",
            "[NeMo I 2024-11-13 13:47:48 collections:746] # 53 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "vad:   0%|          | 0/53 [00:00<?, ?it/s][NeMo W 2024-11-13 13:47:48 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/collections/asr/models/clustering_diarizer.py:226: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "      with autocast():\n",
            "    \n",
            "[NeMo W 2024-11-13 13:47:48 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/collections/asr/parts/preprocessing/features.py:436: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "      with torch.cuda.amp.autocast(enabled=False):\n",
            "    \n",
            "vad: 100%|| 53/53 [00:12<00:00,  4.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:48:01 clustering_diarizer:254] Generating predictions with overlapping input segments\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "                                                               "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:48:25 clustering_diarizer:266] Converting frame level prediction to speech/no-speech segment in start and end times format.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "creating speech segments: 100%|| 1/1 [00:02<00:00,  2.75s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:48:28 clustering_diarizer:291] Subsegmentation for embedding extraction: scale0, /content/temp_outputs/speaker_outputs/subsegments_scale0.json\n",
            "[NeMo I 2024-11-13 13:48:28 clustering_diarizer:347] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-11-13 13:48:28 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-11-13 13:48:28 collections:741] Dataset successfully loaded with 1457 items and total duration provided from manifest is  0.13 hours.\n",
            "[NeMo I 2024-11-13 13:48:28 collections:746] # 1457 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[1/5] extract embeddings:   0%|          | 0/23 [00:00<?, ?it/s][NeMo W 2024-11-13 13:48:28 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/collections/asr/models/clustering_diarizer.py:362: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "      with autocast():\n",
            "    \n",
            "[NeMo W 2024-11-13 13:48:28 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/collections/asr/parts/submodules/jasper.py:476: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "      with torch.cuda.amp.autocast(enabled=False):\n",
            "    \n",
            "[1/5] extract embeddings: 100%|| 23/23 [00:02<00:00, 10.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:48:30 clustering_diarizer:393] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-11-13 13:48:30 clustering_diarizer:291] Subsegmentation for embedding extraction: scale1, /content/temp_outputs/speaker_outputs/subsegments_scale1.json\n",
            "[NeMo I 2024-11-13 13:48:31 clustering_diarizer:347] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-11-13 13:48:31 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-11-13 13:48:31 collections:741] Dataset successfully loaded with 1478 items and total duration provided from manifest is  0.14 hours.\n",
            "[NeMo I 2024-11-13 13:48:31 collections:746] # 1478 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[2/5] extract embeddings: 100%|| 24/24 [00:01<00:00, 13.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:48:33 clustering_diarizer:393] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-11-13 13:48:33 clustering_diarizer:291] Subsegmentation for embedding extraction: scale2, /content/temp_outputs/speaker_outputs/subsegments_scale2.json\n",
            "[NeMo I 2024-11-13 13:48:33 clustering_diarizer:347] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-11-13 13:48:33 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-11-13 13:48:33 collections:741] Dataset successfully loaded with 1512 items and total duration provided from manifest is  0.14 hours.\n",
            "[NeMo I 2024-11-13 13:48:33 collections:746] # 1512 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[3/5] extract embeddings: 100%|| 24/24 [00:01<00:00, 13.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:48:35 clustering_diarizer:393] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-11-13 13:48:35 clustering_diarizer:291] Subsegmentation for embedding extraction: scale3, /content/temp_outputs/speaker_outputs/subsegments_scale3.json\n",
            "[NeMo I 2024-11-13 13:48:35 clustering_diarizer:347] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-11-13 13:48:35 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-11-13 13:48:35 collections:741] Dataset successfully loaded with 1595 items and total duration provided from manifest is  0.15 hours.\n",
            "[NeMo I 2024-11-13 13:48:35 collections:746] # 1595 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[4/5] extract embeddings: 100%|| 25/25 [00:01<00:00, 16.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:48:36 clustering_diarizer:393] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-11-13 13:48:36 clustering_diarizer:291] Subsegmentation for embedding extraction: scale4, /content/temp_outputs/speaker_outputs/subsegments_scale4.json\n",
            "[NeMo I 2024-11-13 13:48:36 clustering_diarizer:347] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-11-13 13:48:36 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-11-13 13:48:36 collections:741] Dataset successfully loaded with 1904 items and total duration provided from manifest is  0.16 hours.\n",
            "[NeMo I 2024-11-13 13:48:36 collections:746] # 1904 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[5/5] extract embeddings: 100%|| 30/30 [00:01<00:00, 16.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:48:39 clustering_diarizer:393] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "clustering: 100%|| 1/1 [00:01<00:00,  1.24s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:48:40 clustering_diarizer:461] Outputs are saved in /content/temp_outputs directory\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[NeMo W 2024-11-13 13:48:40 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:48:40 msdd_models:966] Loading embedding pickle file of scale:0 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale0_embeddings.pkl\n",
            "[NeMo I 2024-11-13 13:48:40 msdd_models:966] Loading embedding pickle file of scale:1 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale1_embeddings.pkl\n",
            "[NeMo I 2024-11-13 13:48:40 msdd_models:966] Loading embedding pickle file of scale:2 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale2_embeddings.pkl\n",
            "[NeMo I 2024-11-13 13:48:40 msdd_models:966] Loading embedding pickle file of scale:3 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale3_embeddings.pkl\n",
            "[NeMo I 2024-11-13 13:48:40 msdd_models:966] Loading embedding pickle file of scale:4 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale4_embeddings.pkl\n",
            "[NeMo I 2024-11-13 13:48:40 msdd_models:944] Loading cluster label file from /content/temp_outputs/speaker_outputs/subsegments_scale4_cluster.label\n",
            "[NeMo I 2024-11-13 13:48:41 collections:1067] Filtered duration for loading collection is 0.000000.\n",
            "[NeMo I 2024-11-13 13:48:41 collections:1071] Total 1 session files loaded accounting to # 1 audio clips\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/1 [00:00<?, ?it/s][NeMo W 2024-11-13 13:48:41 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/collections/asr/models/msdd_models.py:1333: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "      with autocast():\n",
            "    \n",
            "100%|| 1/1 [00:00<00:00,  7.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:48:41 msdd_models:1407]      [Threshold: 0.7000] [use_clus_as_main=False] [diar_window=50]\n",
            "[NeMo I 2024-11-13 13:48:41 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2024-11-13 13:48:41 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[NeMo W 2024-11-13 13:48:41 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:48:41 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-11-13 13:48:41 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:48:41 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-11-13 13:48:41 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:48:41 msdd_models:1435]   \n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Punctuation restoration is not available for ru language. Using the original punctuation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:52:17 msdd_models:1097] Loading pretrained diar_msdd_telephonic model from NGC\n",
            "[NeMo I 2024-11-13 13:52:17 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_2.0.0rc1/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
            "[NeMo I 2024-11-13 13:52:17 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_2.0.0rc1/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo\n",
            "[NeMo I 2024-11-13 13:52:17 common:826] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-11-13 13:52:18 modelPT:176] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: true\n",
            "    \n",
            "[NeMo W 2024-11-13 13:52:18 modelPT:183] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    \n",
            "[NeMo W 2024-11-13 13:52:18 modelPT:189] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    seq_eval_mode: false\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:52:22 features:305] PADDING: 16\n",
            "[NeMo I 2024-11-13 13:52:22 features:305] PADDING: 16\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-11-13 13:52:23 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/core/connectors/save_restore_connector.py:617: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "      return torch.load(model_weights, map_location='cpu')\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:52:23 save_restore_connector:272] Model EncDecDiarLabelModel was successfully restored from /root/.cache/torch/NeMo/NeMo_2.0.0rc1/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
            "[NeMo I 2024-11-13 13:52:23 features:305] PADDING: 16\n",
            "[NeMo I 2024-11-13 13:52:24 clustering_diarizer:127] Loading pretrained vad_multilingual_marblenet model from NGC\n",
            "[NeMo I 2024-11-13 13:52:24 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_2.0.0rc1/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
            "[NeMo I 2024-11-13 13:52:24 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_2.0.0rc1/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo\n",
            "[NeMo I 2024-11-13 13:52:24 common:826] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-11-13 13:52:24 modelPT:176] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: /manifests/ami_train_0.63.json,/manifests/freesound_background_train.json,/manifests/freesound_laughter_train.json,/manifests/fisher_2004_background.json,/manifests/fisher_2004_speech_sampled.json,/manifests/google_train_manifest.json,/manifests/icsi_all_0.63.json,/manifests/musan_freesound_train.json,/manifests/musan_music_train.json,/manifests/musan_soundbible_train.json,/manifests/mandarin_train_sample.json,/manifests/german_train_sample.json,/manifests/spanish_train_sample.json,/manifests/french_train_sample.json,/manifests/russian_train_sample.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: true\n",
            "    is_tarred: false\n",
            "    tarred_audio_filepaths: null\n",
            "    tarred_shard_strategy: scatter\n",
            "    augmentor:\n",
            "      shift:\n",
            "        prob: 0.5\n",
            "        min_shift_ms: -10.0\n",
            "        max_shift_ms: 10.0\n",
            "      white_noise:\n",
            "        prob: 0.5\n",
            "        min_level: -90\n",
            "        max_level: -46\n",
            "        norm: true\n",
            "      noise:\n",
            "        prob: 0.5\n",
            "        manifest_path: /manifests/noise_0_1_musan_fs.json\n",
            "        min_snr_db: 0\n",
            "        max_snr_db: 30\n",
            "        max_gain_db: 300.0\n",
            "        norm: true\n",
            "      gain:\n",
            "        prob: 0.5\n",
            "        min_gain_dbfs: -10.0\n",
            "        max_gain_dbfs: 10.0\n",
            "        norm: true\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2024-11-13 13:52:24 modelPT:183] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: /manifests/ami_dev_0.63.json,/manifests/freesound_background_dev.json,/manifests/freesound_laughter_dev.json,/manifests/ch120_moved_0.63.json,/manifests/fisher_2005_500_speech_sampled.json,/manifests/google_dev_manifest.json,/manifests/musan_music_dev.json,/manifests/mandarin_dev.json,/manifests/german_dev.json,/manifests/spanish_dev.json,/manifests/french_dev.json,/manifests/russian_dev.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: false\n",
            "    val_loss_idx: 0\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2024-11-13 13:52:24 modelPT:189] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 128\n",
            "    shuffle: false\n",
            "    test_loss_idx: 0\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:52:24 features:305] PADDING: 16\n",
            "[NeMo I 2024-11-13 13:52:24 save_restore_connector:272] Model EncDecClassificationModel was successfully restored from /root/.cache/torch/NeMo/NeMo_2.0.0rc1/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
            "[NeMo I 2024-11-13 13:52:25 msdd_models:870] Multiscale Weights: [1, 1, 1, 1, 1]\n",
            "[NeMo I 2024-11-13 13:52:25 msdd_models:871] Clustering Parameters: {\n",
            "        \"oracle_num_speakers\": false,\n",
            "        \"max_num_speakers\": 8,\n",
            "        \"enhanced_count_thres\": 80,\n",
            "        \"max_rp_threshold\": 0.25,\n",
            "        \"sparse_search_volume\": 30,\n",
            "        \"maj_vote_spk_count\": false,\n",
            "        \"chunk_cluster_count\": 50,\n",
            "        \"embeddings_per_chunk\": 10000\n",
            "    }\n",
            "[NeMo I 2024-11-13 13:52:25 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2024-11-13 13:52:25 clustering_diarizer:313] Split long audio file to avoid CUDA memory issue\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "splitting manifest: 100%|| 1/1 [00:00<00:00,  6.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:52:25 classification_models:293] Perform streaming frame-level VAD\n",
            "[NeMo I 2024-11-13 13:52:25 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-11-13 13:52:25 collections:741] Dataset successfully loaded with 20 items and total duration provided from manifest is  0.27 hours.\n",
            "[NeMo I 2024-11-13 13:52:25 collections:746] # 20 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "vad:   0%|          | 0/20 [00:00<?, ?it/s][NeMo W 2024-11-13 13:52:25 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/collections/asr/models/clustering_diarizer.py:226: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "      with autocast():\n",
            "    \n",
            "[NeMo W 2024-11-13 13:52:25 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/collections/asr/parts/preprocessing/features.py:436: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "      with torch.cuda.amp.autocast(enabled=False):\n",
            "    \n",
            "vad: 100%|| 20/20 [00:04<00:00,  4.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:52:29 clustering_diarizer:254] Generating predictions with overlapping input segments\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "                                                               "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:52:38 clustering_diarizer:266] Converting frame level prediction to speech/no-speech segment in start and end times format.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "creating speech segments: 100%|| 1/1 [00:00<00:00,  1.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:52:39 clustering_diarizer:291] Subsegmentation for embedding extraction: scale0, /content/temp_outputs/speaker_outputs/subsegments_scale0.json\n",
            "[NeMo I 2024-11-13 13:52:39 clustering_diarizer:347] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-11-13 13:52:39 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-11-13 13:52:39 collections:741] Dataset successfully loaded with 809 items and total duration provided from manifest is  0.18 hours.\n",
            "[NeMo I 2024-11-13 13:52:39 collections:746] # 809 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[1/5] extract embeddings:   0%|          | 0/13 [00:00<?, ?it/s][NeMo W 2024-11-13 13:52:39 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/collections/asr/models/clustering_diarizer.py:362: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "      with autocast():\n",
            "    \n",
            "[NeMo W 2024-11-13 13:52:39 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/collections/asr/parts/submodules/jasper.py:476: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "      with torch.cuda.amp.autocast(enabled=False):\n",
            "    \n",
            "[1/5] extract embeddings: 100%|| 13/13 [00:01<00:00,  9.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:52:41 clustering_diarizer:393] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-11-13 13:52:41 clustering_diarizer:291] Subsegmentation for embedding extraction: scale1, /content/temp_outputs/speaker_outputs/subsegments_scale1.json\n",
            "[NeMo I 2024-11-13 13:52:41 clustering_diarizer:347] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-11-13 13:52:41 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-11-13 13:52:41 collections:741] Dataset successfully loaded with 901 items and total duration provided from manifest is  0.19 hours.\n",
            "[NeMo I 2024-11-13 13:52:41 collections:746] # 901 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[2/5] extract embeddings: 100%|| 15/15 [00:01<00:00, 12.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:52:42 clustering_diarizer:393] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-11-13 13:52:42 clustering_diarizer:291] Subsegmentation for embedding extraction: scale2, /content/temp_outputs/speaker_outputs/subsegments_scale2.json\n",
            "[NeMo I 2024-11-13 13:52:42 clustering_diarizer:347] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-11-13 13:52:42 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-11-13 13:52:42 collections:741] Dataset successfully loaded with 1040 items and total duration provided from manifest is  0.20 hours.\n",
            "[NeMo I 2024-11-13 13:52:42 collections:746] # 1040 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[3/5] extract embeddings: 100%|| 17/17 [00:01<00:00, 13.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:52:43 clustering_diarizer:393] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-11-13 13:52:43 clustering_diarizer:291] Subsegmentation for embedding extraction: scale3, /content/temp_outputs/speaker_outputs/subsegments_scale3.json\n",
            "[NeMo I 2024-11-13 13:52:43 clustering_diarizer:347] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-11-13 13:52:43 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-11-13 13:52:43 collections:741] Dataset successfully loaded with 1314 items and total duration provided from manifest is  0.22 hours.\n",
            "[NeMo I 2024-11-13 13:52:43 collections:746] # 1314 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[4/5] extract embeddings: 100%|| 21/21 [00:01<00:00, 15.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:52:45 clustering_diarizer:393] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-11-13 13:52:45 clustering_diarizer:291] Subsegmentation for embedding extraction: scale4, /content/temp_outputs/speaker_outputs/subsegments_scale4.json\n",
            "[NeMo I 2024-11-13 13:52:45 clustering_diarizer:347] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-11-13 13:52:45 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-11-13 13:52:45 collections:741] Dataset successfully loaded with 1941 items and total duration provided from manifest is  0.24 hours.\n",
            "[NeMo I 2024-11-13 13:52:45 collections:746] # 1941 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[5/5] extract embeddings: 100%|| 31/31 [00:01<00:00, 17.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:52:47 clustering_diarizer:393] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "clustering: 100%|| 1/1 [00:00<00:00,  1.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:52:48 clustering_diarizer:461] Outputs are saved in /content/temp_outputs directory\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[NeMo W 2024-11-13 13:52:48 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:52:48 msdd_models:966] Loading embedding pickle file of scale:0 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale0_embeddings.pkl\n",
            "[NeMo I 2024-11-13 13:52:48 msdd_models:966] Loading embedding pickle file of scale:1 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale1_embeddings.pkl\n",
            "[NeMo I 2024-11-13 13:52:48 msdd_models:966] Loading embedding pickle file of scale:2 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale2_embeddings.pkl\n",
            "[NeMo I 2024-11-13 13:52:48 msdd_models:966] Loading embedding pickle file of scale:3 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale3_embeddings.pkl\n",
            "[NeMo I 2024-11-13 13:52:48 msdd_models:966] Loading embedding pickle file of scale:4 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale4_embeddings.pkl\n",
            "[NeMo I 2024-11-13 13:52:48 msdd_models:944] Loading cluster label file from /content/temp_outputs/speaker_outputs/subsegments_scale4_cluster.label\n",
            "[NeMo I 2024-11-13 13:52:48 collections:1067] Filtered duration for loading collection is 0.000000.\n",
            "[NeMo I 2024-11-13 13:52:48 collections:1071] Total 1 session files loaded accounting to # 1 audio clips\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/1 [00:00<?, ?it/s][NeMo W 2024-11-13 13:52:48 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/collections/asr/models/msdd_models.py:1333: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "      with autocast():\n",
            "    \n",
            "100%|| 1/1 [00:00<00:00, 13.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:52:48 msdd_models:1407]      [Threshold: 0.7000] [use_clus_as_main=False] [diar_window=50]\n",
            "[NeMo I 2024-11-13 13:52:48 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2024-11-13 13:52:48 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[NeMo W 2024-11-13 13:52:48 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:52:48 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-11-13 13:52:48 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:52:48 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-11-13 13:52:48 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:52:48 msdd_models:1435]   \n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Punctuation restoration is not available for ru language. Using the original punctuation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:57:44 msdd_models:1097] Loading pretrained diar_msdd_telephonic model from NGC\n",
            "[NeMo I 2024-11-13 13:57:44 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_2.0.0rc1/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
            "[NeMo I 2024-11-13 13:57:44 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_2.0.0rc1/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo\n",
            "[NeMo I 2024-11-13 13:57:44 common:826] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-11-13 13:57:46 modelPT:176] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: true\n",
            "    \n",
            "[NeMo W 2024-11-13 13:57:46 modelPT:183] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    \n",
            "[NeMo W 2024-11-13 13:57:46 modelPT:189] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    seq_eval_mode: false\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:57:46 features:305] PADDING: 16\n",
            "[NeMo I 2024-11-13 13:57:46 features:305] PADDING: 16\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-11-13 13:57:47 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/core/connectors/save_restore_connector.py:617: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "      return torch.load(model_weights, map_location='cpu')\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:57:47 save_restore_connector:272] Model EncDecDiarLabelModel was successfully restored from /root/.cache/torch/NeMo/NeMo_2.0.0rc1/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
            "[NeMo I 2024-11-13 13:57:47 features:305] PADDING: 16\n",
            "[NeMo I 2024-11-13 13:57:48 clustering_diarizer:127] Loading pretrained vad_multilingual_marblenet model from NGC\n",
            "[NeMo I 2024-11-13 13:57:48 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_2.0.0rc1/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
            "[NeMo I 2024-11-13 13:57:48 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_2.0.0rc1/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo\n",
            "[NeMo I 2024-11-13 13:57:48 common:826] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-11-13 13:57:48 modelPT:176] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: /manifests/ami_train_0.63.json,/manifests/freesound_background_train.json,/manifests/freesound_laughter_train.json,/manifests/fisher_2004_background.json,/manifests/fisher_2004_speech_sampled.json,/manifests/google_train_manifest.json,/manifests/icsi_all_0.63.json,/manifests/musan_freesound_train.json,/manifests/musan_music_train.json,/manifests/musan_soundbible_train.json,/manifests/mandarin_train_sample.json,/manifests/german_train_sample.json,/manifests/spanish_train_sample.json,/manifests/french_train_sample.json,/manifests/russian_train_sample.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: true\n",
            "    is_tarred: false\n",
            "    tarred_audio_filepaths: null\n",
            "    tarred_shard_strategy: scatter\n",
            "    augmentor:\n",
            "      shift:\n",
            "        prob: 0.5\n",
            "        min_shift_ms: -10.0\n",
            "        max_shift_ms: 10.0\n",
            "      white_noise:\n",
            "        prob: 0.5\n",
            "        min_level: -90\n",
            "        max_level: -46\n",
            "        norm: true\n",
            "      noise:\n",
            "        prob: 0.5\n",
            "        manifest_path: /manifests/noise_0_1_musan_fs.json\n",
            "        min_snr_db: 0\n",
            "        max_snr_db: 30\n",
            "        max_gain_db: 300.0\n",
            "        norm: true\n",
            "      gain:\n",
            "        prob: 0.5\n",
            "        min_gain_dbfs: -10.0\n",
            "        max_gain_dbfs: 10.0\n",
            "        norm: true\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2024-11-13 13:57:48 modelPT:183] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: /manifests/ami_dev_0.63.json,/manifests/freesound_background_dev.json,/manifests/freesound_laughter_dev.json,/manifests/ch120_moved_0.63.json,/manifests/fisher_2005_500_speech_sampled.json,/manifests/google_dev_manifest.json,/manifests/musan_music_dev.json,/manifests/mandarin_dev.json,/manifests/german_dev.json,/manifests/spanish_dev.json,/manifests/french_dev.json,/manifests/russian_dev.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: false\n",
            "    val_loss_idx: 0\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2024-11-13 13:57:48 modelPT:189] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 128\n",
            "    shuffle: false\n",
            "    test_loss_idx: 0\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:57:48 features:305] PADDING: 16\n",
            "[NeMo I 2024-11-13 13:57:48 save_restore_connector:272] Model EncDecClassificationModel was successfully restored from /root/.cache/torch/NeMo/NeMo_2.0.0rc1/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
            "[NeMo I 2024-11-13 13:57:48 msdd_models:870] Multiscale Weights: [1, 1, 1, 1, 1]\n",
            "[NeMo I 2024-11-13 13:57:48 msdd_models:871] Clustering Parameters: {\n",
            "        \"oracle_num_speakers\": false,\n",
            "        \"max_num_speakers\": 8,\n",
            "        \"enhanced_count_thres\": 80,\n",
            "        \"max_rp_threshold\": 0.25,\n",
            "        \"sparse_search_volume\": 30,\n",
            "        \"maj_vote_spk_count\": false,\n",
            "        \"chunk_cluster_count\": 50,\n",
            "        \"embeddings_per_chunk\": 10000\n",
            "    }\n",
            "[NeMo I 2024-11-13 13:57:48 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2024-11-13 13:57:48 clustering_diarizer:313] Split long audio file to avoid CUDA memory issue\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "splitting manifest: 100%|| 1/1 [00:00<00:00,  6.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:57:48 classification_models:293] Perform streaming frame-level VAD\n",
            "[NeMo I 2024-11-13 13:57:48 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-11-13 13:57:48 collections:741] Dataset successfully loaded with 28 items and total duration provided from manifest is  0.39 hours.\n",
            "[NeMo I 2024-11-13 13:57:48 collections:746] # 28 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "vad:   0%|          | 0/28 [00:00<?, ?it/s][NeMo W 2024-11-13 13:57:48 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/collections/asr/models/clustering_diarizer.py:226: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "      with autocast():\n",
            "    \n",
            "[NeMo W 2024-11-13 13:57:48 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/collections/asr/parts/preprocessing/features.py:436: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "      with torch.cuda.amp.autocast(enabled=False):\n",
            "    \n",
            "vad: 100%|| 28/28 [00:07<00:00,  3.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:57:55 clustering_diarizer:254] Generating predictions with overlapping input segments\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "                                                               "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:58:09 clustering_diarizer:266] Converting frame level prediction to speech/no-speech segment in start and end times format.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "creating speech segments: 100%|| 1/1 [00:00<00:00,  1.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:58:10 clustering_diarizer:291] Subsegmentation for embedding extraction: scale0, /content/temp_outputs/speaker_outputs/subsegments_scale0.json\n",
            "[NeMo I 2024-11-13 13:58:10 clustering_diarizer:347] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-11-13 13:58:10 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-11-13 13:58:10 collections:741] Dataset successfully loaded with 1099 items and total duration provided from manifest is  0.17 hours.\n",
            "[NeMo I 2024-11-13 13:58:10 collections:746] # 1099 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[1/5] extract embeddings:   0%|          | 0/18 [00:00<?, ?it/s][NeMo W 2024-11-13 13:58:10 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/collections/asr/models/clustering_diarizer.py:362: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "      with autocast():\n",
            "    \n",
            "[NeMo W 2024-11-13 13:58:10 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/collections/asr/parts/submodules/jasper.py:476: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "      with torch.cuda.amp.autocast(enabled=False):\n",
            "    \n",
            "[1/5] extract embeddings: 100%|| 18/18 [00:01<00:00,  9.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:58:12 clustering_diarizer:393] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-11-13 13:58:12 clustering_diarizer:291] Subsegmentation for embedding extraction: scale1, /content/temp_outputs/speaker_outputs/subsegments_scale1.json\n",
            "[NeMo I 2024-11-13 13:58:12 clustering_diarizer:347] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-11-13 13:58:12 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-11-13 13:58:12 collections:741] Dataset successfully loaded with 1160 items and total duration provided from manifest is  0.18 hours.\n",
            "[NeMo I 2024-11-13 13:58:12 collections:746] # 1160 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[2/5] extract embeddings: 100%|| 19/19 [00:01<00:00, 12.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:58:13 clustering_diarizer:393] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-11-13 13:58:13 clustering_diarizer:291] Subsegmentation for embedding extraction: scale2, /content/temp_outputs/speaker_outputs/subsegments_scale2.json\n",
            "[NeMo I 2024-11-13 13:58:13 clustering_diarizer:347] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-11-13 13:58:13 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-11-13 13:58:13 collections:741] Dataset successfully loaded with 1262 items and total duration provided from manifest is  0.19 hours.\n",
            "[NeMo I 2024-11-13 13:58:13 collections:746] # 1262 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[3/5] extract embeddings: 100%|| 20/20 [00:01<00:00, 12.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:58:15 clustering_diarizer:393] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-11-13 13:58:15 clustering_diarizer:291] Subsegmentation for embedding extraction: scale3, /content/temp_outputs/speaker_outputs/subsegments_scale3.json\n",
            "[NeMo I 2024-11-13 13:58:15 clustering_diarizer:347] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-11-13 13:58:15 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-11-13 13:58:15 collections:741] Dataset successfully loaded with 1477 items and total duration provided from manifest is  0.20 hours.\n",
            "[NeMo I 2024-11-13 13:58:15 collections:746] # 1477 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[4/5] extract embeddings: 100%|| 24/24 [00:01<00:00, 16.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:58:17 clustering_diarizer:393] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-11-13 13:58:17 clustering_diarizer:291] Subsegmentation for embedding extraction: scale4, /content/temp_outputs/speaker_outputs/subsegments_scale4.json\n",
            "[NeMo I 2024-11-13 13:58:17 clustering_diarizer:347] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-11-13 13:58:17 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-11-13 13:58:17 collections:741] Dataset successfully loaded with 2049 items and total duration provided from manifest is  0.23 hours.\n",
            "[NeMo I 2024-11-13 13:58:17 collections:746] # 2049 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[5/5] extract embeddings: 100%|| 33/33 [00:02<00:00, 14.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:58:21 clustering_diarizer:393] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "clustering: 100%|| 1/1 [00:00<00:00,  1.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:58:22 clustering_diarizer:461] Outputs are saved in /content/temp_outputs directory\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[NeMo W 2024-11-13 13:58:22 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:58:22 msdd_models:966] Loading embedding pickle file of scale:0 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale0_embeddings.pkl\n",
            "[NeMo I 2024-11-13 13:58:22 msdd_models:966] Loading embedding pickle file of scale:1 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale1_embeddings.pkl\n",
            "[NeMo I 2024-11-13 13:58:22 msdd_models:966] Loading embedding pickle file of scale:2 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale2_embeddings.pkl\n",
            "[NeMo I 2024-11-13 13:58:22 msdd_models:966] Loading embedding pickle file of scale:3 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale3_embeddings.pkl\n",
            "[NeMo I 2024-11-13 13:58:22 msdd_models:966] Loading embedding pickle file of scale:4 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale4_embeddings.pkl\n",
            "[NeMo I 2024-11-13 13:58:22 msdd_models:944] Loading cluster label file from /content/temp_outputs/speaker_outputs/subsegments_scale4_cluster.label\n",
            "[NeMo I 2024-11-13 13:58:22 collections:1067] Filtered duration for loading collection is 0.000000.\n",
            "[NeMo I 2024-11-13 13:58:22 collections:1071] Total 1 session files loaded accounting to # 1 audio clips\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/1 [00:00<?, ?it/s][NeMo W 2024-11-13 13:58:23 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/collections/asr/models/msdd_models.py:1333: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "      with autocast():\n",
            "    \n",
            "100%|| 1/1 [00:00<00:00,  9.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:58:23 msdd_models:1407]      [Threshold: 0.7000] [use_clus_as_main=False] [diar_window=50]\n",
            "[NeMo I 2024-11-13 13:58:23 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2024-11-13 13:58:23 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[NeMo W 2024-11-13 13:58:23 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:58:23 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-11-13 13:58:23 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:58:23 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-11-13 13:58:23 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:58:23 msdd_models:1435]   \n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Punctuation restoration is not available for ru language. Using the original punctuation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:59:43 msdd_models:1097] Loading pretrained diar_msdd_telephonic model from NGC\n",
            "[NeMo I 2024-11-13 13:59:43 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_2.0.0rc1/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
            "[NeMo I 2024-11-13 13:59:43 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_2.0.0rc1/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo\n",
            "[NeMo I 2024-11-13 13:59:43 common:826] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-11-13 13:59:45 modelPT:176] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: true\n",
            "    \n",
            "[NeMo W 2024-11-13 13:59:45 modelPT:183] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    \n",
            "[NeMo W 2024-11-13 13:59:45 modelPT:189] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    seq_eval_mode: false\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:59:45 features:305] PADDING: 16\n",
            "[NeMo I 2024-11-13 13:59:45 features:305] PADDING: 16\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-11-13 13:59:45 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/core/connectors/save_restore_connector.py:617: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "      return torch.load(model_weights, map_location='cpu')\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:59:45 save_restore_connector:272] Model EncDecDiarLabelModel was successfully restored from /root/.cache/torch/NeMo/NeMo_2.0.0rc1/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
            "[NeMo I 2024-11-13 13:59:45 features:305] PADDING: 16\n",
            "[NeMo I 2024-11-13 13:59:46 clustering_diarizer:127] Loading pretrained vad_multilingual_marblenet model from NGC\n",
            "[NeMo I 2024-11-13 13:59:46 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_2.0.0rc1/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
            "[NeMo I 2024-11-13 13:59:46 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_2.0.0rc1/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo\n",
            "[NeMo I 2024-11-13 13:59:46 common:826] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-11-13 13:59:46 modelPT:176] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: /manifests/ami_train_0.63.json,/manifests/freesound_background_train.json,/manifests/freesound_laughter_train.json,/manifests/fisher_2004_background.json,/manifests/fisher_2004_speech_sampled.json,/manifests/google_train_manifest.json,/manifests/icsi_all_0.63.json,/manifests/musan_freesound_train.json,/manifests/musan_music_train.json,/manifests/musan_soundbible_train.json,/manifests/mandarin_train_sample.json,/manifests/german_train_sample.json,/manifests/spanish_train_sample.json,/manifests/french_train_sample.json,/manifests/russian_train_sample.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: true\n",
            "    is_tarred: false\n",
            "    tarred_audio_filepaths: null\n",
            "    tarred_shard_strategy: scatter\n",
            "    augmentor:\n",
            "      shift:\n",
            "        prob: 0.5\n",
            "        min_shift_ms: -10.0\n",
            "        max_shift_ms: 10.0\n",
            "      white_noise:\n",
            "        prob: 0.5\n",
            "        min_level: -90\n",
            "        max_level: -46\n",
            "        norm: true\n",
            "      noise:\n",
            "        prob: 0.5\n",
            "        manifest_path: /manifests/noise_0_1_musan_fs.json\n",
            "        min_snr_db: 0\n",
            "        max_snr_db: 30\n",
            "        max_gain_db: 300.0\n",
            "        norm: true\n",
            "      gain:\n",
            "        prob: 0.5\n",
            "        min_gain_dbfs: -10.0\n",
            "        max_gain_dbfs: 10.0\n",
            "        norm: true\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2024-11-13 13:59:46 modelPT:183] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: /manifests/ami_dev_0.63.json,/manifests/freesound_background_dev.json,/manifests/freesound_laughter_dev.json,/manifests/ch120_moved_0.63.json,/manifests/fisher_2005_500_speech_sampled.json,/manifests/google_dev_manifest.json,/manifests/musan_music_dev.json,/manifests/mandarin_dev.json,/manifests/german_dev.json,/manifests/spanish_dev.json,/manifests/french_dev.json,/manifests/russian_dev.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: false\n",
            "    val_loss_idx: 0\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2024-11-13 13:59:46 modelPT:189] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 128\n",
            "    shuffle: false\n",
            "    test_loss_idx: 0\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:59:46 features:305] PADDING: 16\n",
            "[NeMo I 2024-11-13 13:59:46 save_restore_connector:272] Model EncDecClassificationModel was successfully restored from /root/.cache/torch/NeMo/NeMo_2.0.0rc1/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
            "[NeMo I 2024-11-13 13:59:46 msdd_models:870] Multiscale Weights: [1, 1, 1, 1, 1]\n",
            "[NeMo I 2024-11-13 13:59:46 msdd_models:871] Clustering Parameters: {\n",
            "        \"oracle_num_speakers\": false,\n",
            "        \"max_num_speakers\": 8,\n",
            "        \"enhanced_count_thres\": 80,\n",
            "        \"max_rp_threshold\": 0.25,\n",
            "        \"sparse_search_volume\": 30,\n",
            "        \"maj_vote_spk_count\": false,\n",
            "        \"chunk_cluster_count\": 50,\n",
            "        \"embeddings_per_chunk\": 10000\n",
            "    }\n",
            "[NeMo I 2024-11-13 13:59:46 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2024-11-13 13:59:46 clustering_diarizer:313] Split long audio file to avoid CUDA memory issue\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "splitting manifest: 100%|| 1/1 [00:00<00:00, 35.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:59:46 classification_models:293] Perform streaming frame-level VAD\n",
            "[NeMo I 2024-11-13 13:59:46 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-11-13 13:59:46 collections:741] Dataset successfully loaded with 6 items and total duration provided from manifest is  0.08 hours.\n",
            "[NeMo I 2024-11-13 13:59:46 collections:746] # 6 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "vad:   0%|          | 0/6 [00:00<?, ?it/s][NeMo W 2024-11-13 13:59:46 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/collections/asr/models/clustering_diarizer.py:226: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "      with autocast():\n",
            "    \n",
            "[NeMo W 2024-11-13 13:59:46 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/collections/asr/parts/preprocessing/features.py:436: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "      with torch.cuda.amp.autocast(enabled=False):\n",
            "    \n",
            "vad: 100%|| 6/6 [00:01<00:00,  4.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:59:48 clustering_diarizer:254] Generating predictions with overlapping input segments\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "                                                               "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:59:51 clustering_diarizer:266] Converting frame level prediction to speech/no-speech segment in start and end times format.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "creating speech segments: 100%|| 1/1 [00:00<00:00,  3.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:59:51 clustering_diarizer:291] Subsegmentation for embedding extraction: scale0, /content/temp_outputs/speaker_outputs/subsegments_scale0.json\n",
            "[NeMo I 2024-11-13 13:59:51 clustering_diarizer:347] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-11-13 13:59:51 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-11-13 13:59:51 collections:741] Dataset successfully loaded with 231 items and total duration provided from manifest is  0.05 hours.\n",
            "[NeMo I 2024-11-13 13:59:51 collections:746] # 231 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[1/5] extract embeddings:   0%|          | 0/4 [00:00<?, ?it/s][NeMo W 2024-11-13 13:59:51 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/collections/asr/models/clustering_diarizer.py:362: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "      with autocast():\n",
            "    \n",
            "[NeMo W 2024-11-13 13:59:51 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/collections/asr/parts/submodules/jasper.py:476: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "      with torch.cuda.amp.autocast(enabled=False):\n",
            "    \n",
            "[1/5] extract embeddings: 100%|| 4/4 [00:00<00:00,  8.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:59:52 clustering_diarizer:393] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-11-13 13:59:52 clustering_diarizer:291] Subsegmentation for embedding extraction: scale1, /content/temp_outputs/speaker_outputs/subsegments_scale1.json\n",
            "[NeMo I 2024-11-13 13:59:52 clustering_diarizer:347] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-11-13 13:59:52 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-11-13 13:59:52 collections:741] Dataset successfully loaded with 256 items and total duration provided from manifest is  0.05 hours.\n",
            "[NeMo I 2024-11-13 13:59:52 collections:746] # 256 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[2/5] extract embeddings: 100%|| 4/4 [00:00<00:00, 10.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:59:53 clustering_diarizer:393] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-11-13 13:59:53 clustering_diarizer:291] Subsegmentation for embedding extraction: scale2, /content/temp_outputs/speaker_outputs/subsegments_scale2.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:59:53 clustering_diarizer:347] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-11-13 13:59:53 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-11-13 13:59:53 collections:741] Dataset successfully loaded with 300 items and total duration provided from manifest is  0.06 hours.\n",
            "[NeMo I 2024-11-13 13:59:53 collections:746] # 300 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[3/5] extract embeddings: 100%|| 5/5 [00:00<00:00, 13.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:59:53 clustering_diarizer:393] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-11-13 13:59:53 clustering_diarizer:291] Subsegmentation for embedding extraction: scale3, /content/temp_outputs/speaker_outputs/subsegments_scale3.json\n",
            "[NeMo I 2024-11-13 13:59:53 clustering_diarizer:347] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-11-13 13:59:53 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-11-13 13:59:53 collections:741] Dataset successfully loaded with 370 items and total duration provided from manifest is  0.06 hours.\n",
            "[NeMo I 2024-11-13 13:59:53 collections:746] # 370 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[4/5] extract embeddings: 100%|| 6/6 [00:00<00:00, 16.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:59:54 clustering_diarizer:393] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-11-13 13:59:54 clustering_diarizer:291] Subsegmentation for embedding extraction: scale4, /content/temp_outputs/speaker_outputs/subsegments_scale4.json\n",
            "[NeMo I 2024-11-13 13:59:54 clustering_diarizer:347] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-11-13 13:59:54 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-11-13 13:59:54 collections:741] Dataset successfully loaded with 541 items and total duration provided from manifest is  0.06 hours.\n",
            "[NeMo I 2024-11-13 13:59:54 collections:746] # 541 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[5/5] extract embeddings: 100%|| 9/9 [00:00<00:00, 18.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:59:54 clustering_diarizer:393] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "clustering: 100%|| 1/1 [00:00<00:00,  2.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:59:54 clustering_diarizer:461] Outputs are saved in /content/temp_outputs directory\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[NeMo W 2024-11-13 13:59:54 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:59:55 msdd_models:966] Loading embedding pickle file of scale:0 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale0_embeddings.pkl\n",
            "[NeMo I 2024-11-13 13:59:55 msdd_models:966] Loading embedding pickle file of scale:1 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale1_embeddings.pkl\n",
            "[NeMo I 2024-11-13 13:59:55 msdd_models:966] Loading embedding pickle file of scale:2 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale2_embeddings.pkl\n",
            "[NeMo I 2024-11-13 13:59:55 msdd_models:966] Loading embedding pickle file of scale:3 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale3_embeddings.pkl\n",
            "[NeMo I 2024-11-13 13:59:55 msdd_models:966] Loading embedding pickle file of scale:4 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale4_embeddings.pkl\n",
            "[NeMo I 2024-11-13 13:59:55 msdd_models:944] Loading cluster label file from /content/temp_outputs/speaker_outputs/subsegments_scale4_cluster.label\n",
            "[NeMo I 2024-11-13 13:59:55 collections:1067] Filtered duration for loading collection is 0.000000.\n",
            "[NeMo I 2024-11-13 13:59:55 collections:1071] Total 1 session files loaded accounting to # 1 audio clips\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/1 [00:00<?, ?it/s][NeMo W 2024-11-13 13:59:55 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/collections/asr/models/msdd_models.py:1333: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "      with autocast():\n",
            "    \n",
            "100%|| 1/1 [00:00<00:00, 23.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:59:55 msdd_models:1407]      [Threshold: 0.7000] [use_clus_as_main=False] [diar_window=50]\n",
            "[NeMo I 2024-11-13 13:59:55 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2024-11-13 13:59:55 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-11-13 13:59:55 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:59:55 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-11-13 13:59:55 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:59:55 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-11-13 13:59:55 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 13:59:55 msdd_models:1435]   \n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Punctuation restoration is not available for ru language. Using the original punctuation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:04:23 msdd_models:1097] Loading pretrained diar_msdd_telephonic model from NGC\n",
            "[NeMo I 2024-11-13 14:04:23 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_2.0.0rc1/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
            "[NeMo I 2024-11-13 14:04:23 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_2.0.0rc1/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo\n",
            "[NeMo I 2024-11-13 14:04:23 common:826] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-11-13 14:04:25 modelPT:176] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: true\n",
            "    \n",
            "[NeMo W 2024-11-13 14:04:25 modelPT:183] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    \n",
            "[NeMo W 2024-11-13 14:04:25 modelPT:189] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    seq_eval_mode: false\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:04:25 features:305] PADDING: 16\n",
            "[NeMo I 2024-11-13 14:04:25 features:305] PADDING: 16\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-11-13 14:04:25 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/core/connectors/save_restore_connector.py:617: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "      return torch.load(model_weights, map_location='cpu')\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:04:27 save_restore_connector:272] Model EncDecDiarLabelModel was successfully restored from /root/.cache/torch/NeMo/NeMo_2.0.0rc1/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
            "[NeMo I 2024-11-13 14:04:28 features:305] PADDING: 16\n",
            "[NeMo I 2024-11-13 14:04:28 clustering_diarizer:127] Loading pretrained vad_multilingual_marblenet model from NGC\n",
            "[NeMo I 2024-11-13 14:04:28 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_2.0.0rc1/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
            "[NeMo I 2024-11-13 14:04:28 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_2.0.0rc1/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo\n",
            "[NeMo I 2024-11-13 14:04:28 common:826] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-11-13 14:04:28 modelPT:176] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: /manifests/ami_train_0.63.json,/manifests/freesound_background_train.json,/manifests/freesound_laughter_train.json,/manifests/fisher_2004_background.json,/manifests/fisher_2004_speech_sampled.json,/manifests/google_train_manifest.json,/manifests/icsi_all_0.63.json,/manifests/musan_freesound_train.json,/manifests/musan_music_train.json,/manifests/musan_soundbible_train.json,/manifests/mandarin_train_sample.json,/manifests/german_train_sample.json,/manifests/spanish_train_sample.json,/manifests/french_train_sample.json,/manifests/russian_train_sample.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: true\n",
            "    is_tarred: false\n",
            "    tarred_audio_filepaths: null\n",
            "    tarred_shard_strategy: scatter\n",
            "    augmentor:\n",
            "      shift:\n",
            "        prob: 0.5\n",
            "        min_shift_ms: -10.0\n",
            "        max_shift_ms: 10.0\n",
            "      white_noise:\n",
            "        prob: 0.5\n",
            "        min_level: -90\n",
            "        max_level: -46\n",
            "        norm: true\n",
            "      noise:\n",
            "        prob: 0.5\n",
            "        manifest_path: /manifests/noise_0_1_musan_fs.json\n",
            "        min_snr_db: 0\n",
            "        max_snr_db: 30\n",
            "        max_gain_db: 300.0\n",
            "        norm: true\n",
            "      gain:\n",
            "        prob: 0.5\n",
            "        min_gain_dbfs: -10.0\n",
            "        max_gain_dbfs: 10.0\n",
            "        norm: true\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2024-11-13 14:04:28 modelPT:183] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: /manifests/ami_dev_0.63.json,/manifests/freesound_background_dev.json,/manifests/freesound_laughter_dev.json,/manifests/ch120_moved_0.63.json,/manifests/fisher_2005_500_speech_sampled.json,/manifests/google_dev_manifest.json,/manifests/musan_music_dev.json,/manifests/mandarin_dev.json,/manifests/german_dev.json,/manifests/spanish_dev.json,/manifests/french_dev.json,/manifests/russian_dev.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: false\n",
            "    val_loss_idx: 0\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2024-11-13 14:04:28 modelPT:189] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 128\n",
            "    shuffle: false\n",
            "    test_loss_idx: 0\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:04:28 features:305] PADDING: 16\n",
            "[NeMo I 2024-11-13 14:04:28 save_restore_connector:272] Model EncDecClassificationModel was successfully restored from /root/.cache/torch/NeMo/NeMo_2.0.0rc1/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
            "[NeMo I 2024-11-13 14:04:28 msdd_models:870] Multiscale Weights: [1, 1, 1, 1, 1]\n",
            "[NeMo I 2024-11-13 14:04:28 msdd_models:871] Clustering Parameters: {\n",
            "        \"oracle_num_speakers\": false,\n",
            "        \"max_num_speakers\": 8,\n",
            "        \"enhanced_count_thres\": 80,\n",
            "        \"max_rp_threshold\": 0.25,\n",
            "        \"sparse_search_volume\": 30,\n",
            "        \"maj_vote_spk_count\": false,\n",
            "        \"chunk_cluster_count\": 50,\n",
            "        \"embeddings_per_chunk\": 10000\n",
            "    }\n",
            "[NeMo I 2024-11-13 14:04:28 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2024-11-13 14:04:28 clustering_diarizer:313] Split long audio file to avoid CUDA memory issue\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "splitting manifest: 100%|| 1/1 [00:00<00:00,  4.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:04:29 classification_models:293] Perform streaming frame-level VAD\n",
            "[NeMo I 2024-11-13 14:04:29 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-11-13 14:04:29 collections:741] Dataset successfully loaded with 27 items and total duration provided from manifest is  0.37 hours.\n",
            "[NeMo I 2024-11-13 14:04:29 collections:746] # 27 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "vad:   0%|          | 0/27 [00:00<?, ?it/s][NeMo W 2024-11-13 14:04:29 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/collections/asr/models/clustering_diarizer.py:226: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "      with autocast():\n",
            "    \n",
            "[NeMo W 2024-11-13 14:04:29 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/collections/asr/parts/preprocessing/features.py:436: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "      with torch.cuda.amp.autocast(enabled=False):\n",
            "    \n",
            "vad: 100%|| 27/27 [00:06<00:00,  4.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:04:35 clustering_diarizer:254] Generating predictions with overlapping input segments\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "                                                               "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:04:48 clustering_diarizer:266] Converting frame level prediction to speech/no-speech segment in start and end times format.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "creating speech segments: 100%|| 1/1 [00:00<00:00,  1.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:04:49 clustering_diarizer:291] Subsegmentation for embedding extraction: scale0, /content/temp_outputs/speaker_outputs/subsegments_scale0.json\n",
            "[NeMo I 2024-11-13 14:04:49 clustering_diarizer:347] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-11-13 14:04:49 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-11-13 14:04:49 collections:741] Dataset successfully loaded with 871 items and total duration provided from manifest is  0.09 hours.\n",
            "[NeMo I 2024-11-13 14:04:49 collections:746] # 871 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[1/5] extract embeddings:   0%|          | 0/14 [00:00<?, ?it/s][NeMo W 2024-11-13 14:04:49 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/collections/asr/models/clustering_diarizer.py:362: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "      with autocast():\n",
            "    \n",
            "[NeMo W 2024-11-13 14:04:49 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/collections/asr/parts/submodules/jasper.py:476: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "      with torch.cuda.amp.autocast(enabled=False):\n",
            "    \n",
            "[1/5] extract embeddings: 100%|| 14/14 [00:01<00:00, 10.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:04:50 clustering_diarizer:393] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-11-13 14:04:50 clustering_diarizer:291] Subsegmentation for embedding extraction: scale1, /content/temp_outputs/speaker_outputs/subsegments_scale1.json\n",
            "[NeMo I 2024-11-13 14:04:51 clustering_diarizer:347] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-11-13 14:04:51 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-11-13 14:04:51 collections:741] Dataset successfully loaded with 890 items and total duration provided from manifest is  0.10 hours.\n",
            "[NeMo I 2024-11-13 14:04:51 collections:746] # 890 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[2/5] extract embeddings: 100%|| 14/14 [00:01<00:00, 12.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:04:52 clustering_diarizer:393] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-11-13 14:04:52 clustering_diarizer:291] Subsegmentation for embedding extraction: scale2, /content/temp_outputs/speaker_outputs/subsegments_scale2.json\n",
            "[NeMo I 2024-11-13 14:04:52 clustering_diarizer:347] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-11-13 14:04:52 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-11-13 14:04:52 collections:741] Dataset successfully loaded with 922 items and total duration provided from manifest is  0.10 hours.\n",
            "[NeMo I 2024-11-13 14:04:52 collections:746] # 922 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[3/5] extract embeddings: 100%|| 15/15 [00:01<00:00, 13.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:04:53 clustering_diarizer:393] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-11-13 14:04:53 clustering_diarizer:291] Subsegmentation for embedding extraction: scale3, /content/temp_outputs/speaker_outputs/subsegments_scale3.json\n",
            "[NeMo I 2024-11-13 14:04:53 clustering_diarizer:347] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-11-13 14:04:53 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-11-13 14:04:53 collections:741] Dataset successfully loaded with 1003 items and total duration provided from manifest is  0.11 hours.\n",
            "[NeMo I 2024-11-13 14:04:53 collections:746] # 1003 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[4/5] extract embeddings: 100%|| 16/16 [00:00<00:00, 16.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:04:54 clustering_diarizer:393] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-11-13 14:04:54 clustering_diarizer:291] Subsegmentation for embedding extraction: scale4, /content/temp_outputs/speaker_outputs/subsegments_scale4.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:04:54 clustering_diarizer:347] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-11-13 14:04:54 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-11-13 14:04:54 collections:741] Dataset successfully loaded with 1241 items and total duration provided from manifest is  0.12 hours.\n",
            "[NeMo I 2024-11-13 14:04:54 collections:746] # 1241 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[5/5] extract embeddings: 100%|| 20/20 [00:01<00:00, 17.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:04:55 clustering_diarizer:393] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "clustering: 100%|| 1/1 [00:00<00:00,  2.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:04:56 clustering_diarizer:461] Outputs are saved in /content/temp_outputs directory\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[NeMo W 2024-11-13 14:04:56 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:04:56 msdd_models:966] Loading embedding pickle file of scale:0 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale0_embeddings.pkl\n",
            "[NeMo I 2024-11-13 14:04:56 msdd_models:966] Loading embedding pickle file of scale:1 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale1_embeddings.pkl\n",
            "[NeMo I 2024-11-13 14:04:56 msdd_models:966] Loading embedding pickle file of scale:2 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale2_embeddings.pkl\n",
            "[NeMo I 2024-11-13 14:04:56 msdd_models:966] Loading embedding pickle file of scale:3 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale3_embeddings.pkl\n",
            "[NeMo I 2024-11-13 14:04:56 msdd_models:966] Loading embedding pickle file of scale:4 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale4_embeddings.pkl\n",
            "[NeMo I 2024-11-13 14:04:56 msdd_models:944] Loading cluster label file from /content/temp_outputs/speaker_outputs/subsegments_scale4_cluster.label\n",
            "[NeMo I 2024-11-13 14:04:56 collections:1067] Filtered duration for loading collection is 0.000000.\n",
            "[NeMo I 2024-11-13 14:04:56 collections:1071] Total 1 session files loaded accounting to # 1 audio clips\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/1 [00:00<?, ?it/s][NeMo W 2024-11-13 14:04:56 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/collections/asr/models/msdd_models.py:1333: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "      with autocast():\n",
            "    \n",
            "100%|| 1/1 [00:00<00:00, 11.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:04:56 msdd_models:1407]      [Threshold: 0.7000] [use_clus_as_main=False] [diar_window=50]\n",
            "[NeMo I 2024-11-13 14:04:56 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2024-11-13 14:04:56 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[NeMo W 2024-11-13 14:04:57 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:04:57 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-11-13 14:04:57 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:04:57 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-11-13 14:04:57 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:04:57 msdd_models:1435]   \n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Punctuation restoration is not available for ru language. Using the original punctuation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:10:04 msdd_models:1097] Loading pretrained diar_msdd_telephonic model from NGC\n",
            "[NeMo I 2024-11-13 14:10:04 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_2.0.0rc1/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
            "[NeMo I 2024-11-13 14:10:04 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_2.0.0rc1/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo\n",
            "[NeMo I 2024-11-13 14:10:04 common:826] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-11-13 14:10:10 modelPT:176] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: true\n",
            "    \n",
            "[NeMo W 2024-11-13 14:10:10 modelPT:183] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    \n",
            "[NeMo W 2024-11-13 14:10:10 modelPT:189] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    seq_eval_mode: false\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:10:10 features:305] PADDING: 16\n",
            "[NeMo I 2024-11-13 14:10:10 features:305] PADDING: 16\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-11-13 14:10:11 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/core/connectors/save_restore_connector.py:617: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "      return torch.load(model_weights, map_location='cpu')\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:10:11 save_restore_connector:272] Model EncDecDiarLabelModel was successfully restored from /root/.cache/torch/NeMo/NeMo_2.0.0rc1/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
            "[NeMo I 2024-11-13 14:10:11 features:305] PADDING: 16\n",
            "[NeMo I 2024-11-13 14:10:12 clustering_diarizer:127] Loading pretrained vad_multilingual_marblenet model from NGC\n",
            "[NeMo I 2024-11-13 14:10:12 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_2.0.0rc1/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
            "[NeMo I 2024-11-13 14:10:12 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_2.0.0rc1/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo\n",
            "[NeMo I 2024-11-13 14:10:12 common:826] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-11-13 14:10:12 modelPT:176] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: /manifests/ami_train_0.63.json,/manifests/freesound_background_train.json,/manifests/freesound_laughter_train.json,/manifests/fisher_2004_background.json,/manifests/fisher_2004_speech_sampled.json,/manifests/google_train_manifest.json,/manifests/icsi_all_0.63.json,/manifests/musan_freesound_train.json,/manifests/musan_music_train.json,/manifests/musan_soundbible_train.json,/manifests/mandarin_train_sample.json,/manifests/german_train_sample.json,/manifests/spanish_train_sample.json,/manifests/french_train_sample.json,/manifests/russian_train_sample.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: true\n",
            "    is_tarred: false\n",
            "    tarred_audio_filepaths: null\n",
            "    tarred_shard_strategy: scatter\n",
            "    augmentor:\n",
            "      shift:\n",
            "        prob: 0.5\n",
            "        min_shift_ms: -10.0\n",
            "        max_shift_ms: 10.0\n",
            "      white_noise:\n",
            "        prob: 0.5\n",
            "        min_level: -90\n",
            "        max_level: -46\n",
            "        norm: true\n",
            "      noise:\n",
            "        prob: 0.5\n",
            "        manifest_path: /manifests/noise_0_1_musan_fs.json\n",
            "        min_snr_db: 0\n",
            "        max_snr_db: 30\n",
            "        max_gain_db: 300.0\n",
            "        norm: true\n",
            "      gain:\n",
            "        prob: 0.5\n",
            "        min_gain_dbfs: -10.0\n",
            "        max_gain_dbfs: 10.0\n",
            "        norm: true\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2024-11-13 14:10:12 modelPT:183] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: /manifests/ami_dev_0.63.json,/manifests/freesound_background_dev.json,/manifests/freesound_laughter_dev.json,/manifests/ch120_moved_0.63.json,/manifests/fisher_2005_500_speech_sampled.json,/manifests/google_dev_manifest.json,/manifests/musan_music_dev.json,/manifests/mandarin_dev.json,/manifests/german_dev.json,/manifests/spanish_dev.json,/manifests/french_dev.json,/manifests/russian_dev.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: false\n",
            "    val_loss_idx: 0\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2024-11-13 14:10:12 modelPT:189] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 128\n",
            "    shuffle: false\n",
            "    test_loss_idx: 0\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:10:12 features:305] PADDING: 16\n",
            "[NeMo I 2024-11-13 14:10:12 save_restore_connector:272] Model EncDecClassificationModel was successfully restored from /root/.cache/torch/NeMo/NeMo_2.0.0rc1/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
            "[NeMo I 2024-11-13 14:10:12 msdd_models:870] Multiscale Weights: [1, 1, 1, 1, 1]\n",
            "[NeMo I 2024-11-13 14:10:12 msdd_models:871] Clustering Parameters: {\n",
            "        \"oracle_num_speakers\": false,\n",
            "        \"max_num_speakers\": 8,\n",
            "        \"enhanced_count_thres\": 80,\n",
            "        \"max_rp_threshold\": 0.25,\n",
            "        \"sparse_search_volume\": 30,\n",
            "        \"maj_vote_spk_count\": false,\n",
            "        \"chunk_cluster_count\": 50,\n",
            "        \"embeddings_per_chunk\": 10000\n",
            "    }\n",
            "[NeMo I 2024-11-13 14:10:12 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2024-11-13 14:10:12 clustering_diarizer:313] Split long audio file to avoid CUDA memory issue\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "splitting manifest: 100%|| 1/1 [00:00<00:00,  6.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:10:12 classification_models:293] Perform streaming frame-level VAD\n",
            "[NeMo I 2024-11-13 14:10:12 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-11-13 14:10:12 collections:741] Dataset successfully loaded with 33 items and total duration provided from manifest is  0.45 hours.\n",
            "[NeMo I 2024-11-13 14:10:12 collections:746] # 33 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "vad:   0%|          | 0/33 [00:00<?, ?it/s][NeMo W 2024-11-13 14:10:12 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/collections/asr/models/clustering_diarizer.py:226: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "      with autocast():\n",
            "    \n",
            "[NeMo W 2024-11-13 14:10:12 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/collections/asr/parts/preprocessing/features.py:436: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "      with torch.cuda.amp.autocast(enabled=False):\n",
            "    \n",
            "vad: 100%|| 33/33 [00:07<00:00,  4.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:10:20 clustering_diarizer:254] Generating predictions with overlapping input segments\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "                                                               "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:10:35 clustering_diarizer:266] Converting frame level prediction to speech/no-speech segment in start and end times format.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "creating speech segments: 100%|| 1/1 [00:01<00:00,  1.14s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:10:36 clustering_diarizer:291] Subsegmentation for embedding extraction: scale0, /content/temp_outputs/speaker_outputs/subsegments_scale0.json\n",
            "[NeMo I 2024-11-13 14:10:36 clustering_diarizer:347] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-11-13 14:10:36 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-11-13 14:10:36 collections:741] Dataset successfully loaded with 1241 items and total duration provided from manifest is  0.22 hours.\n",
            "[NeMo I 2024-11-13 14:10:36 collections:746] # 1241 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[1/5] extract embeddings:   0%|          | 0/20 [00:00<?, ?it/s][NeMo W 2024-11-13 14:10:36 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/collections/asr/models/clustering_diarizer.py:362: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "      with autocast():\n",
            "    \n",
            "[NeMo W 2024-11-13 14:10:36 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/collections/asr/parts/submodules/jasper.py:476: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "      with torch.cuda.amp.autocast(enabled=False):\n",
            "    \n",
            "[1/5] extract embeddings: 100%|| 20/20 [00:02<00:00,  9.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:10:38 clustering_diarizer:393] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-11-13 14:10:38 clustering_diarizer:291] Subsegmentation for embedding extraction: scale1, /content/temp_outputs/speaker_outputs/subsegments_scale1.json\n",
            "[NeMo I 2024-11-13 14:10:38 clustering_diarizer:347] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-11-13 14:10:38 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-11-13 14:10:38 collections:741] Dataset successfully loaded with 1329 items and total duration provided from manifest is  0.23 hours.\n",
            "[NeMo I 2024-11-13 14:10:38 collections:746] # 1329 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[2/5] extract embeddings: 100%|| 21/21 [00:01<00:00, 12.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:10:40 clustering_diarizer:393] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-11-13 14:10:40 clustering_diarizer:291] Subsegmentation for embedding extraction: scale2, /content/temp_outputs/speaker_outputs/subsegments_scale2.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:10:40 clustering_diarizer:347] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-11-13 14:10:40 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-11-13 14:10:40 collections:741] Dataset successfully loaded with 1485 items and total duration provided from manifest is  0.25 hours.\n",
            "[NeMo I 2024-11-13 14:10:40 collections:746] # 1485 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[3/5] extract embeddings: 100%|| 24/24 [00:01<00:00, 13.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:10:42 clustering_diarizer:393] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-11-13 14:10:42 clustering_diarizer:291] Subsegmentation for embedding extraction: scale3, /content/temp_outputs/speaker_outputs/subsegments_scale3.json\n",
            "[NeMo I 2024-11-13 14:10:42 clustering_diarizer:347] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-11-13 14:10:42 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-11-13 14:10:42 collections:741] Dataset successfully loaded with 1778 items and total duration provided from manifest is  0.26 hours.\n",
            "[NeMo I 2024-11-13 14:10:42 collections:746] # 1778 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[4/5] extract embeddings: 100%|| 28/28 [00:01<00:00, 15.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:10:45 clustering_diarizer:393] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-11-13 14:10:45 clustering_diarizer:291] Subsegmentation for embedding extraction: scale4, /content/temp_outputs/speaker_outputs/subsegments_scale4.json\n",
            "[NeMo I 2024-11-13 14:10:45 clustering_diarizer:347] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-11-13 14:10:45 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-11-13 14:10:45 collections:741] Dataset successfully loaded with 2525 items and total duration provided from manifest is  0.29 hours.\n",
            "[NeMo I 2024-11-13 14:10:45 collections:746] # 2525 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[5/5] extract embeddings: 100%|| 40/40 [00:02<00:00, 14.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:10:48 clustering_diarizer:393] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "clustering: 100%|| 1/1 [00:00<00:00,  1.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:10:49 clustering_diarizer:461] Outputs are saved in /content/temp_outputs directory\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[NeMo W 2024-11-13 14:10:49 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:10:49 msdd_models:966] Loading embedding pickle file of scale:0 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale0_embeddings.pkl\n",
            "[NeMo I 2024-11-13 14:10:49 msdd_models:966] Loading embedding pickle file of scale:1 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale1_embeddings.pkl\n",
            "[NeMo I 2024-11-13 14:10:49 msdd_models:966] Loading embedding pickle file of scale:2 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale2_embeddings.pkl\n",
            "[NeMo I 2024-11-13 14:10:49 msdd_models:966] Loading embedding pickle file of scale:3 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale3_embeddings.pkl\n",
            "[NeMo I 2024-11-13 14:10:49 msdd_models:966] Loading embedding pickle file of scale:4 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale4_embeddings.pkl\n",
            "[NeMo I 2024-11-13 14:10:49 msdd_models:944] Loading cluster label file from /content/temp_outputs/speaker_outputs/subsegments_scale4_cluster.label\n",
            "[NeMo I 2024-11-13 14:10:49 collections:1067] Filtered duration for loading collection is 0.000000.\n",
            "[NeMo I 2024-11-13 14:10:49 collections:1071] Total 1 session files loaded accounting to # 1 audio clips\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/1 [00:00<?, ?it/s][NeMo W 2024-11-13 14:10:49 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/collections/asr/models/msdd_models.py:1333: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "      with autocast():\n",
            "    \n",
            "100%|| 1/1 [00:00<00:00,  9.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:10:49 msdd_models:1407]      [Threshold: 0.7000] [use_clus_as_main=False] [diar_window=50]\n",
            "[NeMo I 2024-11-13 14:10:49 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2024-11-13 14:10:49 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[NeMo W 2024-11-13 14:10:50 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:10:50 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-11-13 14:10:50 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:10:50 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-11-13 14:10:50 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:10:50 msdd_models:1435]   \n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Punctuation restoration is not available for ru language. Using the original punctuation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:12:07 msdd_models:1097] Loading pretrained diar_msdd_telephonic model from NGC\n",
            "[NeMo I 2024-11-13 14:12:07 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_2.0.0rc1/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
            "[NeMo I 2024-11-13 14:12:07 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_2.0.0rc1/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo\n",
            "[NeMo I 2024-11-13 14:12:07 common:826] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-11-13 14:12:09 modelPT:176] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: true\n",
            "    \n",
            "[NeMo W 2024-11-13 14:12:09 modelPT:183] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    \n",
            "[NeMo W 2024-11-13 14:12:09 modelPT:189] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    seq_eval_mode: false\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:12:09 features:305] PADDING: 16\n",
            "[NeMo I 2024-11-13 14:12:09 features:305] PADDING: 16\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-11-13 14:12:10 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/core/connectors/save_restore_connector.py:617: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "      return torch.load(model_weights, map_location='cpu')\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:12:10 save_restore_connector:272] Model EncDecDiarLabelModel was successfully restored from /root/.cache/torch/NeMo/NeMo_2.0.0rc1/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
            "[NeMo I 2024-11-13 14:12:10 features:305] PADDING: 16\n",
            "[NeMo I 2024-11-13 14:12:10 clustering_diarizer:127] Loading pretrained vad_multilingual_marblenet model from NGC\n",
            "[NeMo I 2024-11-13 14:12:10 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_2.0.0rc1/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
            "[NeMo I 2024-11-13 14:12:10 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_2.0.0rc1/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo\n",
            "[NeMo I 2024-11-13 14:12:10 common:826] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-11-13 14:12:11 modelPT:176] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: /manifests/ami_train_0.63.json,/manifests/freesound_background_train.json,/manifests/freesound_laughter_train.json,/manifests/fisher_2004_background.json,/manifests/fisher_2004_speech_sampled.json,/manifests/google_train_manifest.json,/manifests/icsi_all_0.63.json,/manifests/musan_freesound_train.json,/manifests/musan_music_train.json,/manifests/musan_soundbible_train.json,/manifests/mandarin_train_sample.json,/manifests/german_train_sample.json,/manifests/spanish_train_sample.json,/manifests/french_train_sample.json,/manifests/russian_train_sample.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: true\n",
            "    is_tarred: false\n",
            "    tarred_audio_filepaths: null\n",
            "    tarred_shard_strategy: scatter\n",
            "    augmentor:\n",
            "      shift:\n",
            "        prob: 0.5\n",
            "        min_shift_ms: -10.0\n",
            "        max_shift_ms: 10.0\n",
            "      white_noise:\n",
            "        prob: 0.5\n",
            "        min_level: -90\n",
            "        max_level: -46\n",
            "        norm: true\n",
            "      noise:\n",
            "        prob: 0.5\n",
            "        manifest_path: /manifests/noise_0_1_musan_fs.json\n",
            "        min_snr_db: 0\n",
            "        max_snr_db: 30\n",
            "        max_gain_db: 300.0\n",
            "        norm: true\n",
            "      gain:\n",
            "        prob: 0.5\n",
            "        min_gain_dbfs: -10.0\n",
            "        max_gain_dbfs: 10.0\n",
            "        norm: true\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2024-11-13 14:12:11 modelPT:183] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: /manifests/ami_dev_0.63.json,/manifests/freesound_background_dev.json,/manifests/freesound_laughter_dev.json,/manifests/ch120_moved_0.63.json,/manifests/fisher_2005_500_speech_sampled.json,/manifests/google_dev_manifest.json,/manifests/musan_music_dev.json,/manifests/mandarin_dev.json,/manifests/german_dev.json,/manifests/spanish_dev.json,/manifests/french_dev.json,/manifests/russian_dev.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: false\n",
            "    val_loss_idx: 0\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2024-11-13 14:12:11 modelPT:189] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 128\n",
            "    shuffle: false\n",
            "    test_loss_idx: 0\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:12:11 features:305] PADDING: 16\n",
            "[NeMo I 2024-11-13 14:12:11 save_restore_connector:272] Model EncDecClassificationModel was successfully restored from /root/.cache/torch/NeMo/NeMo_2.0.0rc1/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
            "[NeMo I 2024-11-13 14:12:11 msdd_models:870] Multiscale Weights: [1, 1, 1, 1, 1]\n",
            "[NeMo I 2024-11-13 14:12:11 msdd_models:871] Clustering Parameters: {\n",
            "        \"oracle_num_speakers\": false,\n",
            "        \"max_num_speakers\": 8,\n",
            "        \"enhanced_count_thres\": 80,\n",
            "        \"max_rp_threshold\": 0.25,\n",
            "        \"sparse_search_volume\": 30,\n",
            "        \"maj_vote_spk_count\": false,\n",
            "        \"chunk_cluster_count\": 50,\n",
            "        \"embeddings_per_chunk\": 10000\n",
            "    }\n",
            "[NeMo I 2024-11-13 14:12:11 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2024-11-13 14:12:11 clustering_diarizer:313] Split long audio file to avoid CUDA memory issue\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "splitting manifest: 100%|| 1/1 [00:00<00:00, 36.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:12:11 classification_models:293] Perform streaming frame-level VAD\n",
            "[NeMo I 2024-11-13 14:12:11 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-11-13 14:12:11 collections:741] Dataset successfully loaded with 6 items and total duration provided from manifest is  0.08 hours.\n",
            "[NeMo I 2024-11-13 14:12:11 collections:746] # 6 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "vad:   0%|          | 0/6 [00:00<?, ?it/s][NeMo W 2024-11-13 14:12:11 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/collections/asr/models/clustering_diarizer.py:226: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "      with autocast():\n",
            "    \n",
            "[NeMo W 2024-11-13 14:12:11 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/collections/asr/parts/preprocessing/features.py:436: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "      with torch.cuda.amp.autocast(enabled=False):\n",
            "    \n",
            "vad: 100%|| 6/6 [00:01<00:00,  4.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:12:12 clustering_diarizer:254] Generating predictions with overlapping input segments\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "                                                               "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:12:15 clustering_diarizer:266] Converting frame level prediction to speech/no-speech segment in start and end times format.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "creating speech segments: 100%|| 1/1 [00:00<00:00,  2.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:12:15 clustering_diarizer:291] Subsegmentation for embedding extraction: scale0, /content/temp_outputs/speaker_outputs/subsegments_scale0.json\n",
            "[NeMo I 2024-11-13 14:12:15 clustering_diarizer:347] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-11-13 14:12:15 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-11-13 14:12:15 collections:741] Dataset successfully loaded with 216 items and total duration provided from manifest is  0.05 hours.\n",
            "[NeMo I 2024-11-13 14:12:15 collections:746] # 216 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[1/5] extract embeddings:   0%|          | 0/4 [00:00<?, ?it/s][NeMo W 2024-11-13 14:12:15 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/collections/asr/models/clustering_diarizer.py:362: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "      with autocast():\n",
            "    \n",
            "[NeMo W 2024-11-13 14:12:15 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/collections/asr/parts/submodules/jasper.py:476: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "      with torch.cuda.amp.autocast(enabled=False):\n",
            "    \n",
            "[1/5] extract embeddings: 100%|| 4/4 [00:00<00:00,  8.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:12:16 clustering_diarizer:393] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-11-13 14:12:16 clustering_diarizer:291] Subsegmentation for embedding extraction: scale1, /content/temp_outputs/speaker_outputs/subsegments_scale1.json\n",
            "[NeMo I 2024-11-13 14:12:16 clustering_diarizer:347] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-11-13 14:12:16 collections:740] Filtered duration for loading collection is  0.00 hours.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:12:16 collections:741] Dataset successfully loaded with 241 items and total duration provided from manifest is  0.05 hours.\n",
            "[NeMo I 2024-11-13 14:12:16 collections:746] # 241 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[2/5] extract embeddings: 100%|| 4/4 [00:00<00:00, 11.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:12:16 clustering_diarizer:393] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-11-13 14:12:16 clustering_diarizer:291] Subsegmentation for embedding extraction: scale2, /content/temp_outputs/speaker_outputs/subsegments_scale2.json\n",
            "[NeMo I 2024-11-13 14:12:16 clustering_diarizer:347] Extracting embeddings for Diarization\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:12:16 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-11-13 14:12:16 collections:741] Dataset successfully loaded with 276 items and total duration provided from manifest is  0.05 hours.\n",
            "[NeMo I 2024-11-13 14:12:16 collections:746] # 276 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[3/5] extract embeddings: 100%|| 5/5 [00:00<00:00, 11.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:12:17 clustering_diarizer:393] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-11-13 14:12:17 clustering_diarizer:291] Subsegmentation for embedding extraction: scale3, /content/temp_outputs/speaker_outputs/subsegments_scale3.json\n",
            "[NeMo I 2024-11-13 14:12:17 clustering_diarizer:347] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-11-13 14:12:17 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-11-13 14:12:17 collections:741] Dataset successfully loaded with 338 items and total duration provided from manifest is  0.05 hours.\n",
            "[NeMo I 2024-11-13 14:12:17 collections:746] # 338 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[4/5] extract embeddings: 100%|| 6/6 [00:00<00:00, 14.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:12:17 clustering_diarizer:393] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-11-13 14:12:17 clustering_diarizer:291] Subsegmentation for embedding extraction: scale4, /content/temp_outputs/speaker_outputs/subsegments_scale4.json\n",
            "[NeMo I 2024-11-13 14:12:17 clustering_diarizer:347] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-11-13 14:12:17 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-11-13 14:12:17 collections:741] Dataset successfully loaded with 502 items and total duration provided from manifest is  0.06 hours.\n",
            "[NeMo I 2024-11-13 14:12:17 collections:746] # 502 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[5/5] extract embeddings: 100%|| 8/8 [00:00<00:00, 17.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:12:18 clustering_diarizer:393] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "clustering: 100%|| 1/1 [00:00<00:00,  1.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:12:18 clustering_diarizer:461] Outputs are saved in /content/temp_outputs directory\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[NeMo W 2024-11-13 14:12:18 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:12:18 msdd_models:966] Loading embedding pickle file of scale:0 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale0_embeddings.pkl\n",
            "[NeMo I 2024-11-13 14:12:18 msdd_models:966] Loading embedding pickle file of scale:1 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale1_embeddings.pkl\n",
            "[NeMo I 2024-11-13 14:12:18 msdd_models:966] Loading embedding pickle file of scale:2 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale2_embeddings.pkl\n",
            "[NeMo I 2024-11-13 14:12:18 msdd_models:966] Loading embedding pickle file of scale:3 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale3_embeddings.pkl\n",
            "[NeMo I 2024-11-13 14:12:18 msdd_models:966] Loading embedding pickle file of scale:4 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale4_embeddings.pkl\n",
            "[NeMo I 2024-11-13 14:12:18 msdd_models:944] Loading cluster label file from /content/temp_outputs/speaker_outputs/subsegments_scale4_cluster.label\n",
            "[NeMo I 2024-11-13 14:12:18 collections:1067] Filtered duration for loading collection is 0.000000.\n",
            "[NeMo I 2024-11-13 14:12:18 collections:1071] Total 1 session files loaded accounting to # 1 audio clips\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/1 [00:00<?, ?it/s][NeMo W 2024-11-13 14:12:18 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/collections/asr/models/msdd_models.py:1333: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "      with autocast():\n",
            "    \n",
            "100%|| 1/1 [00:00<00:00, 26.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:12:18 msdd_models:1407]      [Threshold: 0.7000] [use_clus_as_main=False] [diar_window=50]\n",
            "[NeMo I 2024-11-13 14:12:18 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2024-11-13 14:12:18 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[NeMo W 2024-11-13 14:12:18 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:12:18 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-11-13 14:12:19 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:12:19 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-11-13 14:12:19 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:12:19 msdd_models:1435]   \n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Punctuation restoration is not available for ru language. Using the original punctuation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:14:54 msdd_models:1097] Loading pretrained diar_msdd_telephonic model from NGC\n",
            "[NeMo I 2024-11-13 14:14:54 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_2.0.0rc1/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
            "[NeMo I 2024-11-13 14:14:54 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_2.0.0rc1/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo\n",
            "[NeMo I 2024-11-13 14:14:54 common:826] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-11-13 14:14:55 modelPT:176] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: true\n",
            "    \n",
            "[NeMo W 2024-11-13 14:14:55 modelPT:183] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    \n",
            "[NeMo W 2024-11-13 14:14:55 modelPT:189] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    seq_eval_mode: false\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:14:55 features:305] PADDING: 16\n",
            "[NeMo I 2024-11-13 14:14:56 features:305] PADDING: 16\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-11-13 14:14:56 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/core/connectors/save_restore_connector.py:617: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "      return torch.load(model_weights, map_location='cpu')\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:14:58 save_restore_connector:272] Model EncDecDiarLabelModel was successfully restored from /root/.cache/torch/NeMo/NeMo_2.0.0rc1/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
            "[NeMo I 2024-11-13 14:14:58 features:305] PADDING: 16\n",
            "[NeMo I 2024-11-13 14:14:59 clustering_diarizer:127] Loading pretrained vad_multilingual_marblenet model from NGC\n",
            "[NeMo I 2024-11-13 14:14:59 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_2.0.0rc1/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
            "[NeMo I 2024-11-13 14:14:59 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_2.0.0rc1/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo\n",
            "[NeMo I 2024-11-13 14:14:59 common:826] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-11-13 14:15:00 modelPT:176] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: /manifests/ami_train_0.63.json,/manifests/freesound_background_train.json,/manifests/freesound_laughter_train.json,/manifests/fisher_2004_background.json,/manifests/fisher_2004_speech_sampled.json,/manifests/google_train_manifest.json,/manifests/icsi_all_0.63.json,/manifests/musan_freesound_train.json,/manifests/musan_music_train.json,/manifests/musan_soundbible_train.json,/manifests/mandarin_train_sample.json,/manifests/german_train_sample.json,/manifests/spanish_train_sample.json,/manifests/french_train_sample.json,/manifests/russian_train_sample.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: true\n",
            "    is_tarred: false\n",
            "    tarred_audio_filepaths: null\n",
            "    tarred_shard_strategy: scatter\n",
            "    augmentor:\n",
            "      shift:\n",
            "        prob: 0.5\n",
            "        min_shift_ms: -10.0\n",
            "        max_shift_ms: 10.0\n",
            "      white_noise:\n",
            "        prob: 0.5\n",
            "        min_level: -90\n",
            "        max_level: -46\n",
            "        norm: true\n",
            "      noise:\n",
            "        prob: 0.5\n",
            "        manifest_path: /manifests/noise_0_1_musan_fs.json\n",
            "        min_snr_db: 0\n",
            "        max_snr_db: 30\n",
            "        max_gain_db: 300.0\n",
            "        norm: true\n",
            "      gain:\n",
            "        prob: 0.5\n",
            "        min_gain_dbfs: -10.0\n",
            "        max_gain_dbfs: 10.0\n",
            "        norm: true\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2024-11-13 14:15:00 modelPT:183] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: /manifests/ami_dev_0.63.json,/manifests/freesound_background_dev.json,/manifests/freesound_laughter_dev.json,/manifests/ch120_moved_0.63.json,/manifests/fisher_2005_500_speech_sampled.json,/manifests/google_dev_manifest.json,/manifests/musan_music_dev.json,/manifests/mandarin_dev.json,/manifests/german_dev.json,/manifests/spanish_dev.json,/manifests/french_dev.json,/manifests/russian_dev.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: false\n",
            "    val_loss_idx: 0\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2024-11-13 14:15:00 modelPT:189] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 128\n",
            "    shuffle: false\n",
            "    test_loss_idx: 0\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:15:00 features:305] PADDING: 16\n",
            "[NeMo I 2024-11-13 14:15:00 save_restore_connector:272] Model EncDecClassificationModel was successfully restored from /root/.cache/torch/NeMo/NeMo_2.0.0rc1/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
            "[NeMo I 2024-11-13 14:15:00 msdd_models:870] Multiscale Weights: [1, 1, 1, 1, 1]\n",
            "[NeMo I 2024-11-13 14:15:00 msdd_models:871] Clustering Parameters: {\n",
            "        \"oracle_num_speakers\": false,\n",
            "        \"max_num_speakers\": 8,\n",
            "        \"enhanced_count_thres\": 80,\n",
            "        \"max_rp_threshold\": 0.25,\n",
            "        \"sparse_search_volume\": 30,\n",
            "        \"maj_vote_spk_count\": false,\n",
            "        \"chunk_cluster_count\": 50,\n",
            "        \"embeddings_per_chunk\": 10000\n",
            "    }\n",
            "[NeMo I 2024-11-13 14:15:00 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2024-11-13 14:15:00 clustering_diarizer:313] Split long audio file to avoid CUDA memory issue\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "splitting manifest: 100%|| 1/1 [00:00<00:00,  9.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:15:00 classification_models:293] Perform streaming frame-level VAD\n",
            "[NeMo I 2024-11-13 14:15:00 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-11-13 14:15:00 collections:741] Dataset successfully loaded with 19 items and total duration provided from manifest is  0.26 hours.\n",
            "[NeMo I 2024-11-13 14:15:00 collections:746] # 19 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "vad:   0%|          | 0/19 [00:00<?, ?it/s][NeMo W 2024-11-13 14:15:00 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/collections/asr/models/clustering_diarizer.py:226: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "      with autocast():\n",
            "    \n",
            "[NeMo W 2024-11-13 14:15:00 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/collections/asr/parts/preprocessing/features.py:436: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "      with torch.cuda.amp.autocast(enabled=False):\n",
            "    \n",
            "vad: 100%|| 19/19 [00:04<00:00,  4.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:15:04 clustering_diarizer:254] Generating predictions with overlapping input segments\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "                                                               "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:15:13 clustering_diarizer:266] Converting frame level prediction to speech/no-speech segment in start and end times format.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "creating speech segments: 100%|| 1/1 [00:01<00:00,  1.03s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:15:14 clustering_diarizer:291] Subsegmentation for embedding extraction: scale0, /content/temp_outputs/speaker_outputs/subsegments_scale0.json\n",
            "[NeMo I 2024-11-13 14:15:14 clustering_diarizer:347] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-11-13 14:15:14 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-11-13 14:15:14 collections:741] Dataset successfully loaded with 614 items and total duration provided from manifest is  0.08 hours.\n",
            "[NeMo I 2024-11-13 14:15:14 collections:746] # 614 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[1/5] extract embeddings:   0%|          | 0/10 [00:00<?, ?it/s][NeMo W 2024-11-13 14:15:14 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/collections/asr/models/clustering_diarizer.py:362: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "      with autocast():\n",
            "    \n",
            "[NeMo W 2024-11-13 14:15:14 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/collections/asr/parts/submodules/jasper.py:476: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "      with torch.cuda.amp.autocast(enabled=False):\n",
            "    \n",
            "[1/5] extract embeddings: 100%|| 10/10 [00:01<00:00,  9.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:15:15 clustering_diarizer:393] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-11-13 14:15:15 clustering_diarizer:291] Subsegmentation for embedding extraction: scale1, /content/temp_outputs/speaker_outputs/subsegments_scale1.json\n",
            "[NeMo I 2024-11-13 14:15:15 clustering_diarizer:347] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-11-13 14:15:15 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-11-13 14:15:15 collections:741] Dataset successfully loaded with 641 items and total duration provided from manifest is  0.08 hours.\n",
            "[NeMo I 2024-11-13 14:15:15 collections:746] # 641 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[2/5] extract embeddings: 100%|| 11/11 [00:00<00:00, 12.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:15:16 clustering_diarizer:393] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-11-13 14:15:16 clustering_diarizer:291] Subsegmentation for embedding extraction: scale2, /content/temp_outputs/speaker_outputs/subsegments_scale2.json\n",
            "[NeMo I 2024-11-13 14:15:16 clustering_diarizer:347] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-11-13 14:15:16 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-11-13 14:15:16 collections:741] Dataset successfully loaded with 677 items and total duration provided from manifest is  0.08 hours.\n",
            "[NeMo I 2024-11-13 14:15:16 collections:746] # 677 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[3/5] extract embeddings: 100%|| 11/11 [00:00<00:00, 13.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:15:17 clustering_diarizer:393] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-11-13 14:15:17 clustering_diarizer:291] Subsegmentation for embedding extraction: scale3, /content/temp_outputs/speaker_outputs/subsegments_scale3.json\n",
            "[NeMo I 2024-11-13 14:15:17 clustering_diarizer:347] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-11-13 14:15:17 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-11-13 14:15:17 collections:741] Dataset successfully loaded with 756 items and total duration provided from manifest is  0.09 hours.\n",
            "[NeMo I 2024-11-13 14:15:17 collections:746] # 756 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[4/5] extract embeddings: 100%|| 12/12 [00:00<00:00, 16.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:15:18 clustering_diarizer:393] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-11-13 14:15:18 clustering_diarizer:291] Subsegmentation for embedding extraction: scale4, /content/temp_outputs/speaker_outputs/subsegments_scale4.json\n",
            "[NeMo I 2024-11-13 14:15:18 clustering_diarizer:347] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-11-13 14:15:18 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-11-13 14:15:18 collections:741] Dataset successfully loaded with 986 items and total duration provided from manifest is  0.10 hours.\n",
            "[NeMo I 2024-11-13 14:15:18 collections:746] # 986 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[5/5] extract embeddings: 100%|| 16/16 [00:00<00:00, 17.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:15:19 clustering_diarizer:393] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "clustering: 100%|| 1/1 [00:00<00:00,  1.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:15:19 clustering_diarizer:461] Outputs are saved in /content/temp_outputs directory\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[NeMo W 2024-11-13 14:15:19 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:15:19 msdd_models:966] Loading embedding pickle file of scale:0 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale0_embeddings.pkl\n",
            "[NeMo I 2024-11-13 14:15:19 msdd_models:966] Loading embedding pickle file of scale:1 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale1_embeddings.pkl\n",
            "[NeMo I 2024-11-13 14:15:19 msdd_models:966] Loading embedding pickle file of scale:2 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale2_embeddings.pkl\n",
            "[NeMo I 2024-11-13 14:15:19 msdd_models:966] Loading embedding pickle file of scale:3 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale3_embeddings.pkl\n",
            "[NeMo I 2024-11-13 14:15:19 msdd_models:966] Loading embedding pickle file of scale:4 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale4_embeddings.pkl\n",
            "[NeMo I 2024-11-13 14:15:19 msdd_models:944] Loading cluster label file from /content/temp_outputs/speaker_outputs/subsegments_scale4_cluster.label\n",
            "[NeMo I 2024-11-13 14:15:20 collections:1067] Filtered duration for loading collection is 0.000000.\n",
            "[NeMo I 2024-11-13 14:15:20 collections:1071] Total 1 session files loaded accounting to # 1 audio clips\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/1 [00:00<?, ?it/s][NeMo W 2024-11-13 14:15:20 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/collections/asr/models/msdd_models.py:1333: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "      with autocast():\n",
            "    \n",
            "100%|| 1/1 [00:00<00:00, 19.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:15:20 msdd_models:1407]      [Threshold: 0.7000] [use_clus_as_main=False] [diar_window=50]\n",
            "[NeMo I 2024-11-13 14:15:20 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2024-11-13 14:15:20 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[NeMo W 2024-11-13 14:15:20 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:15:20 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-11-13 14:15:20 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:15:20 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-11-13 14:15:20 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:15:20 msdd_models:1435]   \n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Punctuation restoration is not available for ru language. Using the original punctuation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:19:48 msdd_models:1097] Loading pretrained diar_msdd_telephonic model from NGC\n",
            "[NeMo I 2024-11-13 14:19:48 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_2.0.0rc1/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
            "[NeMo I 2024-11-13 14:19:48 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_2.0.0rc1/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo\n",
            "[NeMo I 2024-11-13 14:19:48 common:826] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-11-13 14:19:50 modelPT:176] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: true\n",
            "    \n",
            "[NeMo W 2024-11-13 14:19:50 modelPT:183] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    \n",
            "[NeMo W 2024-11-13 14:19:50 modelPT:189] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    seq_eval_mode: false\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:19:50 features:305] PADDING: 16\n",
            "[NeMo I 2024-11-13 14:19:50 features:305] PADDING: 16\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-11-13 14:19:51 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/core/connectors/save_restore_connector.py:617: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "      return torch.load(model_weights, map_location='cpu')\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:19:53 save_restore_connector:272] Model EncDecDiarLabelModel was successfully restored from /root/.cache/torch/NeMo/NeMo_2.0.0rc1/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
            "[NeMo I 2024-11-13 14:19:53 features:305] PADDING: 16\n",
            "[NeMo I 2024-11-13 14:19:53 clustering_diarizer:127] Loading pretrained vad_multilingual_marblenet model from NGC\n",
            "[NeMo I 2024-11-13 14:19:53 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_2.0.0rc1/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
            "[NeMo I 2024-11-13 14:19:53 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_2.0.0rc1/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo\n",
            "[NeMo I 2024-11-13 14:19:53 common:826] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-11-13 14:19:53 modelPT:176] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: /manifests/ami_train_0.63.json,/manifests/freesound_background_train.json,/manifests/freesound_laughter_train.json,/manifests/fisher_2004_background.json,/manifests/fisher_2004_speech_sampled.json,/manifests/google_train_manifest.json,/manifests/icsi_all_0.63.json,/manifests/musan_freesound_train.json,/manifests/musan_music_train.json,/manifests/musan_soundbible_train.json,/manifests/mandarin_train_sample.json,/manifests/german_train_sample.json,/manifests/spanish_train_sample.json,/manifests/french_train_sample.json,/manifests/russian_train_sample.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: true\n",
            "    is_tarred: false\n",
            "    tarred_audio_filepaths: null\n",
            "    tarred_shard_strategy: scatter\n",
            "    augmentor:\n",
            "      shift:\n",
            "        prob: 0.5\n",
            "        min_shift_ms: -10.0\n",
            "        max_shift_ms: 10.0\n",
            "      white_noise:\n",
            "        prob: 0.5\n",
            "        min_level: -90\n",
            "        max_level: -46\n",
            "        norm: true\n",
            "      noise:\n",
            "        prob: 0.5\n",
            "        manifest_path: /manifests/noise_0_1_musan_fs.json\n",
            "        min_snr_db: 0\n",
            "        max_snr_db: 30\n",
            "        max_gain_db: 300.0\n",
            "        norm: true\n",
            "      gain:\n",
            "        prob: 0.5\n",
            "        min_gain_dbfs: -10.0\n",
            "        max_gain_dbfs: 10.0\n",
            "        norm: true\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2024-11-13 14:19:53 modelPT:183] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: /manifests/ami_dev_0.63.json,/manifests/freesound_background_dev.json,/manifests/freesound_laughter_dev.json,/manifests/ch120_moved_0.63.json,/manifests/fisher_2005_500_speech_sampled.json,/manifests/google_dev_manifest.json,/manifests/musan_music_dev.json,/manifests/mandarin_dev.json,/manifests/german_dev.json,/manifests/spanish_dev.json,/manifests/french_dev.json,/manifests/russian_dev.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: false\n",
            "    val_loss_idx: 0\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2024-11-13 14:19:53 modelPT:189] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 128\n",
            "    shuffle: false\n",
            "    test_loss_idx: 0\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:19:53 features:305] PADDING: 16\n",
            "[NeMo I 2024-11-13 14:19:53 save_restore_connector:272] Model EncDecClassificationModel was successfully restored from /root/.cache/torch/NeMo/NeMo_2.0.0rc1/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
            "[NeMo I 2024-11-13 14:19:54 msdd_models:870] Multiscale Weights: [1, 1, 1, 1, 1]\n",
            "[NeMo I 2024-11-13 14:19:54 msdd_models:871] Clustering Parameters: {\n",
            "        \"oracle_num_speakers\": false,\n",
            "        \"max_num_speakers\": 8,\n",
            "        \"enhanced_count_thres\": 80,\n",
            "        \"max_rp_threshold\": 0.25,\n",
            "        \"sparse_search_volume\": 30,\n",
            "        \"maj_vote_spk_count\": false,\n",
            "        \"chunk_cluster_count\": 50,\n",
            "        \"embeddings_per_chunk\": 10000\n",
            "    }\n",
            "[NeMo I 2024-11-13 14:19:54 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2024-11-13 14:19:54 clustering_diarizer:313] Split long audio file to avoid CUDA memory issue\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "splitting manifest: 100%|| 1/1 [00:00<00:00,  7.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:19:54 classification_models:293] Perform streaming frame-level VAD\n",
            "[NeMo I 2024-11-13 14:19:54 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-11-13 14:19:54 collections:741] Dataset successfully loaded with 25 items and total duration provided from manifest is  0.34 hours.\n",
            "[NeMo I 2024-11-13 14:19:54 collections:746] # 25 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "vad:   0%|          | 0/25 [00:00<?, ?it/s][NeMo W 2024-11-13 14:19:54 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/collections/asr/models/clustering_diarizer.py:226: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "      with autocast():\n",
            "    \n",
            "[NeMo W 2024-11-13 14:19:54 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/collections/asr/parts/preprocessing/features.py:436: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "      with torch.cuda.amp.autocast(enabled=False):\n",
            "    \n",
            "vad: 100%|| 25/25 [00:05<00:00,  4.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:19:59 clustering_diarizer:254] Generating predictions with overlapping input segments\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "                                                               "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:20:11 clustering_diarizer:266] Converting frame level prediction to speech/no-speech segment in start and end times format.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "creating speech segments: 100%|| 1/1 [00:00<00:00,  1.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:20:12 clustering_diarizer:291] Subsegmentation for embedding extraction: scale0, /content/temp_outputs/speaker_outputs/subsegments_scale0.json\n",
            "[NeMo I 2024-11-13 14:20:12 clustering_diarizer:347] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-11-13 14:20:12 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-11-13 14:20:12 collections:741] Dataset successfully loaded with 983 items and total duration provided from manifest is  0.20 hours.\n",
            "[NeMo I 2024-11-13 14:20:12 collections:746] # 983 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[1/5] extract embeddings:   0%|          | 0/16 [00:00<?, ?it/s][NeMo W 2024-11-13 14:20:12 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/collections/asr/models/clustering_diarizer.py:362: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "      with autocast():\n",
            "    \n",
            "[NeMo W 2024-11-13 14:20:12 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/collections/asr/parts/submodules/jasper.py:476: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "      with torch.cuda.amp.autocast(enabled=False):\n",
            "    \n",
            "[1/5] extract embeddings: 100%|| 16/16 [00:01<00:00,  8.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:20:14 clustering_diarizer:393] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-11-13 14:20:14 clustering_diarizer:291] Subsegmentation for embedding extraction: scale1, /content/temp_outputs/speaker_outputs/subsegments_scale1.json\n",
            "[NeMo I 2024-11-13 14:20:14 clustering_diarizer:347] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-11-13 14:20:14 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-11-13 14:20:14 collections:741] Dataset successfully loaded with 1076 items and total duration provided from manifest is  0.21 hours.\n",
            "[NeMo I 2024-11-13 14:20:14 collections:746] # 1076 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[2/5] extract embeddings: 100%|| 17/17 [00:01<00:00,  9.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:20:17 clustering_diarizer:393] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-11-13 14:20:17 clustering_diarizer:291] Subsegmentation for embedding extraction: scale2, /content/temp_outputs/speaker_outputs/subsegments_scale2.json\n",
            "[NeMo I 2024-11-13 14:20:17 clustering_diarizer:347] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-11-13 14:20:17 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-11-13 14:20:17 collections:741] Dataset successfully loaded with 1233 items and total duration provided from manifest is  0.23 hours.\n",
            "[NeMo I 2024-11-13 14:20:17 collections:746] # 1233 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[3/5] extract embeddings: 100%|| 20/20 [00:01<00:00, 13.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:20:19 clustering_diarizer:393] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-11-13 14:20:19 clustering_diarizer:291] Subsegmentation for embedding extraction: scale3, /content/temp_outputs/speaker_outputs/subsegments_scale3.json\n",
            "[NeMo I 2024-11-13 14:20:19 clustering_diarizer:347] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-11-13 14:20:19 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-11-13 14:20:19 collections:741] Dataset successfully loaded with 1529 items and total duration provided from manifest is  0.24 hours.\n",
            "[NeMo I 2024-11-13 14:20:19 collections:746] # 1529 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[4/5] extract embeddings: 100%|| 24/24 [00:01<00:00, 15.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:20:20 clustering_diarizer:393] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-11-13 14:20:20 clustering_diarizer:291] Subsegmentation for embedding extraction: scale4, /content/temp_outputs/speaker_outputs/subsegments_scale4.json\n",
            "[NeMo I 2024-11-13 14:20:20 clustering_diarizer:347] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-11-13 14:20:20 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-11-13 14:20:20 collections:741] Dataset successfully loaded with 2235 items and total duration provided from manifest is  0.27 hours.\n",
            "[NeMo I 2024-11-13 14:20:20 collections:746] # 2235 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[5/5] extract embeddings: 100%|| 35/35 [00:02<00:00, 17.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:20:23 clustering_diarizer:393] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "clustering: 100%|| 1/1 [00:01<00:00,  1.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:20:24 clustering_diarizer:461] Outputs are saved in /content/temp_outputs directory\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[NeMo W 2024-11-13 14:20:24 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:20:24 msdd_models:966] Loading embedding pickle file of scale:0 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale0_embeddings.pkl\n",
            "[NeMo I 2024-11-13 14:20:24 msdd_models:966] Loading embedding pickle file of scale:1 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale1_embeddings.pkl\n",
            "[NeMo I 2024-11-13 14:20:24 msdd_models:966] Loading embedding pickle file of scale:2 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale2_embeddings.pkl\n",
            "[NeMo I 2024-11-13 14:20:24 msdd_models:966] Loading embedding pickle file of scale:3 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale3_embeddings.pkl\n",
            "[NeMo I 2024-11-13 14:20:24 msdd_models:966] Loading embedding pickle file of scale:4 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale4_embeddings.pkl\n",
            "[NeMo I 2024-11-13 14:20:24 msdd_models:944] Loading cluster label file from /content/temp_outputs/speaker_outputs/subsegments_scale4_cluster.label\n",
            "[NeMo I 2024-11-13 14:20:24 collections:1067] Filtered duration for loading collection is 0.000000.\n",
            "[NeMo I 2024-11-13 14:20:24 collections:1071] Total 1 session files loaded accounting to # 1 audio clips\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/1 [00:00<?, ?it/s][NeMo W 2024-11-13 14:20:25 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/collections/asr/models/msdd_models.py:1333: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "      with autocast():\n",
            "    \n",
            "100%|| 1/1 [00:00<00:00,  7.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:20:25 msdd_models:1407]      [Threshold: 0.7000] [use_clus_as_main=False] [diar_window=50]\n",
            "[NeMo I 2024-11-13 14:20:25 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2024-11-13 14:20:25 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[NeMo W 2024-11-13 14:20:25 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:20:25 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-11-13 14:20:25 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:20:25 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-11-13 14:20:25 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:20:25 msdd_models:1435]   \n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Punctuation restoration is not available for ru language. Using the original punctuation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:22:33 msdd_models:1097] Loading pretrained diar_msdd_telephonic model from NGC\n",
            "[NeMo I 2024-11-13 14:22:33 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_2.0.0rc1/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
            "[NeMo I 2024-11-13 14:22:33 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_2.0.0rc1/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo\n",
            "[NeMo I 2024-11-13 14:22:33 common:826] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-11-13 14:22:35 modelPT:176] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: true\n",
            "    \n",
            "[NeMo W 2024-11-13 14:22:35 modelPT:183] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    \n",
            "[NeMo W 2024-11-13 14:22:35 modelPT:189] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    seq_eval_mode: false\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:22:35 features:305] PADDING: 16\n",
            "[NeMo I 2024-11-13 14:22:35 features:305] PADDING: 16\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-11-13 14:22:36 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/core/connectors/save_restore_connector.py:617: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "      return torch.load(model_weights, map_location='cpu')\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:22:36 save_restore_connector:272] Model EncDecDiarLabelModel was successfully restored from /root/.cache/torch/NeMo/NeMo_2.0.0rc1/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
            "[NeMo I 2024-11-13 14:22:36 features:305] PADDING: 16\n",
            "[NeMo I 2024-11-13 14:22:36 clustering_diarizer:127] Loading pretrained vad_multilingual_marblenet model from NGC\n",
            "[NeMo I 2024-11-13 14:22:36 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_2.0.0rc1/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
            "[NeMo I 2024-11-13 14:22:36 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_2.0.0rc1/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo\n",
            "[NeMo I 2024-11-13 14:22:36 common:826] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-11-13 14:22:36 modelPT:176] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: /manifests/ami_train_0.63.json,/manifests/freesound_background_train.json,/manifests/freesound_laughter_train.json,/manifests/fisher_2004_background.json,/manifests/fisher_2004_speech_sampled.json,/manifests/google_train_manifest.json,/manifests/icsi_all_0.63.json,/manifests/musan_freesound_train.json,/manifests/musan_music_train.json,/manifests/musan_soundbible_train.json,/manifests/mandarin_train_sample.json,/manifests/german_train_sample.json,/manifests/spanish_train_sample.json,/manifests/french_train_sample.json,/manifests/russian_train_sample.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: true\n",
            "    is_tarred: false\n",
            "    tarred_audio_filepaths: null\n",
            "    tarred_shard_strategy: scatter\n",
            "    augmentor:\n",
            "      shift:\n",
            "        prob: 0.5\n",
            "        min_shift_ms: -10.0\n",
            "        max_shift_ms: 10.0\n",
            "      white_noise:\n",
            "        prob: 0.5\n",
            "        min_level: -90\n",
            "        max_level: -46\n",
            "        norm: true\n",
            "      noise:\n",
            "        prob: 0.5\n",
            "        manifest_path: /manifests/noise_0_1_musan_fs.json\n",
            "        min_snr_db: 0\n",
            "        max_snr_db: 30\n",
            "        max_gain_db: 300.0\n",
            "        norm: true\n",
            "      gain:\n",
            "        prob: 0.5\n",
            "        min_gain_dbfs: -10.0\n",
            "        max_gain_dbfs: 10.0\n",
            "        norm: true\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2024-11-13 14:22:36 modelPT:183] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: /manifests/ami_dev_0.63.json,/manifests/freesound_background_dev.json,/manifests/freesound_laughter_dev.json,/manifests/ch120_moved_0.63.json,/manifests/fisher_2005_500_speech_sampled.json,/manifests/google_dev_manifest.json,/manifests/musan_music_dev.json,/manifests/mandarin_dev.json,/manifests/german_dev.json,/manifests/spanish_dev.json,/manifests/french_dev.json,/manifests/russian_dev.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: false\n",
            "    val_loss_idx: 0\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2024-11-13 14:22:36 modelPT:189] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 128\n",
            "    shuffle: false\n",
            "    test_loss_idx: 0\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:22:36 features:305] PADDING: 16\n",
            "[NeMo I 2024-11-13 14:22:36 save_restore_connector:272] Model EncDecClassificationModel was successfully restored from /root/.cache/torch/NeMo/NeMo_2.0.0rc1/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
            "[NeMo I 2024-11-13 14:22:36 msdd_models:870] Multiscale Weights: [1, 1, 1, 1, 1]\n",
            "[NeMo I 2024-11-13 14:22:36 msdd_models:871] Clustering Parameters: {\n",
            "        \"oracle_num_speakers\": false,\n",
            "        \"max_num_speakers\": 8,\n",
            "        \"enhanced_count_thres\": 80,\n",
            "        \"max_rp_threshold\": 0.25,\n",
            "        \"sparse_search_volume\": 30,\n",
            "        \"maj_vote_spk_count\": false,\n",
            "        \"chunk_cluster_count\": 50,\n",
            "        \"embeddings_per_chunk\": 10000\n",
            "    }\n",
            "[NeMo I 2024-11-13 14:22:36 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2024-11-13 14:22:36 clustering_diarizer:313] Split long audio file to avoid CUDA memory issue\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "splitting manifest: 100%|| 1/1 [00:00<00:00, 12.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:22:37 classification_models:293] Perform streaming frame-level VAD\n",
            "[NeMo I 2024-11-13 14:22:37 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-11-13 14:22:37 collections:741] Dataset successfully loaded with 13 items and total duration provided from manifest is  0.18 hours.\n",
            "[NeMo I 2024-11-13 14:22:37 collections:746] # 13 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "vad:   0%|          | 0/13 [00:00<?, ?it/s][NeMo W 2024-11-13 14:22:37 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/collections/asr/models/clustering_diarizer.py:226: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "      with autocast():\n",
            "    \n",
            "[NeMo W 2024-11-13 14:22:37 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/collections/asr/parts/preprocessing/features.py:436: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "      with torch.cuda.amp.autocast(enabled=False):\n",
            "    \n",
            "vad: 100%|| 13/13 [00:03<00:00,  4.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:22:40 clustering_diarizer:254] Generating predictions with overlapping input segments\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "                                                               "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:22:46 clustering_diarizer:266] Converting frame level prediction to speech/no-speech segment in start and end times format.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "creating speech segments: 100%|| 1/1 [00:00<00:00,  2.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:22:46 clustering_diarizer:291] Subsegmentation for embedding extraction: scale0, /content/temp_outputs/speaker_outputs/subsegments_scale0.json\n",
            "[NeMo I 2024-11-13 14:22:46 clustering_diarizer:347] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-11-13 14:22:46 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-11-13 14:22:46 collections:741] Dataset successfully loaded with 457 items and total duration provided from manifest is  0.06 hours.\n",
            "[NeMo I 2024-11-13 14:22:46 collections:746] # 457 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[1/5] extract embeddings:   0%|          | 0/8 [00:00<?, ?it/s][NeMo W 2024-11-13 14:22:46 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/collections/asr/models/clustering_diarizer.py:362: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "      with autocast():\n",
            "    \n",
            "[NeMo W 2024-11-13 14:22:46 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/collections/asr/parts/submodules/jasper.py:476: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "      with torch.cuda.amp.autocast(enabled=False):\n",
            "    \n",
            "[1/5] extract embeddings: 100%|| 8/8 [00:00<00:00,  9.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:22:47 clustering_diarizer:393] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-11-13 14:22:47 clustering_diarizer:291] Subsegmentation for embedding extraction: scale1, /content/temp_outputs/speaker_outputs/subsegments_scale1.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:22:47 clustering_diarizer:347] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-11-13 14:22:47 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-11-13 14:22:47 collections:741] Dataset successfully loaded with 470 items and total duration provided from manifest is  0.06 hours.\n",
            "[NeMo I 2024-11-13 14:22:47 collections:746] # 470 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[2/5] extract embeddings: 100%|| 8/8 [00:00<00:00, 12.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:22:48 clustering_diarizer:393] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-11-13 14:22:48 clustering_diarizer:291] Subsegmentation for embedding extraction: scale2, /content/temp_outputs/speaker_outputs/subsegments_scale2.json\n",
            "[NeMo I 2024-11-13 14:22:48 clustering_diarizer:347] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-11-13 14:22:48 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-11-13 14:22:48 collections:741] Dataset successfully loaded with 500 items and total duration provided from manifest is  0.06 hours.\n",
            "[NeMo I 2024-11-13 14:22:48 collections:746] # 500 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[3/5] extract embeddings: 100%|| 8/8 [00:00<00:00, 13.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:22:49 clustering_diarizer:393] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-11-13 14:22:49 clustering_diarizer:291] Subsegmentation for embedding extraction: scale3, /content/temp_outputs/speaker_outputs/subsegments_scale3.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:22:49 clustering_diarizer:347] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-11-13 14:22:49 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-11-13 14:22:49 collections:741] Dataset successfully loaded with 577 items and total duration provided from manifest is  0.07 hours.\n",
            "[NeMo I 2024-11-13 14:22:49 collections:746] # 577 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[4/5] extract embeddings: 100%|| 10/10 [00:00<00:00, 16.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:22:49 clustering_diarizer:393] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-11-13 14:22:49 clustering_diarizer:291] Subsegmentation for embedding extraction: scale4, /content/temp_outputs/speaker_outputs/subsegments_scale4.json\n",
            "[NeMo I 2024-11-13 14:22:49 clustering_diarizer:347] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-11-13 14:22:49 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-11-13 14:22:49 collections:741] Dataset successfully loaded with 751 items and total duration provided from manifest is  0.08 hours.\n",
            "[NeMo I 2024-11-13 14:22:49 collections:746] # 751 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[5/5] extract embeddings: 100%|| 12/12 [00:00<00:00, 16.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:22:50 clustering_diarizer:393] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "clustering: 100%|| 1/1 [00:00<00:00,  1.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:22:51 clustering_diarizer:461] Outputs are saved in /content/temp_outputs directory\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[NeMo W 2024-11-13 14:22:51 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:22:51 msdd_models:966] Loading embedding pickle file of scale:0 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale0_embeddings.pkl\n",
            "[NeMo I 2024-11-13 14:22:51 msdd_models:966] Loading embedding pickle file of scale:1 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale1_embeddings.pkl\n",
            "[NeMo I 2024-11-13 14:22:51 msdd_models:966] Loading embedding pickle file of scale:2 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale2_embeddings.pkl\n",
            "[NeMo I 2024-11-13 14:22:51 msdd_models:966] Loading embedding pickle file of scale:3 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale3_embeddings.pkl\n",
            "[NeMo I 2024-11-13 14:22:51 msdd_models:966] Loading embedding pickle file of scale:4 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale4_embeddings.pkl\n",
            "[NeMo I 2024-11-13 14:22:51 msdd_models:944] Loading cluster label file from /content/temp_outputs/speaker_outputs/subsegments_scale4_cluster.label\n",
            "[NeMo I 2024-11-13 14:22:51 collections:1067] Filtered duration for loading collection is 0.000000.\n",
            "[NeMo I 2024-11-13 14:22:51 collections:1071] Total 1 session files loaded accounting to # 1 audio clips\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/1 [00:00<?, ?it/s][NeMo W 2024-11-13 14:22:51 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/collections/asr/models/msdd_models.py:1333: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "      with autocast():\n",
            "    \n",
            "100%|| 1/1 [00:00<00:00, 19.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:22:51 msdd_models:1407]      [Threshold: 0.7000] [use_clus_as_main=False] [diar_window=50]\n",
            "[NeMo I 2024-11-13 14:22:51 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2024-11-13 14:22:51 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[NeMo W 2024-11-13 14:22:51 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:22:51 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-11-13 14:22:51 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:22:51 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-11-13 14:22:51 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:22:51 msdd_models:1435]   \n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Punctuation restoration is not available for ru language. Using the original punctuation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:26:05 msdd_models:1097] Loading pretrained diar_msdd_telephonic model from NGC\n",
            "[NeMo I 2024-11-13 14:26:05 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_2.0.0rc1/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
            "[NeMo I 2024-11-13 14:26:05 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_2.0.0rc1/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo\n",
            "[NeMo I 2024-11-13 14:26:05 common:826] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-11-13 14:26:07 modelPT:176] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: true\n",
            "    \n",
            "[NeMo W 2024-11-13 14:26:07 modelPT:183] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    \n",
            "[NeMo W 2024-11-13 14:26:07 modelPT:189] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    seq_eval_mode: false\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:26:07 features:305] PADDING: 16\n",
            "[NeMo I 2024-11-13 14:26:07 features:305] PADDING: 16\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-11-13 14:26:07 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/core/connectors/save_restore_connector.py:617: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "      return torch.load(model_weights, map_location='cpu')\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:26:07 save_restore_connector:272] Model EncDecDiarLabelModel was successfully restored from /root/.cache/torch/NeMo/NeMo_2.0.0rc1/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
            "[NeMo I 2024-11-13 14:26:08 features:305] PADDING: 16\n",
            "[NeMo I 2024-11-13 14:26:08 clustering_diarizer:127] Loading pretrained vad_multilingual_marblenet model from NGC\n",
            "[NeMo I 2024-11-13 14:26:08 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_2.0.0rc1/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
            "[NeMo I 2024-11-13 14:26:08 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_2.0.0rc1/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo\n",
            "[NeMo I 2024-11-13 14:26:08 common:826] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-11-13 14:26:08 modelPT:176] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: /manifests/ami_train_0.63.json,/manifests/freesound_background_train.json,/manifests/freesound_laughter_train.json,/manifests/fisher_2004_background.json,/manifests/fisher_2004_speech_sampled.json,/manifests/google_train_manifest.json,/manifests/icsi_all_0.63.json,/manifests/musan_freesound_train.json,/manifests/musan_music_train.json,/manifests/musan_soundbible_train.json,/manifests/mandarin_train_sample.json,/manifests/german_train_sample.json,/manifests/spanish_train_sample.json,/manifests/french_train_sample.json,/manifests/russian_train_sample.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: true\n",
            "    is_tarred: false\n",
            "    tarred_audio_filepaths: null\n",
            "    tarred_shard_strategy: scatter\n",
            "    augmentor:\n",
            "      shift:\n",
            "        prob: 0.5\n",
            "        min_shift_ms: -10.0\n",
            "        max_shift_ms: 10.0\n",
            "      white_noise:\n",
            "        prob: 0.5\n",
            "        min_level: -90\n",
            "        max_level: -46\n",
            "        norm: true\n",
            "      noise:\n",
            "        prob: 0.5\n",
            "        manifest_path: /manifests/noise_0_1_musan_fs.json\n",
            "        min_snr_db: 0\n",
            "        max_snr_db: 30\n",
            "        max_gain_db: 300.0\n",
            "        norm: true\n",
            "      gain:\n",
            "        prob: 0.5\n",
            "        min_gain_dbfs: -10.0\n",
            "        max_gain_dbfs: 10.0\n",
            "        norm: true\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2024-11-13 14:26:08 modelPT:183] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: /manifests/ami_dev_0.63.json,/manifests/freesound_background_dev.json,/manifests/freesound_laughter_dev.json,/manifests/ch120_moved_0.63.json,/manifests/fisher_2005_500_speech_sampled.json,/manifests/google_dev_manifest.json,/manifests/musan_music_dev.json,/manifests/mandarin_dev.json,/manifests/german_dev.json,/manifests/spanish_dev.json,/manifests/french_dev.json,/manifests/russian_dev.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: false\n",
            "    val_loss_idx: 0\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2024-11-13 14:26:08 modelPT:189] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 128\n",
            "    shuffle: false\n",
            "    test_loss_idx: 0\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:26:08 features:305] PADDING: 16\n",
            "[NeMo I 2024-11-13 14:26:08 save_restore_connector:272] Model EncDecClassificationModel was successfully restored from /root/.cache/torch/NeMo/NeMo_2.0.0rc1/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
            "[NeMo I 2024-11-13 14:26:08 msdd_models:870] Multiscale Weights: [1, 1, 1, 1, 1]\n",
            "[NeMo I 2024-11-13 14:26:08 msdd_models:871] Clustering Parameters: {\n",
            "        \"oracle_num_speakers\": false,\n",
            "        \"max_num_speakers\": 8,\n",
            "        \"enhanced_count_thres\": 80,\n",
            "        \"max_rp_threshold\": 0.25,\n",
            "        \"sparse_search_volume\": 30,\n",
            "        \"maj_vote_spk_count\": false,\n",
            "        \"chunk_cluster_count\": 50,\n",
            "        \"embeddings_per_chunk\": 10000\n",
            "    }\n",
            "[NeMo I 2024-11-13 14:26:08 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2024-11-13 14:26:08 clustering_diarizer:313] Split long audio file to avoid CUDA memory issue\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "splitting manifest: 100%|| 1/1 [00:00<00:00,  8.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:26:08 classification_models:293] Perform streaming frame-level VAD\n",
            "[NeMo I 2024-11-13 14:26:08 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-11-13 14:26:08 collections:741] Dataset successfully loaded with 19 items and total duration provided from manifest is  0.26 hours.\n",
            "[NeMo I 2024-11-13 14:26:08 collections:746] # 19 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "vad:   0%|          | 0/19 [00:00<?, ?it/s][NeMo W 2024-11-13 14:26:09 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/collections/asr/models/clustering_diarizer.py:226: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "      with autocast():\n",
            "    \n",
            "[NeMo W 2024-11-13 14:26:09 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/collections/asr/parts/preprocessing/features.py:436: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "      with torch.cuda.amp.autocast(enabled=False):\n",
            "    \n",
            "vad: 100%|| 19/19 [00:05<00:00,  3.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:26:14 clustering_diarizer:254] Generating predictions with overlapping input segments\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                               "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:26:21 clustering_diarizer:266] Converting frame level prediction to speech/no-speech segment in start and end times format.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "creating speech segments: 100%|| 1/1 [00:00<00:00,  1.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:26:22 clustering_diarizer:291] Subsegmentation for embedding extraction: scale0, /content/temp_outputs/speaker_outputs/subsegments_scale0.json\n",
            "[NeMo I 2024-11-13 14:26:22 clustering_diarizer:347] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-11-13 14:26:22 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-11-13 14:26:22 collections:741] Dataset successfully loaded with 700 items and total duration provided from manifest is  0.11 hours.\n",
            "[NeMo I 2024-11-13 14:26:22 collections:746] # 700 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[1/5] extract embeddings:   0%|          | 0/11 [00:00<?, ?it/s][NeMo W 2024-11-13 14:26:22 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/collections/asr/models/clustering_diarizer.py:362: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "      with autocast():\n",
            "    \n",
            "[NeMo W 2024-11-13 14:26:22 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/collections/asr/parts/submodules/jasper.py:476: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "      with torch.cuda.amp.autocast(enabled=False):\n",
            "    \n",
            "[1/5] extract embeddings: 100%|| 11/11 [00:01<00:00,  8.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:26:24 clustering_diarizer:393] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-11-13 14:26:24 clustering_diarizer:291] Subsegmentation for embedding extraction: scale1, /content/temp_outputs/speaker_outputs/subsegments_scale1.json\n",
            "[NeMo I 2024-11-13 14:26:24 clustering_diarizer:347] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-11-13 14:26:24 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-11-13 14:26:24 collections:741] Dataset successfully loaded with 738 items and total duration provided from manifest is  0.12 hours.\n",
            "[NeMo I 2024-11-13 14:26:24 collections:746] # 738 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[2/5] extract embeddings: 100%|| 12/12 [00:01<00:00,  9.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:26:26 clustering_diarizer:393] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-11-13 14:26:26 clustering_diarizer:291] Subsegmentation for embedding extraction: scale2, /content/temp_outputs/speaker_outputs/subsegments_scale2.json\n",
            "[NeMo I 2024-11-13 14:26:26 clustering_diarizer:347] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-11-13 14:26:26 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-11-13 14:26:26 collections:741] Dataset successfully loaded with 812 items and total duration provided from manifest is  0.12 hours.\n",
            "[NeMo I 2024-11-13 14:26:26 collections:746] # 812 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[3/5] extract embeddings: 100%|| 13/13 [00:01<00:00, 12.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:26:27 clustering_diarizer:393] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-11-13 14:26:27 clustering_diarizer:291] Subsegmentation for embedding extraction: scale3, /content/temp_outputs/speaker_outputs/subsegments_scale3.json\n",
            "[NeMo I 2024-11-13 14:26:27 clustering_diarizer:347] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-11-13 14:26:27 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-11-13 14:26:27 collections:741] Dataset successfully loaded with 968 items and total duration provided from manifest is  0.13 hours.\n",
            "[NeMo I 2024-11-13 14:26:27 collections:746] # 968 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[4/5] extract embeddings: 100%|| 16/16 [00:00<00:00, 16.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:26:28 clustering_diarizer:393] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-11-13 14:26:28 clustering_diarizer:291] Subsegmentation for embedding extraction: scale4, /content/temp_outputs/speaker_outputs/subsegments_scale4.json\n",
            "[NeMo I 2024-11-13 14:26:28 clustering_diarizer:347] Extracting embeddings for Diarization\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:26:28 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-11-13 14:26:28 collections:741] Dataset successfully loaded with 1346 items and total duration provided from manifest is  0.15 hours.\n",
            "[NeMo I 2024-11-13 14:26:28 collections:746] # 1346 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[5/5] extract embeddings: 100%|| 22/22 [00:01<00:00, 17.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:26:30 clustering_diarizer:393] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "clustering: 100%|| 1/1 [00:00<00:00,  1.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:26:30 clustering_diarizer:461] Outputs are saved in /content/temp_outputs directory\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[NeMo W 2024-11-13 14:26:30 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:26:30 msdd_models:966] Loading embedding pickle file of scale:0 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale0_embeddings.pkl\n",
            "[NeMo I 2024-11-13 14:26:30 msdd_models:966] Loading embedding pickle file of scale:1 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale1_embeddings.pkl\n",
            "[NeMo I 2024-11-13 14:26:30 msdd_models:966] Loading embedding pickle file of scale:2 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale2_embeddings.pkl\n",
            "[NeMo I 2024-11-13 14:26:30 msdd_models:966] Loading embedding pickle file of scale:3 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale3_embeddings.pkl\n",
            "[NeMo I 2024-11-13 14:26:30 msdd_models:966] Loading embedding pickle file of scale:4 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale4_embeddings.pkl\n",
            "[NeMo I 2024-11-13 14:26:30 msdd_models:944] Loading cluster label file from /content/temp_outputs/speaker_outputs/subsegments_scale4_cluster.label\n",
            "[NeMo I 2024-11-13 14:26:31 collections:1067] Filtered duration for loading collection is 0.000000.\n",
            "[NeMo I 2024-11-13 14:26:31 collections:1071] Total 1 session files loaded accounting to # 1 audio clips\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/1 [00:00<?, ?it/s][NeMo W 2024-11-13 14:26:31 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/collections/asr/models/msdd_models.py:1333: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "      with autocast():\n",
            "    \n",
            "100%|| 1/1 [00:00<00:00, 18.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:26:31 msdd_models:1407]      [Threshold: 0.7000] [use_clus_as_main=False] [diar_window=50]\n",
            "[NeMo I 2024-11-13 14:26:31 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2024-11-13 14:26:31 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[NeMo W 2024-11-13 14:26:31 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:26:31 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-11-13 14:26:31 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:26:31 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-11-13 14:26:31 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:26:31 msdd_models:1435]   \n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Punctuation restoration is not available for ru language. Using the original punctuation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:29:04 msdd_models:1097] Loading pretrained diar_msdd_telephonic model from NGC\n",
            "[NeMo I 2024-11-13 14:29:04 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_2.0.0rc1/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
            "[NeMo I 2024-11-13 14:29:04 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_2.0.0rc1/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo\n",
            "[NeMo I 2024-11-13 14:29:04 common:826] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-11-13 14:29:05 modelPT:176] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: true\n",
            "    \n",
            "[NeMo W 2024-11-13 14:29:05 modelPT:183] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    \n",
            "[NeMo W 2024-11-13 14:29:05 modelPT:189] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    seq_eval_mode: false\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:29:05 features:305] PADDING: 16\n",
            "[NeMo I 2024-11-13 14:29:06 features:305] PADDING: 16\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-11-13 14:29:06 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/core/connectors/save_restore_connector.py:617: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "      return torch.load(model_weights, map_location='cpu')\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:29:06 save_restore_connector:272] Model EncDecDiarLabelModel was successfully restored from /root/.cache/torch/NeMo/NeMo_2.0.0rc1/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
            "[NeMo I 2024-11-13 14:29:06 features:305] PADDING: 16\n",
            "[NeMo I 2024-11-13 14:29:07 clustering_diarizer:127] Loading pretrained vad_multilingual_marblenet model from NGC\n",
            "[NeMo I 2024-11-13 14:29:07 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_2.0.0rc1/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
            "[NeMo I 2024-11-13 14:29:07 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_2.0.0rc1/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo\n",
            "[NeMo I 2024-11-13 14:29:07 common:826] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-11-13 14:29:07 modelPT:176] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: /manifests/ami_train_0.63.json,/manifests/freesound_background_train.json,/manifests/freesound_laughter_train.json,/manifests/fisher_2004_background.json,/manifests/fisher_2004_speech_sampled.json,/manifests/google_train_manifest.json,/manifests/icsi_all_0.63.json,/manifests/musan_freesound_train.json,/manifests/musan_music_train.json,/manifests/musan_soundbible_train.json,/manifests/mandarin_train_sample.json,/manifests/german_train_sample.json,/manifests/spanish_train_sample.json,/manifests/french_train_sample.json,/manifests/russian_train_sample.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: true\n",
            "    is_tarred: false\n",
            "    tarred_audio_filepaths: null\n",
            "    tarred_shard_strategy: scatter\n",
            "    augmentor:\n",
            "      shift:\n",
            "        prob: 0.5\n",
            "        min_shift_ms: -10.0\n",
            "        max_shift_ms: 10.0\n",
            "      white_noise:\n",
            "        prob: 0.5\n",
            "        min_level: -90\n",
            "        max_level: -46\n",
            "        norm: true\n",
            "      noise:\n",
            "        prob: 0.5\n",
            "        manifest_path: /manifests/noise_0_1_musan_fs.json\n",
            "        min_snr_db: 0\n",
            "        max_snr_db: 30\n",
            "        max_gain_db: 300.0\n",
            "        norm: true\n",
            "      gain:\n",
            "        prob: 0.5\n",
            "        min_gain_dbfs: -10.0\n",
            "        max_gain_dbfs: 10.0\n",
            "        norm: true\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2024-11-13 14:29:07 modelPT:183] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: /manifests/ami_dev_0.63.json,/manifests/freesound_background_dev.json,/manifests/freesound_laughter_dev.json,/manifests/ch120_moved_0.63.json,/manifests/fisher_2005_500_speech_sampled.json,/manifests/google_dev_manifest.json,/manifests/musan_music_dev.json,/manifests/mandarin_dev.json,/manifests/german_dev.json,/manifests/spanish_dev.json,/manifests/french_dev.json,/manifests/russian_dev.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: false\n",
            "    val_loss_idx: 0\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2024-11-13 14:29:07 modelPT:189] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 128\n",
            "    shuffle: false\n",
            "    test_loss_idx: 0\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:29:07 features:305] PADDING: 16\n",
            "[NeMo I 2024-11-13 14:29:07 save_restore_connector:272] Model EncDecClassificationModel was successfully restored from /root/.cache/torch/NeMo/NeMo_2.0.0rc1/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
            "[NeMo I 2024-11-13 14:29:07 msdd_models:870] Multiscale Weights: [1, 1, 1, 1, 1]\n",
            "[NeMo I 2024-11-13 14:29:07 msdd_models:871] Clustering Parameters: {\n",
            "        \"oracle_num_speakers\": false,\n",
            "        \"max_num_speakers\": 8,\n",
            "        \"enhanced_count_thres\": 80,\n",
            "        \"max_rp_threshold\": 0.25,\n",
            "        \"sparse_search_volume\": 30,\n",
            "        \"maj_vote_spk_count\": false,\n",
            "        \"chunk_cluster_count\": 50,\n",
            "        \"embeddings_per_chunk\": 10000\n",
            "    }\n",
            "[NeMo I 2024-11-13 14:29:07 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2024-11-13 14:29:07 clustering_diarizer:313] Split long audio file to avoid CUDA memory issue\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "splitting manifest: 100%|| 1/1 [00:00<00:00,  9.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:29:07 classification_models:293] Perform streaming frame-level VAD\n",
            "[NeMo I 2024-11-13 14:29:07 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-11-13 14:29:07 collections:741] Dataset successfully loaded with 18 items and total duration provided from manifest is  0.24 hours.\n",
            "[NeMo I 2024-11-13 14:29:07 collections:746] # 18 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "vad:   0%|          | 0/18 [00:00<?, ?it/s][NeMo W 2024-11-13 14:29:07 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/collections/asr/models/clustering_diarizer.py:226: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "      with autocast():\n",
            "    \n",
            "[NeMo W 2024-11-13 14:29:07 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/collections/asr/parts/preprocessing/features.py:436: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "      with torch.cuda.amp.autocast(enabled=False):\n",
            "    \n",
            "vad: 100%|| 18/18 [00:04<00:00,  3.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:29:12 clustering_diarizer:254] Generating predictions with overlapping input segments\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "                                                               "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:29:19 clustering_diarizer:266] Converting frame level prediction to speech/no-speech segment in start and end times format.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "creating speech segments: 100%|| 1/1 [00:00<00:00,  1.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:29:20 clustering_diarizer:291] Subsegmentation for embedding extraction: scale0, /content/temp_outputs/speaker_outputs/subsegments_scale0.json\n",
            "[NeMo I 2024-11-13 14:29:20 clustering_diarizer:347] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-11-13 14:29:20 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-11-13 14:29:20 collections:741] Dataset successfully loaded with 531 items and total duration provided from manifest is  0.05 hours.\n",
            "[NeMo I 2024-11-13 14:29:20 collections:746] # 531 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[1/5] extract embeddings:   0%|          | 0/9 [00:00<?, ?it/s][NeMo W 2024-11-13 14:29:20 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/collections/asr/models/clustering_diarizer.py:362: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "      with autocast():\n",
            "    \n",
            "[NeMo W 2024-11-13 14:29:20 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/collections/asr/parts/submodules/jasper.py:476: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "      with torch.cuda.amp.autocast(enabled=False):\n",
            "    \n",
            "[1/5] extract embeddings: 100%|| 9/9 [00:00<00:00, 11.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:29:21 clustering_diarizer:393] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-11-13 14:29:21 clustering_diarizer:291] Subsegmentation for embedding extraction: scale1, /content/temp_outputs/speaker_outputs/subsegments_scale1.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:29:21 clustering_diarizer:347] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-11-13 14:29:21 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-11-13 14:29:21 collections:741] Dataset successfully loaded with 538 items and total duration provided from manifest is  0.05 hours.\n",
            "[NeMo I 2024-11-13 14:29:21 collections:746] # 538 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[2/5] extract embeddings: 100%|| 9/9 [00:00<00:00, 12.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:29:22 clustering_diarizer:393] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-11-13 14:29:22 clustering_diarizer:291] Subsegmentation for embedding extraction: scale2, /content/temp_outputs/speaker_outputs/subsegments_scale2.json\n",
            "[NeMo I 2024-11-13 14:29:22 clustering_diarizer:347] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-11-13 14:29:22 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-11-13 14:29:22 collections:741] Dataset successfully loaded with 548 items and total duration provided from manifest is  0.05 hours.\n",
            "[NeMo I 2024-11-13 14:29:22 collections:746] # 548 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[3/5] extract embeddings: 100%|| 9/9 [00:00<00:00, 11.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:29:23 clustering_diarizer:393] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-11-13 14:29:23 clustering_diarizer:291] Subsegmentation for embedding extraction: scale3, /content/temp_outputs/speaker_outputs/subsegments_scale3.json\n",
            "[NeMo I 2024-11-13 14:29:23 clustering_diarizer:347] Extracting embeddings for Diarization\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:29:23 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-11-13 14:29:23 collections:741] Dataset successfully loaded with 581 items and total duration provided from manifest is  0.05 hours.\n",
            "[NeMo I 2024-11-13 14:29:23 collections:746] # 581 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[4/5] extract embeddings: 100%|| 10/10 [00:00<00:00, 13.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:29:25 clustering_diarizer:393] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-11-13 14:29:25 clustering_diarizer:291] Subsegmentation for embedding extraction: scale4, /content/temp_outputs/speaker_outputs/subsegments_scale4.json\n",
            "[NeMo I 2024-11-13 14:29:25 clustering_diarizer:347] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-11-13 14:29:25 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-11-13 14:29:25 collections:741] Dataset successfully loaded with 687 items and total duration provided from manifest is  0.06 hours.\n",
            "[NeMo I 2024-11-13 14:29:25 collections:746] # 687 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[5/5] extract embeddings: 100%|| 11/11 [00:00<00:00, 16.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:29:26 clustering_diarizer:393] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "clustering: 100%|| 1/1 [00:00<00:00,  2.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:29:26 clustering_diarizer:461] Outputs are saved in /content/temp_outputs directory\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[NeMo W 2024-11-13 14:29:26 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:29:26 msdd_models:966] Loading embedding pickle file of scale:0 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale0_embeddings.pkl\n",
            "[NeMo I 2024-11-13 14:29:26 msdd_models:966] Loading embedding pickle file of scale:1 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale1_embeddings.pkl\n",
            "[NeMo I 2024-11-13 14:29:26 msdd_models:966] Loading embedding pickle file of scale:2 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale2_embeddings.pkl\n",
            "[NeMo I 2024-11-13 14:29:26 msdd_models:966] Loading embedding pickle file of scale:3 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale3_embeddings.pkl\n",
            "[NeMo I 2024-11-13 14:29:26 msdd_models:966] Loading embedding pickle file of scale:4 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale4_embeddings.pkl\n",
            "[NeMo I 2024-11-13 14:29:26 msdd_models:944] Loading cluster label file from /content/temp_outputs/speaker_outputs/subsegments_scale4_cluster.label\n",
            "[NeMo I 2024-11-13 14:29:26 collections:1067] Filtered duration for loading collection is 0.000000.\n",
            "[NeMo I 2024-11-13 14:29:26 collections:1071] Total 1 session files loaded accounting to # 1 audio clips\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/1 [00:00<?, ?it/s][NeMo W 2024-11-13 14:29:26 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/collections/asr/models/msdd_models.py:1333: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "      with autocast():\n",
            "    \n",
            "100%|| 1/1 [00:00<00:00, 25.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:29:26 msdd_models:1407]      [Threshold: 0.7000] [use_clus_as_main=False] [diar_window=50]\n",
            "[NeMo I 2024-11-13 14:29:26 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2024-11-13 14:29:26 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[NeMo W 2024-11-13 14:29:26 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:29:26 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-11-13 14:29:26 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:29:26 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-11-13 14:29:26 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:29:26 msdd_models:1435]   \n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Punctuation restoration is not available for ru language. Using the original punctuation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:31:28 msdd_models:1097] Loading pretrained diar_msdd_telephonic model from NGC\n",
            "[NeMo I 2024-11-13 14:31:28 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_2.0.0rc1/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
            "[NeMo I 2024-11-13 14:31:28 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_2.0.0rc1/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo\n",
            "[NeMo I 2024-11-13 14:31:28 common:826] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-11-13 14:31:29 modelPT:176] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: true\n",
            "    \n",
            "[NeMo W 2024-11-13 14:31:29 modelPT:183] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    \n",
            "[NeMo W 2024-11-13 14:31:29 modelPT:189] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    seq_eval_mode: false\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:31:32 features:305] PADDING: 16\n",
            "[NeMo I 2024-11-13 14:31:33 features:305] PADDING: 16\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-11-13 14:31:33 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/core/connectors/save_restore_connector.py:617: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "      return torch.load(model_weights, map_location='cpu')\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:31:33 save_restore_connector:272] Model EncDecDiarLabelModel was successfully restored from /root/.cache/torch/NeMo/NeMo_2.0.0rc1/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
            "[NeMo I 2024-11-13 14:31:33 features:305] PADDING: 16\n",
            "[NeMo I 2024-11-13 14:31:34 clustering_diarizer:127] Loading pretrained vad_multilingual_marblenet model from NGC\n",
            "[NeMo I 2024-11-13 14:31:34 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_2.0.0rc1/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
            "[NeMo I 2024-11-13 14:31:34 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_2.0.0rc1/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo\n",
            "[NeMo I 2024-11-13 14:31:34 common:826] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-11-13 14:31:34 modelPT:176] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: /manifests/ami_train_0.63.json,/manifests/freesound_background_train.json,/manifests/freesound_laughter_train.json,/manifests/fisher_2004_background.json,/manifests/fisher_2004_speech_sampled.json,/manifests/google_train_manifest.json,/manifests/icsi_all_0.63.json,/manifests/musan_freesound_train.json,/manifests/musan_music_train.json,/manifests/musan_soundbible_train.json,/manifests/mandarin_train_sample.json,/manifests/german_train_sample.json,/manifests/spanish_train_sample.json,/manifests/french_train_sample.json,/manifests/russian_train_sample.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: true\n",
            "    is_tarred: false\n",
            "    tarred_audio_filepaths: null\n",
            "    tarred_shard_strategy: scatter\n",
            "    augmentor:\n",
            "      shift:\n",
            "        prob: 0.5\n",
            "        min_shift_ms: -10.0\n",
            "        max_shift_ms: 10.0\n",
            "      white_noise:\n",
            "        prob: 0.5\n",
            "        min_level: -90\n",
            "        max_level: -46\n",
            "        norm: true\n",
            "      noise:\n",
            "        prob: 0.5\n",
            "        manifest_path: /manifests/noise_0_1_musan_fs.json\n",
            "        min_snr_db: 0\n",
            "        max_snr_db: 30\n",
            "        max_gain_db: 300.0\n",
            "        norm: true\n",
            "      gain:\n",
            "        prob: 0.5\n",
            "        min_gain_dbfs: -10.0\n",
            "        max_gain_dbfs: 10.0\n",
            "        norm: true\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2024-11-13 14:31:34 modelPT:183] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: /manifests/ami_dev_0.63.json,/manifests/freesound_background_dev.json,/manifests/freesound_laughter_dev.json,/manifests/ch120_moved_0.63.json,/manifests/fisher_2005_500_speech_sampled.json,/manifests/google_dev_manifest.json,/manifests/musan_music_dev.json,/manifests/mandarin_dev.json,/manifests/german_dev.json,/manifests/spanish_dev.json,/manifests/french_dev.json,/manifests/russian_dev.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: false\n",
            "    val_loss_idx: 0\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2024-11-13 14:31:34 modelPT:189] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 128\n",
            "    shuffle: false\n",
            "    test_loss_idx: 0\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:31:34 features:305] PADDING: 16\n",
            "[NeMo I 2024-11-13 14:31:34 save_restore_connector:272] Model EncDecClassificationModel was successfully restored from /root/.cache/torch/NeMo/NeMo_2.0.0rc1/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
            "[NeMo I 2024-11-13 14:31:34 msdd_models:870] Multiscale Weights: [1, 1, 1, 1, 1]\n",
            "[NeMo I 2024-11-13 14:31:34 msdd_models:871] Clustering Parameters: {\n",
            "        \"oracle_num_speakers\": false,\n",
            "        \"max_num_speakers\": 8,\n",
            "        \"enhanced_count_thres\": 80,\n",
            "        \"max_rp_threshold\": 0.25,\n",
            "        \"sparse_search_volume\": 30,\n",
            "        \"maj_vote_spk_count\": false,\n",
            "        \"chunk_cluster_count\": 50,\n",
            "        \"embeddings_per_chunk\": 10000\n",
            "    }\n",
            "[NeMo I 2024-11-13 14:31:34 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2024-11-13 14:31:34 clustering_diarizer:313] Split long audio file to avoid CUDA memory issue\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "splitting manifest: 100%|| 1/1 [00:00<00:00, 13.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:31:34 classification_models:293] Perform streaming frame-level VAD\n",
            "[NeMo I 2024-11-13 14:31:34 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-11-13 14:31:34 collections:741] Dataset successfully loaded with 13 items and total duration provided from manifest is  0.17 hours.\n",
            "[NeMo I 2024-11-13 14:31:34 collections:746] # 13 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "vad:   0%|          | 0/13 [00:00<?, ?it/s][NeMo W 2024-11-13 14:31:34 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/collections/asr/models/clustering_diarizer.py:226: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "      with autocast():\n",
            "    \n",
            "[NeMo W 2024-11-13 14:31:34 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/collections/asr/parts/preprocessing/features.py:436: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "      with torch.cuda.amp.autocast(enabled=False):\n",
            "    \n",
            "vad: 100%|| 13/13 [00:03<00:00,  4.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:31:37 clustering_diarizer:254] Generating predictions with overlapping input segments\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "                                                               "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:31:43 clustering_diarizer:266] Converting frame level prediction to speech/no-speech segment in start and end times format.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "creating speech segments: 100%|| 1/1 [00:00<00:00,  2.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:31:44 clustering_diarizer:291] Subsegmentation for embedding extraction: scale0, /content/temp_outputs/speaker_outputs/subsegments_scale0.json\n",
            "[NeMo I 2024-11-13 14:31:44 clustering_diarizer:347] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-11-13 14:31:44 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-11-13 14:31:44 collections:741] Dataset successfully loaded with 481 items and total duration provided from manifest is  0.08 hours.\n",
            "[NeMo I 2024-11-13 14:31:44 collections:746] # 481 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[1/5] extract embeddings:   0%|          | 0/8 [00:00<?, ?it/s][NeMo W 2024-11-13 14:31:44 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/collections/asr/models/clustering_diarizer.py:362: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "      with autocast():\n",
            "    \n",
            "[NeMo W 2024-11-13 14:31:44 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/collections/asr/parts/submodules/jasper.py:476: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "      with torch.cuda.amp.autocast(enabled=False):\n",
            "    \n",
            "[1/5] extract embeddings: 100%|| 8/8 [00:00<00:00,  9.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:31:45 clustering_diarizer:393] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-11-13 14:31:45 clustering_diarizer:291] Subsegmentation for embedding extraction: scale1, /content/temp_outputs/speaker_outputs/subsegments_scale1.json\n",
            "[NeMo I 2024-11-13 14:31:45 clustering_diarizer:347] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-11-13 14:31:45 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-11-13 14:31:45 collections:741] Dataset successfully loaded with 510 items and total duration provided from manifest is  0.08 hours.\n",
            "[NeMo I 2024-11-13 14:31:45 collections:746] # 510 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[2/5] extract embeddings: 100%|| 8/8 [00:00<00:00, 11.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:31:45 clustering_diarizer:393] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-11-13 14:31:45 clustering_diarizer:291] Subsegmentation for embedding extraction: scale2, /content/temp_outputs/speaker_outputs/subsegments_scale2.json\n",
            "[NeMo I 2024-11-13 14:31:45 clustering_diarizer:347] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-11-13 14:31:45 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-11-13 14:31:45 collections:741] Dataset successfully loaded with 554 items and total duration provided from manifest is  0.08 hours.\n",
            "[NeMo I 2024-11-13 14:31:45 collections:746] # 554 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[3/5] extract embeddings: 100%|| 9/9 [00:00<00:00, 12.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:31:46 clustering_diarizer:393] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-11-13 14:31:46 clustering_diarizer:291] Subsegmentation for embedding extraction: scale3, /content/temp_outputs/speaker_outputs/subsegments_scale3.json\n",
            "[NeMo I 2024-11-13 14:31:46 clustering_diarizer:347] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-11-13 14:31:46 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-11-13 14:31:46 collections:741] Dataset successfully loaded with 656 items and total duration provided from manifest is  0.09 hours.\n",
            "[NeMo I 2024-11-13 14:31:46 collections:746] # 656 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[4/5] extract embeddings: 100%|| 11/11 [00:00<00:00, 16.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:31:47 clustering_diarizer:393] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-11-13 14:31:47 clustering_diarizer:291] Subsegmentation for embedding extraction: scale4, /content/temp_outputs/speaker_outputs/subsegments_scale4.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:31:47 clustering_diarizer:347] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-11-13 14:31:47 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-11-13 14:31:47 collections:741] Dataset successfully loaded with 920 items and total duration provided from manifest is  0.10 hours.\n",
            "[NeMo I 2024-11-13 14:31:47 collections:746] # 920 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[5/5] extract embeddings: 100%|| 15/15 [00:00<00:00, 17.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:31:48 clustering_diarizer:393] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "clustering: 100%|| 1/1 [00:00<00:00,  1.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:31:48 clustering_diarizer:461] Outputs are saved in /content/temp_outputs directory\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[NeMo W 2024-11-13 14:31:48 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:31:48 msdd_models:966] Loading embedding pickle file of scale:0 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale0_embeddings.pkl\n",
            "[NeMo I 2024-11-13 14:31:49 msdd_models:966] Loading embedding pickle file of scale:1 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale1_embeddings.pkl\n",
            "[NeMo I 2024-11-13 14:31:49 msdd_models:966] Loading embedding pickle file of scale:2 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale2_embeddings.pkl\n",
            "[NeMo I 2024-11-13 14:31:49 msdd_models:966] Loading embedding pickle file of scale:3 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale3_embeddings.pkl\n",
            "[NeMo I 2024-11-13 14:31:49 msdd_models:966] Loading embedding pickle file of scale:4 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale4_embeddings.pkl\n",
            "[NeMo I 2024-11-13 14:31:49 msdd_models:944] Loading cluster label file from /content/temp_outputs/speaker_outputs/subsegments_scale4_cluster.label\n",
            "[NeMo I 2024-11-13 14:31:49 collections:1067] Filtered duration for loading collection is 0.000000.\n",
            "[NeMo I 2024-11-13 14:31:49 collections:1071] Total 1 session files loaded accounting to # 1 audio clips\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/1 [00:00<?, ?it/s][NeMo W 2024-11-13 14:31:49 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/collections/asr/models/msdd_models.py:1333: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "      with autocast():\n",
            "    \n",
            "100%|| 1/1 [00:00<00:00, 16.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:31:49 msdd_models:1407]      [Threshold: 0.7000] [use_clus_as_main=False] [diar_window=50]\n",
            "[NeMo I 2024-11-13 14:31:49 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2024-11-13 14:31:49 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[NeMo W 2024-11-13 14:31:49 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:31:49 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-11-13 14:31:49 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:31:49 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-11-13 14:31:49 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:31:49 msdd_models:1435]   \n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Punctuation restoration is not available for ru language. Using the original punctuation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:35:19 msdd_models:1097] Loading pretrained diar_msdd_telephonic model from NGC\n",
            "[NeMo I 2024-11-13 14:35:19 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_2.0.0rc1/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
            "[NeMo I 2024-11-13 14:35:19 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_2.0.0rc1/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo\n",
            "[NeMo I 2024-11-13 14:35:19 common:826] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-11-13 14:35:21 modelPT:176] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: true\n",
            "    \n",
            "[NeMo W 2024-11-13 14:35:21 modelPT:183] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    \n",
            "[NeMo W 2024-11-13 14:35:21 modelPT:189] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    seq_eval_mode: false\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:35:21 features:305] PADDING: 16\n",
            "[NeMo I 2024-11-13 14:35:22 features:305] PADDING: 16\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-11-13 14:35:22 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/core/connectors/save_restore_connector.py:617: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "      return torch.load(model_weights, map_location='cpu')\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:35:23 save_restore_connector:272] Model EncDecDiarLabelModel was successfully restored from /root/.cache/torch/NeMo/NeMo_2.0.0rc1/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
            "[NeMo I 2024-11-13 14:35:23 features:305] PADDING: 16\n",
            "[NeMo I 2024-11-13 14:35:24 clustering_diarizer:127] Loading pretrained vad_multilingual_marblenet model from NGC\n",
            "[NeMo I 2024-11-13 14:35:24 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_2.0.0rc1/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
            "[NeMo I 2024-11-13 14:35:24 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_2.0.0rc1/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo\n",
            "[NeMo I 2024-11-13 14:35:24 common:826] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-11-13 14:35:24 modelPT:176] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: /manifests/ami_train_0.63.json,/manifests/freesound_background_train.json,/manifests/freesound_laughter_train.json,/manifests/fisher_2004_background.json,/manifests/fisher_2004_speech_sampled.json,/manifests/google_train_manifest.json,/manifests/icsi_all_0.63.json,/manifests/musan_freesound_train.json,/manifests/musan_music_train.json,/manifests/musan_soundbible_train.json,/manifests/mandarin_train_sample.json,/manifests/german_train_sample.json,/manifests/spanish_train_sample.json,/manifests/french_train_sample.json,/manifests/russian_train_sample.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: true\n",
            "    is_tarred: false\n",
            "    tarred_audio_filepaths: null\n",
            "    tarred_shard_strategy: scatter\n",
            "    augmentor:\n",
            "      shift:\n",
            "        prob: 0.5\n",
            "        min_shift_ms: -10.0\n",
            "        max_shift_ms: 10.0\n",
            "      white_noise:\n",
            "        prob: 0.5\n",
            "        min_level: -90\n",
            "        max_level: -46\n",
            "        norm: true\n",
            "      noise:\n",
            "        prob: 0.5\n",
            "        manifest_path: /manifests/noise_0_1_musan_fs.json\n",
            "        min_snr_db: 0\n",
            "        max_snr_db: 30\n",
            "        max_gain_db: 300.0\n",
            "        norm: true\n",
            "      gain:\n",
            "        prob: 0.5\n",
            "        min_gain_dbfs: -10.0\n",
            "        max_gain_dbfs: 10.0\n",
            "        norm: true\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2024-11-13 14:35:24 modelPT:183] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: /manifests/ami_dev_0.63.json,/manifests/freesound_background_dev.json,/manifests/freesound_laughter_dev.json,/manifests/ch120_moved_0.63.json,/manifests/fisher_2005_500_speech_sampled.json,/manifests/google_dev_manifest.json,/manifests/musan_music_dev.json,/manifests/mandarin_dev.json,/manifests/german_dev.json,/manifests/spanish_dev.json,/manifests/french_dev.json,/manifests/russian_dev.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: false\n",
            "    val_loss_idx: 0\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2024-11-13 14:35:24 modelPT:189] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 128\n",
            "    shuffle: false\n",
            "    test_loss_idx: 0\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:35:24 features:305] PADDING: 16\n",
            "[NeMo I 2024-11-13 14:35:24 save_restore_connector:272] Model EncDecClassificationModel was successfully restored from /root/.cache/torch/NeMo/NeMo_2.0.0rc1/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
            "[NeMo I 2024-11-13 14:35:24 msdd_models:870] Multiscale Weights: [1, 1, 1, 1, 1]\n",
            "[NeMo I 2024-11-13 14:35:24 msdd_models:871] Clustering Parameters: {\n",
            "        \"oracle_num_speakers\": false,\n",
            "        \"max_num_speakers\": 8,\n",
            "        \"enhanced_count_thres\": 80,\n",
            "        \"max_rp_threshold\": 0.25,\n",
            "        \"sparse_search_volume\": 30,\n",
            "        \"maj_vote_spk_count\": false,\n",
            "        \"chunk_cluster_count\": 50,\n",
            "        \"embeddings_per_chunk\": 10000\n",
            "    }\n",
            "[NeMo I 2024-11-13 14:35:24 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2024-11-13 14:35:24 clustering_diarizer:313] Split long audio file to avoid CUDA memory issue\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "splitting manifest: 100%|| 1/1 [00:00<00:00, 10.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:35:24 classification_models:293] Perform streaming frame-level VAD\n",
            "[NeMo I 2024-11-13 14:35:24 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-11-13 14:35:24 collections:741] Dataset successfully loaded with 20 items and total duration provided from manifest is  0.27 hours.\n",
            "[NeMo I 2024-11-13 14:35:24 collections:746] # 20 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "vad:   0%|          | 0/20 [00:00<?, ?it/s][NeMo W 2024-11-13 14:35:25 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/collections/asr/models/clustering_diarizer.py:226: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "      with autocast():\n",
            "    \n",
            "[NeMo W 2024-11-13 14:35:25 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/collections/asr/parts/preprocessing/features.py:436: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "      with torch.cuda.amp.autocast(enabled=False):\n",
            "    \n",
            "vad: 100%|| 20/20 [00:04<00:00,  4.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:35:29 clustering_diarizer:254] Generating predictions with overlapping input segments\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "                                                               "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:35:38 clustering_diarizer:266] Converting frame level prediction to speech/no-speech segment in start and end times format.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "creating speech segments: 100%|| 1/1 [00:00<00:00,  1.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:35:39 clustering_diarizer:291] Subsegmentation for embedding extraction: scale0, /content/temp_outputs/speaker_outputs/subsegments_scale0.json\n",
            "[NeMo I 2024-11-13 14:35:39 clustering_diarizer:347] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-11-13 14:35:39 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-11-13 14:35:39 collections:741] Dataset successfully loaded with 701 items and total duration provided from manifest is  0.09 hours.\n",
            "[NeMo I 2024-11-13 14:35:39 collections:746] # 701 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[1/5] extract embeddings:   0%|          | 0/11 [00:00<?, ?it/s][NeMo W 2024-11-13 14:35:39 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/collections/asr/models/clustering_diarizer.py:362: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "      with autocast():\n",
            "    \n",
            "[NeMo W 2024-11-13 14:35:39 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/collections/asr/parts/submodules/jasper.py:476: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "      with torch.cuda.amp.autocast(enabled=False):\n",
            "    \n",
            "[1/5] extract embeddings: 100%|| 11/11 [00:01<00:00,  9.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:35:40 clustering_diarizer:393] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-11-13 14:35:40 clustering_diarizer:291] Subsegmentation for embedding extraction: scale1, /content/temp_outputs/speaker_outputs/subsegments_scale1.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:35:40 clustering_diarizer:347] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-11-13 14:35:40 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-11-13 14:35:40 collections:741] Dataset successfully loaded with 731 items and total duration provided from manifest is  0.09 hours.\n",
            "[NeMo I 2024-11-13 14:35:40 collections:746] # 731 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[2/5] extract embeddings: 100%|| 12/12 [00:00<00:00, 12.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:35:41 clustering_diarizer:393] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-11-13 14:35:41 clustering_diarizer:291] Subsegmentation for embedding extraction: scale2, /content/temp_outputs/speaker_outputs/subsegments_scale2.json\n",
            "[NeMo I 2024-11-13 14:35:41 clustering_diarizer:347] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-11-13 14:35:41 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-11-13 14:35:41 collections:741] Dataset successfully loaded with 769 items and total duration provided from manifest is  0.10 hours.\n",
            "[NeMo I 2024-11-13 14:35:41 collections:746] # 769 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[3/5] extract embeddings: 100%|| 13/13 [00:00<00:00, 13.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:35:42 clustering_diarizer:393] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-11-13 14:35:42 clustering_diarizer:291] Subsegmentation for embedding extraction: scale3, /content/temp_outputs/speaker_outputs/subsegments_scale3.json\n",
            "[NeMo I 2024-11-13 14:35:42 clustering_diarizer:347] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-11-13 14:35:42 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-11-13 14:35:42 collections:741] Dataset successfully loaded with 857 items and total duration provided from manifest is  0.10 hours.\n",
            "[NeMo I 2024-11-13 14:35:42 collections:746] # 857 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[4/5] extract embeddings: 100%|| 14/14 [00:00<00:00, 16.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:35:43 clustering_diarizer:393] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:35:43 clustering_diarizer:291] Subsegmentation for embedding extraction: scale4, /content/temp_outputs/speaker_outputs/subsegments_scale4.json\n",
            "[NeMo I 2024-11-13 14:35:43 clustering_diarizer:347] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-11-13 14:35:43 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-11-13 14:35:43 collections:741] Dataset successfully loaded with 1125 items and total duration provided from manifest is  0.11 hours.\n",
            "[NeMo I 2024-11-13 14:35:43 collections:746] # 1125 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[5/5] extract embeddings: 100%|| 18/18 [00:01<00:00, 17.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:35:44 clustering_diarizer:393] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "clustering: 100%|| 1/1 [00:00<00:00,  2.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:35:45 clustering_diarizer:461] Outputs are saved in /content/temp_outputs directory\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[NeMo W 2024-11-13 14:35:45 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:35:45 msdd_models:966] Loading embedding pickle file of scale:0 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale0_embeddings.pkl\n",
            "[NeMo I 2024-11-13 14:35:45 msdd_models:966] Loading embedding pickle file of scale:1 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale1_embeddings.pkl\n",
            "[NeMo I 2024-11-13 14:35:45 msdd_models:966] Loading embedding pickle file of scale:2 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale2_embeddings.pkl\n",
            "[NeMo I 2024-11-13 14:35:45 msdd_models:966] Loading embedding pickle file of scale:3 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale3_embeddings.pkl\n",
            "[NeMo I 2024-11-13 14:35:45 msdd_models:966] Loading embedding pickle file of scale:4 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale4_embeddings.pkl\n",
            "[NeMo I 2024-11-13 14:35:45 msdd_models:944] Loading cluster label file from /content/temp_outputs/speaker_outputs/subsegments_scale4_cluster.label\n",
            "[NeMo I 2024-11-13 14:35:45 collections:1067] Filtered duration for loading collection is 0.000000.\n",
            "[NeMo I 2024-11-13 14:35:45 collections:1071] Total 1 session files loaded accounting to # 1 audio clips\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/1 [00:00<?, ?it/s][NeMo W 2024-11-13 14:35:45 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/collections/asr/models/msdd_models.py:1333: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "      with autocast():\n",
            "    \n",
            "100%|| 1/1 [00:00<00:00, 10.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:35:45 msdd_models:1407]      [Threshold: 0.7000] [use_clus_as_main=False] [diar_window=50]\n",
            "[NeMo I 2024-11-13 14:35:45 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2024-11-13 14:35:45 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[NeMo W 2024-11-13 14:35:46 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:35:46 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-11-13 14:35:46 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:35:46 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-11-13 14:35:46 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:35:46 msdd_models:1435]   \n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Punctuation restoration is not available for ru language. Using the original punctuation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:38:19 msdd_models:1097] Loading pretrained diar_msdd_telephonic model from NGC\n",
            "[NeMo I 2024-11-13 14:38:19 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_2.0.0rc1/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
            "[NeMo I 2024-11-13 14:38:19 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_2.0.0rc1/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo\n",
            "[NeMo I 2024-11-13 14:38:19 common:826] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-11-13 14:38:21 modelPT:176] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: true\n",
            "    \n",
            "[NeMo W 2024-11-13 14:38:21 modelPT:183] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    \n",
            "[NeMo W 2024-11-13 14:38:21 modelPT:189] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    seq_eval_mode: false\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:38:21 features:305] PADDING: 16\n",
            "[NeMo I 2024-11-13 14:38:21 features:305] PADDING: 16\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-11-13 14:38:21 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/core/connectors/save_restore_connector.py:617: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "      return torch.load(model_weights, map_location='cpu')\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:38:21 save_restore_connector:272] Model EncDecDiarLabelModel was successfully restored from /root/.cache/torch/NeMo/NeMo_2.0.0rc1/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
            "[NeMo I 2024-11-13 14:38:21 features:305] PADDING: 16\n",
            "[NeMo I 2024-11-13 14:38:22 clustering_diarizer:127] Loading pretrained vad_multilingual_marblenet model from NGC\n",
            "[NeMo I 2024-11-13 14:38:22 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_2.0.0rc1/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
            "[NeMo I 2024-11-13 14:38:22 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_2.0.0rc1/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo\n",
            "[NeMo I 2024-11-13 14:38:22 common:826] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-11-13 14:38:22 modelPT:176] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: /manifests/ami_train_0.63.json,/manifests/freesound_background_train.json,/manifests/freesound_laughter_train.json,/manifests/fisher_2004_background.json,/manifests/fisher_2004_speech_sampled.json,/manifests/google_train_manifest.json,/manifests/icsi_all_0.63.json,/manifests/musan_freesound_train.json,/manifests/musan_music_train.json,/manifests/musan_soundbible_train.json,/manifests/mandarin_train_sample.json,/manifests/german_train_sample.json,/manifests/spanish_train_sample.json,/manifests/french_train_sample.json,/manifests/russian_train_sample.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: true\n",
            "    is_tarred: false\n",
            "    tarred_audio_filepaths: null\n",
            "    tarred_shard_strategy: scatter\n",
            "    augmentor:\n",
            "      shift:\n",
            "        prob: 0.5\n",
            "        min_shift_ms: -10.0\n",
            "        max_shift_ms: 10.0\n",
            "      white_noise:\n",
            "        prob: 0.5\n",
            "        min_level: -90\n",
            "        max_level: -46\n",
            "        norm: true\n",
            "      noise:\n",
            "        prob: 0.5\n",
            "        manifest_path: /manifests/noise_0_1_musan_fs.json\n",
            "        min_snr_db: 0\n",
            "        max_snr_db: 30\n",
            "        max_gain_db: 300.0\n",
            "        norm: true\n",
            "      gain:\n",
            "        prob: 0.5\n",
            "        min_gain_dbfs: -10.0\n",
            "        max_gain_dbfs: 10.0\n",
            "        norm: true\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2024-11-13 14:38:22 modelPT:183] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: /manifests/ami_dev_0.63.json,/manifests/freesound_background_dev.json,/manifests/freesound_laughter_dev.json,/manifests/ch120_moved_0.63.json,/manifests/fisher_2005_500_speech_sampled.json,/manifests/google_dev_manifest.json,/manifests/musan_music_dev.json,/manifests/mandarin_dev.json,/manifests/german_dev.json,/manifests/spanish_dev.json,/manifests/french_dev.json,/manifests/russian_dev.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: false\n",
            "    val_loss_idx: 0\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2024-11-13 14:38:22 modelPT:189] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 128\n",
            "    shuffle: false\n",
            "    test_loss_idx: 0\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:38:22 features:305] PADDING: 16\n",
            "[NeMo I 2024-11-13 14:38:22 save_restore_connector:272] Model EncDecClassificationModel was successfully restored from /root/.cache/torch/NeMo/NeMo_2.0.0rc1/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
            "[NeMo I 2024-11-13 14:38:22 msdd_models:870] Multiscale Weights: [1, 1, 1, 1, 1]\n",
            "[NeMo I 2024-11-13 14:38:22 msdd_models:871] Clustering Parameters: {\n",
            "        \"oracle_num_speakers\": false,\n",
            "        \"max_num_speakers\": 8,\n",
            "        \"enhanced_count_thres\": 80,\n",
            "        \"max_rp_threshold\": 0.25,\n",
            "        \"sparse_search_volume\": 30,\n",
            "        \"maj_vote_spk_count\": false,\n",
            "        \"chunk_cluster_count\": 50,\n",
            "        \"embeddings_per_chunk\": 10000\n",
            "    }\n",
            "[NeMo I 2024-11-13 14:38:22 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2024-11-13 14:38:22 clustering_diarizer:313] Split long audio file to avoid CUDA memory issue\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "splitting manifest: 100%|| 1/1 [00:00<00:00, 10.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:38:22 classification_models:293] Perform streaming frame-level VAD\n",
            "[NeMo I 2024-11-13 14:38:22 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-11-13 14:38:22 collections:741] Dataset successfully loaded with 18 items and total duration provided from manifest is  0.25 hours.\n",
            "[NeMo I 2024-11-13 14:38:22 collections:746] # 18 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "vad:   0%|          | 0/18 [00:00<?, ?it/s][NeMo W 2024-11-13 14:38:22 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/collections/asr/models/clustering_diarizer.py:226: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "      with autocast():\n",
            "    \n",
            "[NeMo W 2024-11-13 14:38:22 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/collections/asr/parts/preprocessing/features.py:436: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "      with torch.cuda.amp.autocast(enabled=False):\n",
            "    \n",
            "vad: 100%|| 18/18 [00:04<00:00,  4.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:38:26 clustering_diarizer:254] Generating predictions with overlapping input segments\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "                                                               "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:38:35 clustering_diarizer:266] Converting frame level prediction to speech/no-speech segment in start and end times format.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "creating speech segments: 100%|| 1/1 [00:00<00:00,  1.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:38:36 clustering_diarizer:291] Subsegmentation for embedding extraction: scale0, /content/temp_outputs/speaker_outputs/subsegments_scale0.json\n",
            "[NeMo I 2024-11-13 14:38:36 clustering_diarizer:347] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-11-13 14:38:36 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-11-13 14:38:36 collections:741] Dataset successfully loaded with 689 items and total duration provided from manifest is  0.10 hours.\n",
            "[NeMo I 2024-11-13 14:38:36 collections:746] # 689 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[1/5] extract embeddings:   0%|          | 0/11 [00:00<?, ?it/s][NeMo W 2024-11-13 14:38:36 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/collections/asr/models/clustering_diarizer.py:362: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "      with autocast():\n",
            "    \n",
            "[NeMo W 2024-11-13 14:38:36 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/collections/asr/parts/submodules/jasper.py:476: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "      with torch.cuda.amp.autocast(enabled=False):\n",
            "    \n",
            "[1/5] extract embeddings: 100%|| 11/11 [00:01<00:00,  9.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:38:37 clustering_diarizer:393] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-11-13 14:38:37 clustering_diarizer:291] Subsegmentation for embedding extraction: scale1, /content/temp_outputs/speaker_outputs/subsegments_scale1.json\n",
            "[NeMo I 2024-11-13 14:38:37 clustering_diarizer:347] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-11-13 14:38:37 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-11-13 14:38:37 collections:741] Dataset successfully loaded with 723 items and total duration provided from manifest is  0.10 hours.\n",
            "[NeMo I 2024-11-13 14:38:37 collections:746] # 723 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[2/5] extract embeddings: 100%|| 12/12 [00:00<00:00, 12.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:38:38 clustering_diarizer:393] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-11-13 14:38:38 clustering_diarizer:291] Subsegmentation for embedding extraction: scale2, /content/temp_outputs/speaker_outputs/subsegments_scale2.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:38:38 clustering_diarizer:347] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-11-13 14:38:38 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-11-13 14:38:38 collections:741] Dataset successfully loaded with 780 items and total duration provided from manifest is  0.11 hours.\n",
            "[NeMo I 2024-11-13 14:38:38 collections:746] # 780 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[3/5] extract embeddings: 100%|| 13/13 [00:00<00:00, 13.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:38:39 clustering_diarizer:393] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-11-13 14:38:39 clustering_diarizer:291] Subsegmentation for embedding extraction: scale3, /content/temp_outputs/speaker_outputs/subsegments_scale3.json\n",
            "[NeMo I 2024-11-13 14:38:39 clustering_diarizer:347] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-11-13 14:38:39 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-11-13 14:38:39 collections:741] Dataset successfully loaded with 894 items and total duration provided from manifest is  0.12 hours.\n",
            "[NeMo I 2024-11-13 14:38:39 collections:746] # 894 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[4/5] extract embeddings: 100%|| 14/14 [00:00<00:00, 15.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:38:40 clustering_diarizer:393] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-11-13 14:38:40 clustering_diarizer:291] Subsegmentation for embedding extraction: scale4, /content/temp_outputs/speaker_outputs/subsegments_scale4.json\n",
            "[NeMo I 2024-11-13 14:38:40 clustering_diarizer:347] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-11-13 14:38:40 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-11-13 14:38:40 collections:741] Dataset successfully loaded with 1200 items and total duration provided from manifest is  0.13 hours.\n",
            "[NeMo I 2024-11-13 14:38:40 collections:746] # 1200 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[5/5] extract embeddings: 100%|| 19/19 [00:01<00:00, 12.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:38:42 clustering_diarizer:393] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "clustering: 100%|| 1/1 [00:00<00:00,  1.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:38:43 clustering_diarizer:461] Outputs are saved in /content/temp_outputs directory\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[NeMo W 2024-11-13 14:38:43 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:38:43 msdd_models:966] Loading embedding pickle file of scale:0 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale0_embeddings.pkl\n",
            "[NeMo I 2024-11-13 14:38:43 msdd_models:966] Loading embedding pickle file of scale:1 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale1_embeddings.pkl\n",
            "[NeMo I 2024-11-13 14:38:43 msdd_models:966] Loading embedding pickle file of scale:2 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale2_embeddings.pkl\n",
            "[NeMo I 2024-11-13 14:38:43 msdd_models:966] Loading embedding pickle file of scale:3 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale3_embeddings.pkl\n",
            "[NeMo I 2024-11-13 14:38:43 msdd_models:966] Loading embedding pickle file of scale:4 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale4_embeddings.pkl\n",
            "[NeMo I 2024-11-13 14:38:43 msdd_models:944] Loading cluster label file from /content/temp_outputs/speaker_outputs/subsegments_scale4_cluster.label\n",
            "[NeMo I 2024-11-13 14:38:43 collections:1067] Filtered duration for loading collection is 0.000000.\n",
            "[NeMo I 2024-11-13 14:38:43 collections:1071] Total 1 session files loaded accounting to # 1 audio clips\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/1 [00:00<?, ?it/s][NeMo W 2024-11-13 14:38:43 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/collections/asr/models/msdd_models.py:1333: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "      with autocast():\n",
            "    \n",
            "100%|| 1/1 [00:00<00:00, 14.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:38:43 msdd_models:1407]      [Threshold: 0.7000] [use_clus_as_main=False] [diar_window=50]\n",
            "[NeMo I 2024-11-13 14:38:43 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2024-11-13 14:38:43 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[NeMo W 2024-11-13 14:38:43 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:38:43 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-11-13 14:38:44 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:38:44 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-11-13 14:38:44 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:38:44 msdd_models:1435]   \n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Punctuation restoration is not available for ru language. Using the original punctuation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:42:58 msdd_models:1097] Loading pretrained diar_msdd_telephonic model from NGC\n",
            "[NeMo I 2024-11-13 14:42:58 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_2.0.0rc1/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
            "[NeMo I 2024-11-13 14:42:58 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_2.0.0rc1/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo\n",
            "[NeMo I 2024-11-13 14:42:58 common:826] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-11-13 14:43:01 modelPT:176] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: true\n",
            "    \n",
            "[NeMo W 2024-11-13 14:43:01 modelPT:183] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    \n",
            "[NeMo W 2024-11-13 14:43:01 modelPT:189] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    seq_eval_mode: false\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:43:01 features:305] PADDING: 16\n",
            "[NeMo I 2024-11-13 14:43:03 features:305] PADDING: 16\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-11-13 14:43:04 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/core/connectors/save_restore_connector.py:617: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "      return torch.load(model_weights, map_location='cpu')\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:43:04 save_restore_connector:272] Model EncDecDiarLabelModel was successfully restored from /root/.cache/torch/NeMo/NeMo_2.0.0rc1/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
            "[NeMo I 2024-11-13 14:43:04 features:305] PADDING: 16\n",
            "[NeMo I 2024-11-13 14:43:05 clustering_diarizer:127] Loading pretrained vad_multilingual_marblenet model from NGC\n",
            "[NeMo I 2024-11-13 14:43:05 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_2.0.0rc1/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
            "[NeMo I 2024-11-13 14:43:05 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_2.0.0rc1/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo\n",
            "[NeMo I 2024-11-13 14:43:05 common:826] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-11-13 14:43:05 modelPT:176] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: /manifests/ami_train_0.63.json,/manifests/freesound_background_train.json,/manifests/freesound_laughter_train.json,/manifests/fisher_2004_background.json,/manifests/fisher_2004_speech_sampled.json,/manifests/google_train_manifest.json,/manifests/icsi_all_0.63.json,/manifests/musan_freesound_train.json,/manifests/musan_music_train.json,/manifests/musan_soundbible_train.json,/manifests/mandarin_train_sample.json,/manifests/german_train_sample.json,/manifests/spanish_train_sample.json,/manifests/french_train_sample.json,/manifests/russian_train_sample.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: true\n",
            "    is_tarred: false\n",
            "    tarred_audio_filepaths: null\n",
            "    tarred_shard_strategy: scatter\n",
            "    augmentor:\n",
            "      shift:\n",
            "        prob: 0.5\n",
            "        min_shift_ms: -10.0\n",
            "        max_shift_ms: 10.0\n",
            "      white_noise:\n",
            "        prob: 0.5\n",
            "        min_level: -90\n",
            "        max_level: -46\n",
            "        norm: true\n",
            "      noise:\n",
            "        prob: 0.5\n",
            "        manifest_path: /manifests/noise_0_1_musan_fs.json\n",
            "        min_snr_db: 0\n",
            "        max_snr_db: 30\n",
            "        max_gain_db: 300.0\n",
            "        norm: true\n",
            "      gain:\n",
            "        prob: 0.5\n",
            "        min_gain_dbfs: -10.0\n",
            "        max_gain_dbfs: 10.0\n",
            "        norm: true\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2024-11-13 14:43:05 modelPT:183] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: /manifests/ami_dev_0.63.json,/manifests/freesound_background_dev.json,/manifests/freesound_laughter_dev.json,/manifests/ch120_moved_0.63.json,/manifests/fisher_2005_500_speech_sampled.json,/manifests/google_dev_manifest.json,/manifests/musan_music_dev.json,/manifests/mandarin_dev.json,/manifests/german_dev.json,/manifests/spanish_dev.json,/manifests/french_dev.json,/manifests/russian_dev.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: false\n",
            "    val_loss_idx: 0\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2024-11-13 14:43:05 modelPT:189] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 128\n",
            "    shuffle: false\n",
            "    test_loss_idx: 0\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:43:05 features:305] PADDING: 16\n",
            "[NeMo I 2024-11-13 14:43:05 save_restore_connector:272] Model EncDecClassificationModel was successfully restored from /root/.cache/torch/NeMo/NeMo_2.0.0rc1/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
            "[NeMo I 2024-11-13 14:43:05 msdd_models:870] Multiscale Weights: [1, 1, 1, 1, 1]\n",
            "[NeMo I 2024-11-13 14:43:05 msdd_models:871] Clustering Parameters: {\n",
            "        \"oracle_num_speakers\": false,\n",
            "        \"max_num_speakers\": 8,\n",
            "        \"enhanced_count_thres\": 80,\n",
            "        \"max_rp_threshold\": 0.25,\n",
            "        \"sparse_search_volume\": 30,\n",
            "        \"maj_vote_spk_count\": false,\n",
            "        \"chunk_cluster_count\": 50,\n",
            "        \"embeddings_per_chunk\": 10000\n",
            "    }\n",
            "[NeMo I 2024-11-13 14:43:05 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2024-11-13 14:43:05 clustering_diarizer:313] Split long audio file to avoid CUDA memory issue\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "splitting manifest: 100%|| 1/1 [00:00<00:00,  7.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:43:05 classification_models:293] Perform streaming frame-level VAD\n",
            "[NeMo I 2024-11-13 14:43:05 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-11-13 14:43:05 collections:741] Dataset successfully loaded with 25 items and total duration provided from manifest is  0.35 hours.\n",
            "[NeMo I 2024-11-13 14:43:05 collections:746] # 25 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "vad:   0%|          | 0/25 [00:00<?, ?it/s][NeMo W 2024-11-13 14:43:06 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/collections/asr/models/clustering_diarizer.py:226: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "      with autocast():\n",
            "    \n",
            "[NeMo W 2024-11-13 14:43:06 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/collections/asr/parts/preprocessing/features.py:436: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "      with torch.cuda.amp.autocast(enabled=False):\n",
            "    \n",
            "vad: 100%|| 25/25 [00:05<00:00,  4.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:43:11 clustering_diarizer:254] Generating predictions with overlapping input segments\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "                                                               "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:43:23 clustering_diarizer:266] Converting frame level prediction to speech/no-speech segment in start and end times format.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "creating speech segments: 100%|| 1/1 [00:00<00:00,  1.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:43:24 clustering_diarizer:291] Subsegmentation for embedding extraction: scale0, /content/temp_outputs/speaker_outputs/subsegments_scale0.json\n",
            "[NeMo I 2024-11-13 14:43:24 clustering_diarizer:347] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-11-13 14:43:24 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-11-13 14:43:24 collections:741] Dataset successfully loaded with 657 items and total duration provided from manifest is  0.06 hours.\n",
            "[NeMo I 2024-11-13 14:43:24 collections:746] # 657 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[1/5] extract embeddings:   0%|          | 0/11 [00:00<?, ?it/s][NeMo W 2024-11-13 14:43:24 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/collections/asr/models/clustering_diarizer.py:362: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "      with autocast():\n",
            "    \n",
            "[NeMo W 2024-11-13 14:43:24 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/collections/asr/parts/submodules/jasper.py:476: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "      with torch.cuda.amp.autocast(enabled=False):\n",
            "    \n",
            "[1/5] extract embeddings: 100%|| 11/11 [00:01<00:00, 10.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:43:25 clustering_diarizer:393] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-11-13 14:43:25 clustering_diarizer:291] Subsegmentation for embedding extraction: scale1, /content/temp_outputs/speaker_outputs/subsegments_scale1.json\n",
            "[NeMo I 2024-11-13 14:43:25 clustering_diarizer:347] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-11-13 14:43:25 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-11-13 14:43:25 collections:741] Dataset successfully loaded with 666 items and total duration provided from manifest is  0.07 hours.\n",
            "[NeMo I 2024-11-13 14:43:25 collections:746] # 666 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[2/5] extract embeddings: 100%|| 11/11 [00:00<00:00, 12.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:43:26 clustering_diarizer:393] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-11-13 14:43:26 clustering_diarizer:291] Subsegmentation for embedding extraction: scale2, /content/temp_outputs/speaker_outputs/subsegments_scale2.json\n",
            "[NeMo I 2024-11-13 14:43:26 clustering_diarizer:347] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-11-13 14:43:26 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-11-13 14:43:26 collections:741] Dataset successfully loaded with 685 items and total duration provided from manifest is  0.07 hours.\n",
            "[NeMo I 2024-11-13 14:43:26 collections:746] # 685 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[3/5] extract embeddings: 100%|| 11/11 [00:00<00:00, 13.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:43:27 clustering_diarizer:393] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-11-13 14:43:27 clustering_diarizer:291] Subsegmentation for embedding extraction: scale3, /content/temp_outputs/speaker_outputs/subsegments_scale3.json\n",
            "[NeMo I 2024-11-13 14:43:27 clustering_diarizer:347] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-11-13 14:43:27 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-11-13 14:43:27 collections:741] Dataset successfully loaded with 731 items and total duration provided from manifest is  0.07 hours.\n",
            "[NeMo I 2024-11-13 14:43:27 collections:746] # 731 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[4/5] extract embeddings: 100%|| 12/12 [00:00<00:00, 16.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:43:28 clustering_diarizer:393] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-11-13 14:43:28 clustering_diarizer:291] Subsegmentation for embedding extraction: scale4, /content/temp_outputs/speaker_outputs/subsegments_scale4.json\n",
            "[NeMo I 2024-11-13 14:43:28 clustering_diarizer:347] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-11-13 14:43:28 collections:740] Filtered duration for loading collection is  0.00 hours.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:43:28 collections:741] Dataset successfully loaded with 889 items and total duration provided from manifest is  0.08 hours.\n",
            "[NeMo I 2024-11-13 14:43:28 collections:746] # 889 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[5/5] extract embeddings: 100%|| 14/14 [00:00<00:00, 17.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:43:29 clustering_diarizer:393] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "clustering: 100%|| 1/1 [00:00<00:00,  1.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:43:30 clustering_diarizer:461] Outputs are saved in /content/temp_outputs directory\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[NeMo W 2024-11-13 14:43:30 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:43:30 msdd_models:966] Loading embedding pickle file of scale:0 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale0_embeddings.pkl\n",
            "[NeMo I 2024-11-13 14:43:30 msdd_models:966] Loading embedding pickle file of scale:1 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale1_embeddings.pkl\n",
            "[NeMo I 2024-11-13 14:43:30 msdd_models:966] Loading embedding pickle file of scale:2 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale2_embeddings.pkl\n",
            "[NeMo I 2024-11-13 14:43:30 msdd_models:966] Loading embedding pickle file of scale:3 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale3_embeddings.pkl\n",
            "[NeMo I 2024-11-13 14:43:30 msdd_models:966] Loading embedding pickle file of scale:4 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale4_embeddings.pkl\n",
            "[NeMo I 2024-11-13 14:43:30 msdd_models:944] Loading cluster label file from /content/temp_outputs/speaker_outputs/subsegments_scale4_cluster.label\n",
            "[NeMo I 2024-11-13 14:43:30 collections:1067] Filtered duration for loading collection is 0.000000.\n",
            "[NeMo I 2024-11-13 14:43:30 collections:1071] Total 1 session files loaded accounting to # 1 audio clips\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/1 [00:00<?, ?it/s][NeMo W 2024-11-13 14:43:30 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/collections/asr/models/msdd_models.py:1333: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "      with autocast():\n",
            "    \n",
            "100%|| 1/1 [00:00<00:00, 15.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:43:30 msdd_models:1407]      [Threshold: 0.7000] [use_clus_as_main=False] [diar_window=50]\n",
            "[NeMo I 2024-11-13 14:43:30 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2024-11-13 14:43:30 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[NeMo W 2024-11-13 14:43:30 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:43:30 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-11-13 14:43:30 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:43:30 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-11-13 14:43:30 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:43:30 msdd_models:1435]   \n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Punctuation restoration is not available for ru language. Using the original punctuation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:47:48 msdd_models:1097] Loading pretrained diar_msdd_telephonic model from NGC\n",
            "[NeMo I 2024-11-13 14:47:48 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_2.0.0rc1/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
            "[NeMo I 2024-11-13 14:47:48 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_2.0.0rc1/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo\n",
            "[NeMo I 2024-11-13 14:47:48 common:826] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-11-13 14:47:50 modelPT:176] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: true\n",
            "    \n",
            "[NeMo W 2024-11-13 14:47:50 modelPT:183] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    \n",
            "[NeMo W 2024-11-13 14:47:50 modelPT:189] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    seq_eval_mode: false\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:47:50 features:305] PADDING: 16\n",
            "[NeMo I 2024-11-13 14:47:50 features:305] PADDING: 16\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-11-13 14:47:50 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/core/connectors/save_restore_connector.py:617: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "      return torch.load(model_weights, map_location='cpu')\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:47:51 save_restore_connector:272] Model EncDecDiarLabelModel was successfully restored from /root/.cache/torch/NeMo/NeMo_2.0.0rc1/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
            "[NeMo I 2024-11-13 14:47:51 features:305] PADDING: 16\n",
            "[NeMo I 2024-11-13 14:47:52 clustering_diarizer:127] Loading pretrained vad_multilingual_marblenet model from NGC\n",
            "[NeMo I 2024-11-13 14:47:52 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_2.0.0rc1/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
            "[NeMo I 2024-11-13 14:47:52 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_2.0.0rc1/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo\n",
            "[NeMo I 2024-11-13 14:47:52 common:826] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-11-13 14:47:52 modelPT:176] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: /manifests/ami_train_0.63.json,/manifests/freesound_background_train.json,/manifests/freesound_laughter_train.json,/manifests/fisher_2004_background.json,/manifests/fisher_2004_speech_sampled.json,/manifests/google_train_manifest.json,/manifests/icsi_all_0.63.json,/manifests/musan_freesound_train.json,/manifests/musan_music_train.json,/manifests/musan_soundbible_train.json,/manifests/mandarin_train_sample.json,/manifests/german_train_sample.json,/manifests/spanish_train_sample.json,/manifests/french_train_sample.json,/manifests/russian_train_sample.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: true\n",
            "    is_tarred: false\n",
            "    tarred_audio_filepaths: null\n",
            "    tarred_shard_strategy: scatter\n",
            "    augmentor:\n",
            "      shift:\n",
            "        prob: 0.5\n",
            "        min_shift_ms: -10.0\n",
            "        max_shift_ms: 10.0\n",
            "      white_noise:\n",
            "        prob: 0.5\n",
            "        min_level: -90\n",
            "        max_level: -46\n",
            "        norm: true\n",
            "      noise:\n",
            "        prob: 0.5\n",
            "        manifest_path: /manifests/noise_0_1_musan_fs.json\n",
            "        min_snr_db: 0\n",
            "        max_snr_db: 30\n",
            "        max_gain_db: 300.0\n",
            "        norm: true\n",
            "      gain:\n",
            "        prob: 0.5\n",
            "        min_gain_dbfs: -10.0\n",
            "        max_gain_dbfs: 10.0\n",
            "        norm: true\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2024-11-13 14:47:52 modelPT:183] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: /manifests/ami_dev_0.63.json,/manifests/freesound_background_dev.json,/manifests/freesound_laughter_dev.json,/manifests/ch120_moved_0.63.json,/manifests/fisher_2005_500_speech_sampled.json,/manifests/google_dev_manifest.json,/manifests/musan_music_dev.json,/manifests/mandarin_dev.json,/manifests/german_dev.json,/manifests/spanish_dev.json,/manifests/french_dev.json,/manifests/russian_dev.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: false\n",
            "    val_loss_idx: 0\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2024-11-13 14:47:52 modelPT:189] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 128\n",
            "    shuffle: false\n",
            "    test_loss_idx: 0\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:47:52 features:305] PADDING: 16\n",
            "[NeMo I 2024-11-13 14:47:52 save_restore_connector:272] Model EncDecClassificationModel was successfully restored from /root/.cache/torch/NeMo/NeMo_2.0.0rc1/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
            "[NeMo I 2024-11-13 14:47:52 msdd_models:870] Multiscale Weights: [1, 1, 1, 1, 1]\n",
            "[NeMo I 2024-11-13 14:47:52 msdd_models:871] Clustering Parameters: {\n",
            "        \"oracle_num_speakers\": false,\n",
            "        \"max_num_speakers\": 8,\n",
            "        \"enhanced_count_thres\": 80,\n",
            "        \"max_rp_threshold\": 0.25,\n",
            "        \"sparse_search_volume\": 30,\n",
            "        \"maj_vote_spk_count\": false,\n",
            "        \"chunk_cluster_count\": 50,\n",
            "        \"embeddings_per_chunk\": 10000\n",
            "    }\n",
            "[NeMo I 2024-11-13 14:47:52 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2024-11-13 14:47:52 clustering_diarizer:313] Split long audio file to avoid CUDA memory issue\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "splitting manifest: 100%|| 1/1 [00:00<00:00,  6.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:47:52 classification_models:293] Perform streaming frame-level VAD\n",
            "[NeMo I 2024-11-13 14:47:52 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-11-13 14:47:52 collections:741] Dataset successfully loaded with 28 items and total duration provided from manifest is  0.38 hours.\n",
            "[NeMo I 2024-11-13 14:47:52 collections:746] # 28 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "vad:   0%|          | 0/28 [00:00<?, ?it/s][NeMo W 2024-11-13 14:47:52 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/collections/asr/models/clustering_diarizer.py:226: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "      with autocast():\n",
            "    \n",
            "[NeMo W 2024-11-13 14:47:52 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/collections/asr/parts/preprocessing/features.py:436: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "      with torch.cuda.amp.autocast(enabled=False):\n",
            "    \n",
            "vad: 100%|| 28/28 [00:06<00:00,  4.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:47:59 clustering_diarizer:254] Generating predictions with overlapping input segments\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "                                                               "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:48:12 clustering_diarizer:266] Converting frame level prediction to speech/no-speech segment in start and end times format.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "creating speech segments: 100%|| 1/1 [00:00<00:00,  1.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:48:13 clustering_diarizer:291] Subsegmentation for embedding extraction: scale0, /content/temp_outputs/speaker_outputs/subsegments_scale0.json\n",
            "[NeMo I 2024-11-13 14:48:13 clustering_diarizer:347] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-11-13 14:48:13 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-11-13 14:48:13 collections:741] Dataset successfully loaded with 930 items and total duration provided from manifest is  0.15 hours.\n",
            "[NeMo I 2024-11-13 14:48:13 collections:746] # 930 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[1/5] extract embeddings:   0%|          | 0/15 [00:00<?, ?it/s][NeMo W 2024-11-13 14:48:13 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/collections/asr/models/clustering_diarizer.py:362: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "      with autocast():\n",
            "    \n",
            "[NeMo W 2024-11-13 14:48:13 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/collections/asr/parts/submodules/jasper.py:476: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "      with torch.cuda.amp.autocast(enabled=False):\n",
            "    \n",
            "[1/5] extract embeddings: 100%|| 15/15 [00:01<00:00,  9.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:48:14 clustering_diarizer:393] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-11-13 14:48:14 clustering_diarizer:291] Subsegmentation for embedding extraction: scale1, /content/temp_outputs/speaker_outputs/subsegments_scale1.json\n",
            "[NeMo I 2024-11-13 14:48:14 clustering_diarizer:347] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-11-13 14:48:15 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-11-13 14:48:15 collections:741] Dataset successfully loaded with 988 items and total duration provided from manifest is  0.15 hours.\n",
            "[NeMo I 2024-11-13 14:48:15 collections:746] # 988 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[2/5] extract embeddings: 100%|| 16/16 [00:01<00:00, 12.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:48:16 clustering_diarizer:393] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-11-13 14:48:16 clustering_diarizer:291] Subsegmentation for embedding extraction: scale2, /content/temp_outputs/speaker_outputs/subsegments_scale2.json\n",
            "[NeMo I 2024-11-13 14:48:16 clustering_diarizer:347] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-11-13 14:48:16 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-11-13 14:48:16 collections:741] Dataset successfully loaded with 1082 items and total duration provided from manifest is  0.16 hours.\n",
            "[NeMo I 2024-11-13 14:48:16 collections:746] # 1082 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[3/5] extract embeddings: 100%|| 17/17 [00:01<00:00, 12.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:48:17 clustering_diarizer:393] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-11-13 14:48:17 clustering_diarizer:291] Subsegmentation for embedding extraction: scale3, /content/temp_outputs/speaker_outputs/subsegments_scale3.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:48:17 clustering_diarizer:347] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-11-13 14:48:17 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-11-13 14:48:17 collections:741] Dataset successfully loaded with 1268 items and total duration provided from manifest is  0.17 hours.\n",
            "[NeMo I 2024-11-13 14:48:17 collections:746] # 1268 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[4/5] extract embeddings: 100%|| 20/20 [00:01<00:00, 12.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:48:19 clustering_diarizer:393] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-11-13 14:48:19 clustering_diarizer:291] Subsegmentation for embedding extraction: scale4, /content/temp_outputs/speaker_outputs/subsegments_scale4.json\n",
            "[NeMo I 2024-11-13 14:48:20 clustering_diarizer:347] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-11-13 14:48:20 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-11-13 14:48:20 collections:741] Dataset successfully loaded with 1757 items and total duration provided from manifest is  0.19 hours.\n",
            "[NeMo I 2024-11-13 14:48:20 collections:746] # 1757 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[5/5] extract embeddings: 100%|| 28/28 [00:01<00:00, 15.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:48:22 clustering_diarizer:393] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "clustering: 100%|| 1/1 [00:00<00:00,  1.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:48:23 clustering_diarizer:461] Outputs are saved in /content/temp_outputs directory\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[NeMo W 2024-11-13 14:48:23 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:48:23 msdd_models:966] Loading embedding pickle file of scale:0 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale0_embeddings.pkl\n",
            "[NeMo I 2024-11-13 14:48:23 msdd_models:966] Loading embedding pickle file of scale:1 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale1_embeddings.pkl\n",
            "[NeMo I 2024-11-13 14:48:23 msdd_models:966] Loading embedding pickle file of scale:2 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale2_embeddings.pkl\n",
            "[NeMo I 2024-11-13 14:48:23 msdd_models:966] Loading embedding pickle file of scale:3 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale3_embeddings.pkl\n",
            "[NeMo I 2024-11-13 14:48:23 msdd_models:966] Loading embedding pickle file of scale:4 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale4_embeddings.pkl\n",
            "[NeMo I 2024-11-13 14:48:23 msdd_models:944] Loading cluster label file from /content/temp_outputs/speaker_outputs/subsegments_scale4_cluster.label\n",
            "[NeMo I 2024-11-13 14:48:23 collections:1067] Filtered duration for loading collection is 0.000000.\n",
            "[NeMo I 2024-11-13 14:48:23 collections:1071] Total 1 session files loaded accounting to # 1 audio clips\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/1 [00:00<?, ?it/s][NeMo W 2024-11-13 14:48:23 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/collections/asr/models/msdd_models.py:1333: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "      with autocast():\n",
            "    \n",
            "100%|| 1/1 [00:00<00:00, 10.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:48:23 msdd_models:1407]      [Threshold: 0.7000] [use_clus_as_main=False] [diar_window=50]\n",
            "[NeMo I 2024-11-13 14:48:23 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2024-11-13 14:48:23 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[NeMo W 2024-11-13 14:48:23 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:48:23 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-11-13 14:48:23 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:48:23 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-11-13 14:48:23 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:48:23 msdd_models:1435]   \n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Punctuation restoration is not available for ru language. Using the original punctuation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:51:03 msdd_models:1097] Loading pretrained diar_msdd_telephonic model from NGC\n",
            "[NeMo I 2024-11-13 14:51:03 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_2.0.0rc1/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
            "[NeMo I 2024-11-13 14:51:03 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_2.0.0rc1/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo\n",
            "[NeMo I 2024-11-13 14:51:03 common:826] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-11-13 14:51:05 modelPT:176] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: true\n",
            "    \n",
            "[NeMo W 2024-11-13 14:51:05 modelPT:183] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    \n",
            "[NeMo W 2024-11-13 14:51:05 modelPT:189] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    seq_eval_mode: false\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:51:05 features:305] PADDING: 16\n",
            "[NeMo I 2024-11-13 14:51:05 features:305] PADDING: 16\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-11-13 14:51:06 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/core/connectors/save_restore_connector.py:617: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "      return torch.load(model_weights, map_location='cpu')\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:51:09 save_restore_connector:272] Model EncDecDiarLabelModel was successfully restored from /root/.cache/torch/NeMo/NeMo_2.0.0rc1/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
            "[NeMo I 2024-11-13 14:51:09 features:305] PADDING: 16\n",
            "[NeMo I 2024-11-13 14:51:09 clustering_diarizer:127] Loading pretrained vad_multilingual_marblenet model from NGC\n",
            "[NeMo I 2024-11-13 14:51:09 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_2.0.0rc1/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
            "[NeMo I 2024-11-13 14:51:09 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_2.0.0rc1/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo\n",
            "[NeMo I 2024-11-13 14:51:09 common:826] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-11-13 14:51:09 modelPT:176] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: /manifests/ami_train_0.63.json,/manifests/freesound_background_train.json,/manifests/freesound_laughter_train.json,/manifests/fisher_2004_background.json,/manifests/fisher_2004_speech_sampled.json,/manifests/google_train_manifest.json,/manifests/icsi_all_0.63.json,/manifests/musan_freesound_train.json,/manifests/musan_music_train.json,/manifests/musan_soundbible_train.json,/manifests/mandarin_train_sample.json,/manifests/german_train_sample.json,/manifests/spanish_train_sample.json,/manifests/french_train_sample.json,/manifests/russian_train_sample.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: true\n",
            "    is_tarred: false\n",
            "    tarred_audio_filepaths: null\n",
            "    tarred_shard_strategy: scatter\n",
            "    augmentor:\n",
            "      shift:\n",
            "        prob: 0.5\n",
            "        min_shift_ms: -10.0\n",
            "        max_shift_ms: 10.0\n",
            "      white_noise:\n",
            "        prob: 0.5\n",
            "        min_level: -90\n",
            "        max_level: -46\n",
            "        norm: true\n",
            "      noise:\n",
            "        prob: 0.5\n",
            "        manifest_path: /manifests/noise_0_1_musan_fs.json\n",
            "        min_snr_db: 0\n",
            "        max_snr_db: 30\n",
            "        max_gain_db: 300.0\n",
            "        norm: true\n",
            "      gain:\n",
            "        prob: 0.5\n",
            "        min_gain_dbfs: -10.0\n",
            "        max_gain_dbfs: 10.0\n",
            "        norm: true\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2024-11-13 14:51:09 modelPT:183] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: /manifests/ami_dev_0.63.json,/manifests/freesound_background_dev.json,/manifests/freesound_laughter_dev.json,/manifests/ch120_moved_0.63.json,/manifests/fisher_2005_500_speech_sampled.json,/manifests/google_dev_manifest.json,/manifests/musan_music_dev.json,/manifests/mandarin_dev.json,/manifests/german_dev.json,/manifests/spanish_dev.json,/manifests/french_dev.json,/manifests/russian_dev.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: false\n",
            "    val_loss_idx: 0\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2024-11-13 14:51:09 modelPT:189] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 128\n",
            "    shuffle: false\n",
            "    test_loss_idx: 0\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:51:09 features:305] PADDING: 16\n",
            "[NeMo I 2024-11-13 14:51:09 save_restore_connector:272] Model EncDecClassificationModel was successfully restored from /root/.cache/torch/NeMo/NeMo_2.0.0rc1/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
            "[NeMo I 2024-11-13 14:51:09 msdd_models:870] Multiscale Weights: [1, 1, 1, 1, 1]\n",
            "[NeMo I 2024-11-13 14:51:09 msdd_models:871] Clustering Parameters: {\n",
            "        \"oracle_num_speakers\": false,\n",
            "        \"max_num_speakers\": 8,\n",
            "        \"enhanced_count_thres\": 80,\n",
            "        \"max_rp_threshold\": 0.25,\n",
            "        \"sparse_search_volume\": 30,\n",
            "        \"maj_vote_spk_count\": false,\n",
            "        \"chunk_cluster_count\": 50,\n",
            "        \"embeddings_per_chunk\": 10000\n",
            "    }\n",
            "[NeMo I 2024-11-13 14:51:09 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2024-11-13 14:51:09 clustering_diarizer:313] Split long audio file to avoid CUDA memory issue\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "splitting manifest: 100%|| 1/1 [00:00<00:00,  8.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:51:10 classification_models:293] Perform streaming frame-level VAD\n",
            "[NeMo I 2024-11-13 14:51:10 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-11-13 14:51:10 collections:741] Dataset successfully loaded with 18 items and total duration provided from manifest is  0.24 hours.\n",
            "[NeMo I 2024-11-13 14:51:10 collections:746] # 18 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "vad:   0%|          | 0/18 [00:00<?, ?it/s][NeMo W 2024-11-13 14:51:10 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/collections/asr/models/clustering_diarizer.py:226: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "      with autocast():\n",
            "    \n",
            "[NeMo W 2024-11-13 14:51:10 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/collections/asr/parts/preprocessing/features.py:436: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "      with torch.cuda.amp.autocast(enabled=False):\n",
            "    \n",
            "vad: 100%|| 18/18 [00:04<00:00,  4.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:51:14 clustering_diarizer:254] Generating predictions with overlapping input segments\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "                                                               "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:51:22 clustering_diarizer:266] Converting frame level prediction to speech/no-speech segment in start and end times format.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "creating speech segments: 100%|| 1/1 [00:00<00:00,  1.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:51:23 clustering_diarizer:291] Subsegmentation for embedding extraction: scale0, /content/temp_outputs/speaker_outputs/subsegments_scale0.json\n",
            "[NeMo I 2024-11-13 14:51:23 clustering_diarizer:347] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-11-13 14:51:23 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-11-13 14:51:23 collections:741] Dataset successfully loaded with 701 items and total duration provided from manifest is  0.15 hours.\n",
            "[NeMo I 2024-11-13 14:51:23 collections:746] # 701 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[1/5] extract embeddings:   0%|          | 0/11 [00:00<?, ?it/s][NeMo W 2024-11-13 14:51:23 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/collections/asr/models/clustering_diarizer.py:362: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "      with autocast():\n",
            "    \n",
            "[NeMo W 2024-11-13 14:51:23 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/collections/asr/parts/submodules/jasper.py:476: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "      with torch.cuda.amp.autocast(enabled=False):\n",
            "    \n",
            "[1/5] extract embeddings: 100%|| 11/11 [00:01<00:00,  8.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:51:24 clustering_diarizer:393] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-11-13 14:51:24 clustering_diarizer:291] Subsegmentation for embedding extraction: scale1, /content/temp_outputs/speaker_outputs/subsegments_scale1.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:51:24 clustering_diarizer:347] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-11-13 14:51:24 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-11-13 14:51:24 collections:741] Dataset successfully loaded with 791 items and total duration provided from manifest is  0.16 hours.\n",
            "[NeMo I 2024-11-13 14:51:24 collections:746] # 791 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[2/5] extract embeddings: 100%|| 13/13 [00:01<00:00, 12.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:51:25 clustering_diarizer:393] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-11-13 14:51:25 clustering_diarizer:291] Subsegmentation for embedding extraction: scale2, /content/temp_outputs/speaker_outputs/subsegments_scale2.json\n",
            "[NeMo I 2024-11-13 14:51:25 clustering_diarizer:347] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-11-13 14:51:25 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-11-13 14:51:25 collections:741] Dataset successfully loaded with 915 items and total duration provided from manifest is  0.17 hours.\n",
            "[NeMo I 2024-11-13 14:51:25 collections:746] # 915 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[3/5] extract embeddings: 100%|| 15/15 [00:01<00:00, 12.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:51:26 clustering_diarizer:393] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-11-13 14:51:26 clustering_diarizer:291] Subsegmentation for embedding extraction: scale3, /content/temp_outputs/speaker_outputs/subsegments_scale3.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:51:26 clustering_diarizer:347] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-11-13 14:51:26 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-11-13 14:51:26 collections:741] Dataset successfully loaded with 1138 items and total duration provided from manifest is  0.19 hours.\n",
            "[NeMo I 2024-11-13 14:51:26 collections:746] # 1138 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[4/5] extract embeddings: 100%|| 18/18 [00:01<00:00, 14.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:51:28 clustering_diarizer:393] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-11-13 14:51:28 clustering_diarizer:291] Subsegmentation for embedding extraction: scale4, /content/temp_outputs/speaker_outputs/subsegments_scale4.json\n",
            "[NeMo I 2024-11-13 14:51:28 clustering_diarizer:347] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-11-13 14:51:28 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-11-13 14:51:28 collections:741] Dataset successfully loaded with 1666 items and total duration provided from manifest is  0.20 hours.\n",
            "[NeMo I 2024-11-13 14:51:28 collections:746] # 1666 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[5/5] extract embeddings: 100%|| 27/27 [00:01<00:00, 13.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:51:30 clustering_diarizer:393] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "clustering: 100%|| 1/1 [00:00<00:00,  1.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:51:31 clustering_diarizer:461] Outputs are saved in /content/temp_outputs directory\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[NeMo W 2024-11-13 14:51:31 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:51:31 msdd_models:966] Loading embedding pickle file of scale:0 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale0_embeddings.pkl\n",
            "[NeMo I 2024-11-13 14:51:31 msdd_models:966] Loading embedding pickle file of scale:1 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale1_embeddings.pkl\n",
            "[NeMo I 2024-11-13 14:51:31 msdd_models:966] Loading embedding pickle file of scale:2 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale2_embeddings.pkl\n",
            "[NeMo I 2024-11-13 14:51:31 msdd_models:966] Loading embedding pickle file of scale:3 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale3_embeddings.pkl\n",
            "[NeMo I 2024-11-13 14:51:31 msdd_models:966] Loading embedding pickle file of scale:4 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale4_embeddings.pkl\n",
            "[NeMo I 2024-11-13 14:51:31 msdd_models:944] Loading cluster label file from /content/temp_outputs/speaker_outputs/subsegments_scale4_cluster.label\n",
            "[NeMo I 2024-11-13 14:51:31 collections:1067] Filtered duration for loading collection is 0.000000.\n",
            "[NeMo I 2024-11-13 14:51:31 collections:1071] Total 1 session files loaded accounting to # 1 audio clips\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/1 [00:00<?, ?it/s][NeMo W 2024-11-13 14:51:31 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/collections/asr/models/msdd_models.py:1333: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "      with autocast():\n",
            "    \n",
            "100%|| 1/1 [00:00<00:00,  9.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:51:31 msdd_models:1407]      [Threshold: 0.7000] [use_clus_as_main=False] [diar_window=50]\n",
            "[NeMo I 2024-11-13 14:51:31 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2024-11-13 14:51:31 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[NeMo W 2024-11-13 14:51:32 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:51:32 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-11-13 14:51:32 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:51:32 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-11-13 14:51:32 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:51:32 msdd_models:1435]   \n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Punctuation restoration is not available for ru language. Using the original punctuation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:52:30 msdd_models:1097] Loading pretrained diar_msdd_telephonic model from NGC\n",
            "[NeMo I 2024-11-13 14:52:30 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_2.0.0rc1/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
            "[NeMo I 2024-11-13 14:52:30 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_2.0.0rc1/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo\n",
            "[NeMo I 2024-11-13 14:52:30 common:826] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-11-13 14:52:32 modelPT:176] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: true\n",
            "    \n",
            "[NeMo W 2024-11-13 14:52:32 modelPT:183] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    \n",
            "[NeMo W 2024-11-13 14:52:32 modelPT:189] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    seq_eval_mode: false\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:52:32 features:305] PADDING: 16\n",
            "[NeMo I 2024-11-13 14:52:33 features:305] PADDING: 16\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-11-13 14:52:34 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/core/connectors/save_restore_connector.py:617: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "      return torch.load(model_weights, map_location='cpu')\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:52:34 save_restore_connector:272] Model EncDecDiarLabelModel was successfully restored from /root/.cache/torch/NeMo/NeMo_2.0.0rc1/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
            "[NeMo I 2024-11-13 14:52:34 features:305] PADDING: 16\n",
            "[NeMo I 2024-11-13 14:52:35 clustering_diarizer:127] Loading pretrained vad_multilingual_marblenet model from NGC\n",
            "[NeMo I 2024-11-13 14:52:35 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_2.0.0rc1/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
            "[NeMo I 2024-11-13 14:52:35 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_2.0.0rc1/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo\n",
            "[NeMo I 2024-11-13 14:52:35 common:826] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-11-13 14:52:35 modelPT:176] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: /manifests/ami_train_0.63.json,/manifests/freesound_background_train.json,/manifests/freesound_laughter_train.json,/manifests/fisher_2004_background.json,/manifests/fisher_2004_speech_sampled.json,/manifests/google_train_manifest.json,/manifests/icsi_all_0.63.json,/manifests/musan_freesound_train.json,/manifests/musan_music_train.json,/manifests/musan_soundbible_train.json,/manifests/mandarin_train_sample.json,/manifests/german_train_sample.json,/manifests/spanish_train_sample.json,/manifests/french_train_sample.json,/manifests/russian_train_sample.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: true\n",
            "    is_tarred: false\n",
            "    tarred_audio_filepaths: null\n",
            "    tarred_shard_strategy: scatter\n",
            "    augmentor:\n",
            "      shift:\n",
            "        prob: 0.5\n",
            "        min_shift_ms: -10.0\n",
            "        max_shift_ms: 10.0\n",
            "      white_noise:\n",
            "        prob: 0.5\n",
            "        min_level: -90\n",
            "        max_level: -46\n",
            "        norm: true\n",
            "      noise:\n",
            "        prob: 0.5\n",
            "        manifest_path: /manifests/noise_0_1_musan_fs.json\n",
            "        min_snr_db: 0\n",
            "        max_snr_db: 30\n",
            "        max_gain_db: 300.0\n",
            "        norm: true\n",
            "      gain:\n",
            "        prob: 0.5\n",
            "        min_gain_dbfs: -10.0\n",
            "        max_gain_dbfs: 10.0\n",
            "        norm: true\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2024-11-13 14:52:35 modelPT:183] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: /manifests/ami_dev_0.63.json,/manifests/freesound_background_dev.json,/manifests/freesound_laughter_dev.json,/manifests/ch120_moved_0.63.json,/manifests/fisher_2005_500_speech_sampled.json,/manifests/google_dev_manifest.json,/manifests/musan_music_dev.json,/manifests/mandarin_dev.json,/manifests/german_dev.json,/manifests/spanish_dev.json,/manifests/french_dev.json,/manifests/russian_dev.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: false\n",
            "    val_loss_idx: 0\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2024-11-13 14:52:35 modelPT:189] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 128\n",
            "    shuffle: false\n",
            "    test_loss_idx: 0\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:52:35 features:305] PADDING: 16\n",
            "[NeMo I 2024-11-13 14:52:35 save_restore_connector:272] Model EncDecClassificationModel was successfully restored from /root/.cache/torch/NeMo/NeMo_2.0.0rc1/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
            "[NeMo I 2024-11-13 14:52:35 msdd_models:870] Multiscale Weights: [1, 1, 1, 1, 1]\n",
            "[NeMo I 2024-11-13 14:52:35 msdd_models:871] Clustering Parameters: {\n",
            "        \"oracle_num_speakers\": false,\n",
            "        \"max_num_speakers\": 8,\n",
            "        \"enhanced_count_thres\": 80,\n",
            "        \"max_rp_threshold\": 0.25,\n",
            "        \"sparse_search_volume\": 30,\n",
            "        \"maj_vote_spk_count\": false,\n",
            "        \"chunk_cluster_count\": 50,\n",
            "        \"embeddings_per_chunk\": 10000\n",
            "    }\n",
            "[NeMo I 2024-11-13 14:52:35 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2024-11-13 14:52:35 clustering_diarizer:313] Split long audio file to avoid CUDA memory issue\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "splitting manifest: 100%|| 1/1 [00:00<00:00, 45.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:52:35 classification_models:293] Perform streaming frame-level VAD\n",
            "[NeMo I 2024-11-13 14:52:35 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-11-13 14:52:35 collections:741] Dataset successfully loaded with 4 items and total duration provided from manifest is  0.05 hours.\n",
            "[NeMo I 2024-11-13 14:52:35 collections:746] # 4 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rvad:   0%|          | 0/4 [00:00<?, ?it/s][NeMo W 2024-11-13 14:52:35 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/collections/asr/models/clustering_diarizer.py:226: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "      with autocast():\n",
            "    \n",
            "[NeMo W 2024-11-13 14:52:35 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/collections/asr/parts/preprocessing/features.py:436: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "      with torch.cuda.amp.autocast(enabled=False):\n",
            "    \n",
            "vad: 100%|| 4/4 [00:00<00:00,  5.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:52:36 clustering_diarizer:254] Generating predictions with overlapping input segments\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "                                                               "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:52:38 clustering_diarizer:266] Converting frame level prediction to speech/no-speech segment in start and end times format.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "creating speech segments: 100%|| 1/1 [00:00<00:00,  7.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:52:38 clustering_diarizer:291] Subsegmentation for embedding extraction: scale0, /content/temp_outputs/speaker_outputs/subsegments_scale0.json\n",
            "[NeMo I 2024-11-13 14:52:38 clustering_diarizer:347] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-11-13 14:52:38 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-11-13 14:52:38 collections:741] Dataset successfully loaded with 107 items and total duration provided from manifest is  0.01 hours.\n",
            "[NeMo I 2024-11-13 14:52:38 collections:746] # 107 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[1/5] extract embeddings:   0%|          | 0/2 [00:00<?, ?it/s][NeMo W 2024-11-13 14:52:38 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/collections/asr/models/clustering_diarizer.py:362: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "      with autocast():\n",
            "    \n",
            "[NeMo W 2024-11-13 14:52:38 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/collections/asr/parts/submodules/jasper.py:476: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "      with torch.cuda.amp.autocast(enabled=False):\n",
            "    \n",
            "[1/5] extract embeddings: 100%|| 2/2 [00:00<00:00,  9.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:52:38 clustering_diarizer:393] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-11-13 14:52:38 clustering_diarizer:291] Subsegmentation for embedding extraction: scale1, /content/temp_outputs/speaker_outputs/subsegments_scale1.json\n",
            "[NeMo I 2024-11-13 14:52:38 clustering_diarizer:347] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-11-13 14:52:38 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-11-13 14:52:38 collections:741] Dataset successfully loaded with 111 items and total duration provided from manifest is  0.02 hours.\n",
            "[NeMo I 2024-11-13 14:52:38 collections:746] # 111 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[2/5] extract embeddings: 100%|| 2/2 [00:00<00:00, 11.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:52:38 clustering_diarizer:393] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:52:38 clustering_diarizer:291] Subsegmentation for embedding extraction: scale2, /content/temp_outputs/speaker_outputs/subsegments_scale2.json\n",
            "[NeMo I 2024-11-13 14:52:38 clustering_diarizer:347] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-11-13 14:52:38 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-11-13 14:52:38 collections:741] Dataset successfully loaded with 119 items and total duration provided from manifest is  0.02 hours.\n",
            "[NeMo I 2024-11-13 14:52:38 collections:746] # 119 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[3/5] extract embeddings: 100%|| 2/2 [00:00<00:00, 12.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:52:38 clustering_diarizer:393] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-11-13 14:52:38 clustering_diarizer:291] Subsegmentation for embedding extraction: scale3, /content/temp_outputs/speaker_outputs/subsegments_scale3.json\n",
            "[NeMo I 2024-11-13 14:52:38 clustering_diarizer:347] Extracting embeddings for Diarization\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:52:38 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-11-13 14:52:38 collections:741] Dataset successfully loaded with 136 items and total duration provided from manifest is  0.02 hours.\n",
            "[NeMo I 2024-11-13 14:52:38 collections:746] # 136 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[4/5] extract embeddings: 100%|| 3/3 [00:00<00:00, 18.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:52:38 clustering_diarizer:393] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-11-13 14:52:38 clustering_diarizer:291] Subsegmentation for embedding extraction: scale4, /content/temp_outputs/speaker_outputs/subsegments_scale4.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:52:38 clustering_diarizer:347] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-11-13 14:52:38 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-11-13 14:52:38 collections:741] Dataset successfully loaded with 183 items and total duration provided from manifest is  0.02 hours.\n",
            "[NeMo I 2024-11-13 14:52:38 collections:746] # 183 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[5/5] extract embeddings: 100%|| 3/3 [00:00<00:00, 14.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:52:39 clustering_diarizer:393] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "clustering: 100%|| 1/1 [00:00<00:00,  4.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:52:39 clustering_diarizer:461] Outputs are saved in /content/temp_outputs directory\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[NeMo W 2024-11-13 14:52:39 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:52:39 msdd_models:966] Loading embedding pickle file of scale:0 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale0_embeddings.pkl\n",
            "[NeMo I 2024-11-13 14:52:39 msdd_models:966] Loading embedding pickle file of scale:1 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale1_embeddings.pkl\n",
            "[NeMo I 2024-11-13 14:52:39 msdd_models:966] Loading embedding pickle file of scale:2 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale2_embeddings.pkl\n",
            "[NeMo I 2024-11-13 14:52:39 msdd_models:966] Loading embedding pickle file of scale:3 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale3_embeddings.pkl\n",
            "[NeMo I 2024-11-13 14:52:39 msdd_models:966] Loading embedding pickle file of scale:4 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale4_embeddings.pkl\n",
            "[NeMo I 2024-11-13 14:52:39 msdd_models:944] Loading cluster label file from /content/temp_outputs/speaker_outputs/subsegments_scale4_cluster.label\n",
            "[NeMo I 2024-11-13 14:52:39 collections:1067] Filtered duration for loading collection is 0.000000.\n",
            "[NeMo I 2024-11-13 14:52:39 collections:1071] Total 1 session files loaded accounting to # 1 audio clips\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/1 [00:00<?, ?it/s][NeMo W 2024-11-13 14:52:39 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/collections/asr/models/msdd_models.py:1333: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "      with autocast():\n",
            "    \n",
            "100%|| 1/1 [00:00<00:00, 30.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:52:39 msdd_models:1407]      [Threshold: 0.7000] [use_clus_as_main=False] [diar_window=50]\n",
            "[NeMo I 2024-11-13 14:52:39 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2024-11-13 14:52:39 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[NeMo W 2024-11-13 14:52:39 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:52:39 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-11-13 14:52:39 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:52:39 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-11-13 14:52:39 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:52:39 msdd_models:1435]   \n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Punctuation restoration is not available for ru language. Using the original punctuation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:55:24 msdd_models:1097] Loading pretrained diar_msdd_telephonic model from NGC\n",
            "[NeMo I 2024-11-13 14:55:24 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_2.0.0rc1/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
            "[NeMo I 2024-11-13 14:55:24 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_2.0.0rc1/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo\n",
            "[NeMo I 2024-11-13 14:55:24 common:826] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-11-13 14:55:26 modelPT:176] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: true\n",
            "    \n",
            "[NeMo W 2024-11-13 14:55:26 modelPT:183] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    \n",
            "[NeMo W 2024-11-13 14:55:26 modelPT:189] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    seq_eval_mode: false\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:55:26 features:305] PADDING: 16\n",
            "[NeMo I 2024-11-13 14:55:27 features:305] PADDING: 16\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-11-13 14:55:27 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/core/connectors/save_restore_connector.py:617: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "      return torch.load(model_weights, map_location='cpu')\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:55:28 save_restore_connector:272] Model EncDecDiarLabelModel was successfully restored from /root/.cache/torch/NeMo/NeMo_2.0.0rc1/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
            "[NeMo I 2024-11-13 14:55:28 features:305] PADDING: 16\n",
            "[NeMo I 2024-11-13 14:55:29 clustering_diarizer:127] Loading pretrained vad_multilingual_marblenet model from NGC\n",
            "[NeMo I 2024-11-13 14:55:29 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_2.0.0rc1/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
            "[NeMo I 2024-11-13 14:55:29 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_2.0.0rc1/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo\n",
            "[NeMo I 2024-11-13 14:55:29 common:826] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-11-13 14:55:29 modelPT:176] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: /manifests/ami_train_0.63.json,/manifests/freesound_background_train.json,/manifests/freesound_laughter_train.json,/manifests/fisher_2004_background.json,/manifests/fisher_2004_speech_sampled.json,/manifests/google_train_manifest.json,/manifests/icsi_all_0.63.json,/manifests/musan_freesound_train.json,/manifests/musan_music_train.json,/manifests/musan_soundbible_train.json,/manifests/mandarin_train_sample.json,/manifests/german_train_sample.json,/manifests/spanish_train_sample.json,/manifests/french_train_sample.json,/manifests/russian_train_sample.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: true\n",
            "    is_tarred: false\n",
            "    tarred_audio_filepaths: null\n",
            "    tarred_shard_strategy: scatter\n",
            "    augmentor:\n",
            "      shift:\n",
            "        prob: 0.5\n",
            "        min_shift_ms: -10.0\n",
            "        max_shift_ms: 10.0\n",
            "      white_noise:\n",
            "        prob: 0.5\n",
            "        min_level: -90\n",
            "        max_level: -46\n",
            "        norm: true\n",
            "      noise:\n",
            "        prob: 0.5\n",
            "        manifest_path: /manifests/noise_0_1_musan_fs.json\n",
            "        min_snr_db: 0\n",
            "        max_snr_db: 30\n",
            "        max_gain_db: 300.0\n",
            "        norm: true\n",
            "      gain:\n",
            "        prob: 0.5\n",
            "        min_gain_dbfs: -10.0\n",
            "        max_gain_dbfs: 10.0\n",
            "        norm: true\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2024-11-13 14:55:29 modelPT:183] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: /manifests/ami_dev_0.63.json,/manifests/freesound_background_dev.json,/manifests/freesound_laughter_dev.json,/manifests/ch120_moved_0.63.json,/manifests/fisher_2005_500_speech_sampled.json,/manifests/google_dev_manifest.json,/manifests/musan_music_dev.json,/manifests/mandarin_dev.json,/manifests/german_dev.json,/manifests/spanish_dev.json,/manifests/french_dev.json,/manifests/russian_dev.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: false\n",
            "    val_loss_idx: 0\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2024-11-13 14:55:29 modelPT:189] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 128\n",
            "    shuffle: false\n",
            "    test_loss_idx: 0\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:55:29 features:305] PADDING: 16\n",
            "[NeMo I 2024-11-13 14:55:29 save_restore_connector:272] Model EncDecClassificationModel was successfully restored from /root/.cache/torch/NeMo/NeMo_2.0.0rc1/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
            "[NeMo I 2024-11-13 14:55:29 msdd_models:870] Multiscale Weights: [1, 1, 1, 1, 1]\n",
            "[NeMo I 2024-11-13 14:55:29 msdd_models:871] Clustering Parameters: {\n",
            "        \"oracle_num_speakers\": false,\n",
            "        \"max_num_speakers\": 8,\n",
            "        \"enhanced_count_thres\": 80,\n",
            "        \"max_rp_threshold\": 0.25,\n",
            "        \"sparse_search_volume\": 30,\n",
            "        \"maj_vote_spk_count\": false,\n",
            "        \"chunk_cluster_count\": 50,\n",
            "        \"embeddings_per_chunk\": 10000\n",
            "    }\n",
            "[NeMo I 2024-11-13 14:55:29 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2024-11-13 14:55:29 clustering_diarizer:313] Split long audio file to avoid CUDA memory issue\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "splitting manifest: 100%|| 1/1 [00:00<00:00,  9.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:55:29 classification_models:293] Perform streaming frame-level VAD\n",
            "[NeMo I 2024-11-13 14:55:29 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-11-13 14:55:29 collections:741] Dataset successfully loaded with 20 items and total duration provided from manifest is  0.28 hours.\n",
            "[NeMo I 2024-11-13 14:55:29 collections:746] # 20 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "vad:   0%|          | 0/20 [00:00<?, ?it/s][NeMo W 2024-11-13 14:55:29 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/collections/asr/models/clustering_diarizer.py:226: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "      with autocast():\n",
            "    \n",
            "[NeMo W 2024-11-13 14:55:29 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/collections/asr/parts/preprocessing/features.py:436: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "      with torch.cuda.amp.autocast(enabled=False):\n",
            "    \n",
            "vad: 100%|| 20/20 [00:04<00:00,  4.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:55:34 clustering_diarizer:254] Generating predictions with overlapping input segments\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "                                                               "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:55:43 clustering_diarizer:266] Converting frame level prediction to speech/no-speech segment in start and end times format.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "creating speech segments: 100%|| 1/1 [00:01<00:00,  1.10s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:55:44 clustering_diarizer:291] Subsegmentation for embedding extraction: scale0, /content/temp_outputs/speaker_outputs/subsegments_scale0.json\n",
            "[NeMo I 2024-11-13 14:55:44 clustering_diarizer:347] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-11-13 14:55:44 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-11-13 14:55:44 collections:741] Dataset successfully loaded with 506 items and total duration provided from manifest is  0.05 hours.\n",
            "[NeMo I 2024-11-13 14:55:44 collections:746] # 506 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[1/5] extract embeddings:   0%|          | 0/8 [00:00<?, ?it/s][NeMo W 2024-11-13 14:55:44 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/collections/asr/models/clustering_diarizer.py:362: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "      with autocast():\n",
            "    \n",
            "[NeMo W 2024-11-13 14:55:44 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/collections/asr/parts/submodules/jasper.py:476: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "      with torch.cuda.amp.autocast(enabled=False):\n",
            "    \n",
            "[1/5] extract embeddings: 100%|| 8/8 [00:00<00:00,  9.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:55:45 clustering_diarizer:393] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-11-13 14:55:45 clustering_diarizer:291] Subsegmentation for embedding extraction: scale1, /content/temp_outputs/speaker_outputs/subsegments_scale1.json\n",
            "[NeMo I 2024-11-13 14:55:45 clustering_diarizer:347] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-11-13 14:55:45 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-11-13 14:55:45 collections:741] Dataset successfully loaded with 511 items and total duration provided from manifest is  0.05 hours.\n",
            "[NeMo I 2024-11-13 14:55:45 collections:746] # 511 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[2/5] extract embeddings: 100%|| 8/8 [00:00<00:00, 12.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:55:45 clustering_diarizer:393] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-11-13 14:55:45 clustering_diarizer:291] Subsegmentation for embedding extraction: scale2, /content/temp_outputs/speaker_outputs/subsegments_scale2.json\n",
            "[NeMo I 2024-11-13 14:55:45 clustering_diarizer:347] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-11-13 14:55:45 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-11-13 14:55:45 collections:741] Dataset successfully loaded with 522 items and total duration provided from manifest is  0.05 hours.\n",
            "[NeMo I 2024-11-13 14:55:45 collections:746] # 522 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[3/5] extract embeddings: 100%|| 9/9 [00:00<00:00, 13.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:55:46 clustering_diarizer:393] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-11-13 14:55:46 clustering_diarizer:291] Subsegmentation for embedding extraction: scale3, /content/temp_outputs/speaker_outputs/subsegments_scale3.json\n",
            "[NeMo I 2024-11-13 14:55:46 clustering_diarizer:347] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-11-13 14:55:46 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-11-13 14:55:46 collections:741] Dataset successfully loaded with 555 items and total duration provided from manifest is  0.05 hours.\n",
            "[NeMo I 2024-11-13 14:55:46 collections:746] # 555 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[4/5] extract embeddings: 100%|| 9/9 [00:00<00:00, 16.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:55:47 clustering_diarizer:393] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-11-13 14:55:47 clustering_diarizer:291] Subsegmentation for embedding extraction: scale4, /content/temp_outputs/speaker_outputs/subsegments_scale4.json\n",
            "[NeMo I 2024-11-13 14:55:47 clustering_diarizer:347] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-11-13 14:55:47 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-11-13 14:55:47 collections:741] Dataset successfully loaded with 659 items and total duration provided from manifest is  0.06 hours.\n",
            "[NeMo I 2024-11-13 14:55:47 collections:746] # 659 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[5/5] extract embeddings: 100%|| 11/11 [00:00<00:00, 17.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:55:48 clustering_diarizer:393] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "clustering: 100%|| 1/1 [00:00<00:00,  2.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:55:48 clustering_diarizer:461] Outputs are saved in /content/temp_outputs directory\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[NeMo W 2024-11-13 14:55:48 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:55:48 msdd_models:966] Loading embedding pickle file of scale:0 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale0_embeddings.pkl\n",
            "[NeMo I 2024-11-13 14:55:48 msdd_models:966] Loading embedding pickle file of scale:1 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale1_embeddings.pkl\n",
            "[NeMo I 2024-11-13 14:55:48 msdd_models:966] Loading embedding pickle file of scale:2 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale2_embeddings.pkl\n",
            "[NeMo I 2024-11-13 14:55:48 msdd_models:966] Loading embedding pickle file of scale:3 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale3_embeddings.pkl\n",
            "[NeMo I 2024-11-13 14:55:48 msdd_models:966] Loading embedding pickle file of scale:4 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale4_embeddings.pkl\n",
            "[NeMo I 2024-11-13 14:55:48 msdd_models:944] Loading cluster label file from /content/temp_outputs/speaker_outputs/subsegments_scale4_cluster.label\n",
            "[NeMo I 2024-11-13 14:55:48 collections:1067] Filtered duration for loading collection is 0.000000.\n",
            "[NeMo I 2024-11-13 14:55:48 collections:1071] Total 1 session files loaded accounting to # 1 audio clips\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/1 [00:00<?, ?it/s][NeMo W 2024-11-13 14:55:48 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/collections/asr/models/msdd_models.py:1333: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "      with autocast():\n",
            "    \n",
            "100%|| 1/1 [00:00<00:00, 23.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:55:48 msdd_models:1407]      [Threshold: 0.7000] [use_clus_as_main=False] [diar_window=50]\n",
            "[NeMo I 2024-11-13 14:55:48 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2024-11-13 14:55:48 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[NeMo W 2024-11-13 14:55:48 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:55:48 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-11-13 14:55:48 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:55:48 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-11-13 14:55:48 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:55:48 msdd_models:1435]   \n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Punctuation restoration is not available for ru language. Using the original punctuation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:58:23 msdd_models:1097] Loading pretrained diar_msdd_telephonic model from NGC\n",
            "[NeMo I 2024-11-13 14:58:23 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_2.0.0rc1/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
            "[NeMo I 2024-11-13 14:58:23 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_2.0.0rc1/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo\n",
            "[NeMo I 2024-11-13 14:58:23 common:826] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-11-13 14:58:25 modelPT:176] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: true\n",
            "    \n",
            "[NeMo W 2024-11-13 14:58:25 modelPT:183] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    \n",
            "[NeMo W 2024-11-13 14:58:25 modelPT:189] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    seq_eval_mode: false\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:58:25 features:305] PADDING: 16\n",
            "[NeMo I 2024-11-13 14:58:25 features:305] PADDING: 16\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-11-13 14:58:26 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/core/connectors/save_restore_connector.py:617: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "      return torch.load(model_weights, map_location='cpu')\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:58:29 save_restore_connector:272] Model EncDecDiarLabelModel was successfully restored from /root/.cache/torch/NeMo/NeMo_2.0.0rc1/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
            "[NeMo I 2024-11-13 14:58:29 features:305] PADDING: 16\n",
            "[NeMo I 2024-11-13 14:58:29 clustering_diarizer:127] Loading pretrained vad_multilingual_marblenet model from NGC\n",
            "[NeMo I 2024-11-13 14:58:29 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_2.0.0rc1/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
            "[NeMo I 2024-11-13 14:58:29 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_2.0.0rc1/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo\n",
            "[NeMo I 2024-11-13 14:58:29 common:826] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-11-13 14:58:30 modelPT:176] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: /manifests/ami_train_0.63.json,/manifests/freesound_background_train.json,/manifests/freesound_laughter_train.json,/manifests/fisher_2004_background.json,/manifests/fisher_2004_speech_sampled.json,/manifests/google_train_manifest.json,/manifests/icsi_all_0.63.json,/manifests/musan_freesound_train.json,/manifests/musan_music_train.json,/manifests/musan_soundbible_train.json,/manifests/mandarin_train_sample.json,/manifests/german_train_sample.json,/manifests/spanish_train_sample.json,/manifests/french_train_sample.json,/manifests/russian_train_sample.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: true\n",
            "    is_tarred: false\n",
            "    tarred_audio_filepaths: null\n",
            "    tarred_shard_strategy: scatter\n",
            "    augmentor:\n",
            "      shift:\n",
            "        prob: 0.5\n",
            "        min_shift_ms: -10.0\n",
            "        max_shift_ms: 10.0\n",
            "      white_noise:\n",
            "        prob: 0.5\n",
            "        min_level: -90\n",
            "        max_level: -46\n",
            "        norm: true\n",
            "      noise:\n",
            "        prob: 0.5\n",
            "        manifest_path: /manifests/noise_0_1_musan_fs.json\n",
            "        min_snr_db: 0\n",
            "        max_snr_db: 30\n",
            "        max_gain_db: 300.0\n",
            "        norm: true\n",
            "      gain:\n",
            "        prob: 0.5\n",
            "        min_gain_dbfs: -10.0\n",
            "        max_gain_dbfs: 10.0\n",
            "        norm: true\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2024-11-13 14:58:30 modelPT:183] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: /manifests/ami_dev_0.63.json,/manifests/freesound_background_dev.json,/manifests/freesound_laughter_dev.json,/manifests/ch120_moved_0.63.json,/manifests/fisher_2005_500_speech_sampled.json,/manifests/google_dev_manifest.json,/manifests/musan_music_dev.json,/manifests/mandarin_dev.json,/manifests/german_dev.json,/manifests/spanish_dev.json,/manifests/french_dev.json,/manifests/russian_dev.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: false\n",
            "    val_loss_idx: 0\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2024-11-13 14:58:30 modelPT:189] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 128\n",
            "    shuffle: false\n",
            "    test_loss_idx: 0\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:58:30 features:305] PADDING: 16\n",
            "[NeMo I 2024-11-13 14:58:30 save_restore_connector:272] Model EncDecClassificationModel was successfully restored from /root/.cache/torch/NeMo/NeMo_2.0.0rc1/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
            "[NeMo I 2024-11-13 14:58:30 msdd_models:870] Multiscale Weights: [1, 1, 1, 1, 1]\n",
            "[NeMo I 2024-11-13 14:58:30 msdd_models:871] Clustering Parameters: {\n",
            "        \"oracle_num_speakers\": false,\n",
            "        \"max_num_speakers\": 8,\n",
            "        \"enhanced_count_thres\": 80,\n",
            "        \"max_rp_threshold\": 0.25,\n",
            "        \"sparse_search_volume\": 30,\n",
            "        \"maj_vote_spk_count\": false,\n",
            "        \"chunk_cluster_count\": 50,\n",
            "        \"embeddings_per_chunk\": 10000\n",
            "    }\n",
            "[NeMo I 2024-11-13 14:58:30 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2024-11-13 14:58:30 clustering_diarizer:313] Split long audio file to avoid CUDA memory issue\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "splitting manifest: 100%|| 1/1 [00:00<00:00, 12.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:58:30 classification_models:293] Perform streaming frame-level VAD\n",
            "[NeMo I 2024-11-13 14:58:30 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-11-13 14:58:30 collections:741] Dataset successfully loaded with 17 items and total duration provided from manifest is  0.23 hours.\n",
            "[NeMo I 2024-11-13 14:58:30 collections:746] # 17 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "vad:   0%|          | 0/17 [00:00<?, ?it/s][NeMo W 2024-11-13 14:58:30 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/collections/asr/models/clustering_diarizer.py:226: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "      with autocast():\n",
            "    \n",
            "[NeMo W 2024-11-13 14:58:30 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/collections/asr/parts/preprocessing/features.py:436: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "      with torch.cuda.amp.autocast(enabled=False):\n",
            "    \n",
            "vad: 100%|| 17/17 [00:03<00:00,  4.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:58:34 clustering_diarizer:254] Generating predictions with overlapping input segments\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "                                                               "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:58:41 clustering_diarizer:266] Converting frame level prediction to speech/no-speech segment in start and end times format.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "creating speech segments: 100%|| 1/1 [00:00<00:00,  1.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:58:42 clustering_diarizer:291] Subsegmentation for embedding extraction: scale0, /content/temp_outputs/speaker_outputs/subsegments_scale0.json\n",
            "[NeMo I 2024-11-13 14:58:42 clustering_diarizer:347] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-11-13 14:58:42 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-11-13 14:58:42 collections:741] Dataset successfully loaded with 661 items and total duration provided from manifest is  0.11 hours.\n",
            "[NeMo I 2024-11-13 14:58:42 collections:746] # 661 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[1/5] extract embeddings:   0%|          | 0/11 [00:00<?, ?it/s][NeMo W 2024-11-13 14:58:42 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/collections/asr/models/clustering_diarizer.py:362: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "      with autocast():\n",
            "    \n",
            "[NeMo W 2024-11-13 14:58:42 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/collections/asr/parts/submodules/jasper.py:476: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "      with torch.cuda.amp.autocast(enabled=False):\n",
            "    \n",
            "[1/5] extract embeddings: 100%|| 11/11 [00:01<00:00,  9.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:58:43 clustering_diarizer:393] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:58:43 clustering_diarizer:291] Subsegmentation for embedding extraction: scale1, /content/temp_outputs/speaker_outputs/subsegments_scale1.json\n",
            "[NeMo I 2024-11-13 14:58:43 clustering_diarizer:347] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-11-13 14:58:43 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-11-13 14:58:43 collections:741] Dataset successfully loaded with 704 items and total duration provided from manifest is  0.12 hours.\n",
            "[NeMo I 2024-11-13 14:58:43 collections:746] # 704 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[2/5] extract embeddings: 100%|| 11/11 [00:00<00:00, 11.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:58:44 clustering_diarizer:393] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-11-13 14:58:44 clustering_diarizer:291] Subsegmentation for embedding extraction: scale2, /content/temp_outputs/speaker_outputs/subsegments_scale2.json\n",
            "[NeMo I 2024-11-13 14:58:44 clustering_diarizer:347] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-11-13 14:58:44 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-11-13 14:58:44 collections:741] Dataset successfully loaded with 780 items and total duration provided from manifest is  0.12 hours.\n",
            "[NeMo I 2024-11-13 14:58:44 collections:746] # 780 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[3/5] extract embeddings: 100%|| 13/13 [00:00<00:00, 13.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:58:45 clustering_diarizer:393] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-11-13 14:58:45 clustering_diarizer:291] Subsegmentation for embedding extraction: scale3, /content/temp_outputs/speaker_outputs/subsegments_scale3.json\n",
            "[NeMo I 2024-11-13 14:58:45 clustering_diarizer:347] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-11-13 14:58:45 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-11-13 14:58:45 collections:741] Dataset successfully loaded with 926 items and total duration provided from manifest is  0.13 hours.\n",
            "[NeMo I 2024-11-13 14:58:45 collections:746] # 926 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[4/5] extract embeddings: 100%|| 15/15 [00:01<00:00, 14.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:58:47 clustering_diarizer:393] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-11-13 14:58:47 clustering_diarizer:291] Subsegmentation for embedding extraction: scale4, /content/temp_outputs/speaker_outputs/subsegments_scale4.json\n",
            "[NeMo I 2024-11-13 14:58:47 clustering_diarizer:347] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-11-13 14:58:47 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-11-13 14:58:47 collections:741] Dataset successfully loaded with 1281 items and total duration provided from manifest is  0.14 hours.\n",
            "[NeMo I 2024-11-13 14:58:47 collections:746] # 1281 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[5/5] extract embeddings: 100%|| 21/21 [00:01<00:00, 13.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:58:49 clustering_diarizer:393] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "clustering: 100%|| 1/1 [00:01<00:00,  1.38s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:58:50 clustering_diarizer:461] Outputs are saved in /content/temp_outputs directory\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[NeMo W 2024-11-13 14:58:50 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:58:50 msdd_models:966] Loading embedding pickle file of scale:0 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale0_embeddings.pkl\n",
            "[NeMo I 2024-11-13 14:58:50 msdd_models:966] Loading embedding pickle file of scale:1 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale1_embeddings.pkl\n",
            "[NeMo I 2024-11-13 14:58:50 msdd_models:966] Loading embedding pickle file of scale:2 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale2_embeddings.pkl\n",
            "[NeMo I 2024-11-13 14:58:50 msdd_models:966] Loading embedding pickle file of scale:3 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale3_embeddings.pkl\n",
            "[NeMo I 2024-11-13 14:58:50 msdd_models:966] Loading embedding pickle file of scale:4 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale4_embeddings.pkl\n",
            "[NeMo I 2024-11-13 14:58:50 msdd_models:944] Loading cluster label file from /content/temp_outputs/speaker_outputs/subsegments_scale4_cluster.label\n",
            "[NeMo I 2024-11-13 14:58:50 collections:1067] Filtered duration for loading collection is 0.000000.\n",
            "[NeMo I 2024-11-13 14:58:50 collections:1071] Total 1 session files loaded accounting to # 1 audio clips\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/1 [00:00<?, ?it/s][NeMo W 2024-11-13 14:58:50 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/collections/asr/models/msdd_models.py:1333: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "      with autocast():\n",
            "    \n",
            "100%|| 1/1 [00:00<00:00, 11.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:58:50 msdd_models:1407]      [Threshold: 0.7000] [use_clus_as_main=False] [diar_window=50]\n",
            "[NeMo I 2024-11-13 14:58:50 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2024-11-13 14:58:50 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[NeMo W 2024-11-13 14:58:51 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:58:51 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-11-13 14:58:51 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:58:51 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-11-13 14:58:51 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-11-13 14:58:51 msdd_models:1435]   \n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Punctuation restoration is not available for ru language. Using the original punctuation.\n"
          ]
        }
      ],
      "source": [
        "# Name of the audio file\n",
        "#audio_path = \"123.mp3\"\n",
        "for audio_path in onlyfiles:\n",
        "  if enable_stemming:\n",
        "      # Isolate vocals from the rest of the audio\n",
        "\n",
        "      return_code = os.system(\n",
        "          f'python3 -m demucs.separate -n htdemucs --two-stems=vocals \"{audio_path}\" -o \"temp_outputs\"'\n",
        "      )\n",
        "\n",
        "      if return_code != 0:\n",
        "          logging.warning(\"Source splitting failed, using original audio file.\")\n",
        "          vocal_target = audio_path\n",
        "      else:\n",
        "          vocal_target = os.path.join(\n",
        "              \"temp_outputs\",\n",
        "              \"htdemucs\",\n",
        "              os.path.splitext(os.path.basename(audio_path))[0],\n",
        "              \"vocals.wav\",\n",
        "          )\n",
        "  else:\n",
        "      vocal_target = audio_path\n",
        "\n",
        "  compute_type = \"float16\"\n",
        "  # or run on GPU with INT8\n",
        "  # compute_type = \"int8_float16\"\n",
        "  # or run on CPU with INT8\n",
        "  # compute_type = \"int8\"\n",
        "\n",
        "  whisper_model = faster_whisper.WhisperModel(\n",
        "      whisper_model_name, device=device, compute_type=compute_type\n",
        "  )\n",
        "  whisper_pipeline = faster_whisper.BatchedInferencePipeline(whisper_model)\n",
        "  audio_waveform = faster_whisper.decode_audio(vocal_target)\n",
        "  suppress_tokens = (\n",
        "      find_numeral_symbol_tokens(whisper_model.hf_tokenizer)\n",
        "      if suppress_numerals\n",
        "      else [-1]\n",
        "  )\n",
        "\n",
        "  if batch_size > 0:\n",
        "      transcript_segments, info = whisper_pipeline.transcribe(\n",
        "          audio_waveform,\n",
        "          language,\n",
        "          suppress_tokens=suppress_tokens,\n",
        "          batch_size=batch_size,\n",
        "          without_timestamps=True,\n",
        "      )\n",
        "  else:\n",
        "      transcript_segments, info = whisper_model.transcribe(\n",
        "          audio_waveform,\n",
        "          language,\n",
        "          suppress_tokens=suppress_tokens,\n",
        "          without_timestamps=True,\n",
        "          vad_filter=True,\n",
        "      )\n",
        "\n",
        "  full_transcript = \"\".join(segment.text for segment in transcript_segments)\n",
        "\n",
        "  # clear gpu vram\n",
        "  del whisper_model, whisper_pipeline\n",
        "  torch.cuda.empty_cache()\n",
        "\n",
        "  alignment_model, alignment_tokenizer = load_alignment_model(\n",
        "      device,\n",
        "      dtype=torch.float16 if device == \"cuda\" else torch.float32,\n",
        "  )\n",
        "\n",
        "  audio_waveform = audio_waveform.to(alignment_model.dtype).to(alignment_model.device)\n",
        "\n",
        "  emissions, stride = generate_emissions(\n",
        "      alignment_model, audio_waveform, batch_size=batch_size\n",
        "  )\n",
        "\n",
        "  del alignment_model\n",
        "  torch.cuda.empty_cache()\n",
        "\n",
        "  tokens_starred, text_starred = preprocess_text(\n",
        "      full_transcript,\n",
        "      romanize=True,\n",
        "      language=langs_to_iso[info.language],\n",
        "  )\n",
        "\n",
        "  segments, scores, blank_token = get_alignments(\n",
        "      emissions,\n",
        "      tokens_starred,\n",
        "      alignment_tokenizer,\n",
        "  )\n",
        "\n",
        "  spans = get_spans(tokens_starred, segments, blank_token)\n",
        "\n",
        "  word_timestamps = postprocess_results(text_starred, spans, stride, scores)\n",
        "\n",
        "  ROOT = os.getcwd()\n",
        "  temp_path = os.path.join(ROOT, \"temp_outputs\")\n",
        "  os.makedirs(temp_path, exist_ok=True)\n",
        "  torchaudio.save(\n",
        "      os.path.join(temp_path, \"mono_file.wav\"),\n",
        "      audio_waveform.cpu().unsqueeze(0).float(),\n",
        "      16000,\n",
        "      channels_first=True,\n",
        "  )\n",
        "\n",
        "  # Initialize NeMo MSDD diarization model\n",
        "  msdd_model = NeuralDiarizer(cfg=create_config(temp_path)).to(\"cuda\")\n",
        "  msdd_model.diarize()\n",
        "\n",
        "  del msdd_model\n",
        "  torch.cuda.empty_cache()\n",
        "\n",
        "  # Reading timestamps <> Speaker Labels mapping\n",
        "\n",
        "  speaker_ts = []\n",
        "  with open(os.path.join(temp_path, \"pred_rttms\", \"mono_file.rttm\"), \"r\") as f:\n",
        "      lines = f.readlines()\n",
        "      for line in lines:\n",
        "          line_list = line.split(\" \")\n",
        "          s = int(float(line_list[5]) * 1000)\n",
        "          e = s + int(float(line_list[8]) * 1000)\n",
        "          speaker_ts.append([s, e, int(line_list[11].split(\"_\")[-1])])\n",
        "\n",
        "  wsm = get_words_speaker_mapping(word_timestamps, speaker_ts, \"start\")\n",
        "\n",
        "  if info.language in punct_model_langs:\n",
        "      # restoring punctuation in the transcript to help realign the sentences\n",
        "      punct_model = PunctuationModel(model=\"kredor/punctuate-all\")\n",
        "\n",
        "      words_list = list(map(lambda x: x[\"word\"], wsm))\n",
        "\n",
        "      labled_words = punct_model.predict(words_list, chunk_size=230)\n",
        "\n",
        "      ending_puncts = \".?!\"\n",
        "      model_puncts = \".,;:!?\"\n",
        "\n",
        "      # We don't want to punctuate U.S.A. with a period. Right?\n",
        "      is_acronym = lambda x: re.fullmatch(r\"\\b(?:[a-zA-Z]\\.){2,}\", x)\n",
        "\n",
        "      for word_dict, labeled_tuple in zip(wsm, labled_words):\n",
        "          word = word_dict[\"word\"]\n",
        "          if (\n",
        "              word\n",
        "              and labeled_tuple[1] in ending_puncts\n",
        "              and (word[-1] not in model_puncts or is_acronym(word))\n",
        "          ):\n",
        "              word += labeled_tuple[1]\n",
        "              if word.endswith(\"..\"):\n",
        "                  word = word.rstrip(\".\")\n",
        "              word_dict[\"word\"] = word\n",
        "\n",
        "  else:\n",
        "      logging.warning(\n",
        "          f\"Punctuation restoration is not available for {info.language} language. Using the original punctuation.\"\n",
        "      )\n",
        "\n",
        "  wsm = get_realigned_ws_mapping_with_punctuation(wsm)\n",
        "  ssm = get_sentences_speaker_mapping(wsm, speaker_ts)\n",
        "\n",
        "  with open(f\"{os.path.splitext(audio_path)[0]}.txt\", \"w\", encoding=\"utf-8-sig\") as f:\n",
        "      get_speaker_aware_transcript(ssm, f)\n",
        "\n",
        "  with open(f\"{os.path.splitext(audio_path)[0]}.srt\", \"w\", encoding=\"utf-8-sig\") as srt:\n",
        "      write_srt(ssm, srt)\n",
        "\n",
        "  cleanup(temp_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GuXi7cv-Uh1w"
      },
      "source": [
        "## Aligning the transcription with the original audio using Forced Alignment\n",
        "---\n",
        "Forced alignment aims to to align the transcription segments with the original audio signal contained in the vocal_target file. This process involves finding the exact timestamps in the audio signal where each segment was spoken and aligning the text accordingly.\n",
        "\n",
        "By combining the outputs of the two models, the code produces a fully aligned transcription of the speech contained in the vocal_target file. This aligned transcription can be useful for a variety of speech processing tasks, such as speaker diarization, sentiment analysis, and language identification."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7EEaJPsQ21Rx"
      },
      "source": [
        "## Convert audio to mono for NeMo combatibility"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D1gkViCf2-CV"
      },
      "source": [
        "## Speaker Diarization using NeMo MSDD Model\n",
        "---\n",
        "This code uses a model called Nvidia NeMo MSDD (Multi-scale Diarization Decoder) to perform speaker diarization on an audio signal. Speaker diarization is the process of separating an audio signal into different segments based on who is speaking at any given time."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NmkZYaDAEOAg"
      },
      "source": [
        "## Mapping Spekers to Sentences According to Timestamps"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Ruxc8S1EXtW"
      },
      "source": [
        "## Realligning Speech segments using Punctuation\n",
        "---\n",
        "\n",
        "This code provides a method for disambiguating speaker labels in cases where a sentence is split between two different speakers. It uses punctuation markings to determine the dominant speaker for each sentence in the transcription.\n",
        "\n",
        "```\n",
        "Speaker A: It's got to come from somewhere else. Yeah, that one's also fun because you know the lows are\n",
        "Speaker B: going to suck, right? So it's actually it hits you on both sides.\n",
        "```\n",
        "\n",
        "For example, if a sentence is split between two speakers, the code takes the mode of speaker labels for each word in the sentence, and uses that speaker label for the whole sentence. This can help to improve the accuracy of speaker diarization, especially in cases where the Whisper model may not take fine utterances like \"hmm\" and \"yeah\" into account, but the Diarization Model (Nemo) may include them, leading to inconsistent results.\n",
        "\n",
        "The code also handles cases where one speaker is giving a monologue while other speakers are making occasional comments in the background. It ignores the comments and assigns the entire monologue to the speaker who is speaking the majority of the time. This provides a robust and reliable method for realigning speech segments to their respective speakers based on punctuation in the transcription."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vF2QAtLOFvwZ"
      },
      "source": [
        "## Cleanup and Exporing the results"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "eCmjcOc9yEtQ",
        "jbsUt3SwyhjD"
      ],
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c01605c21d0e47319d8cca72738b4ae1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_53e7265c51a146379f3973e0309c86ce",
              "IPY_MODEL_a48c9d954f37468aaa5f65a8ca035cc5",
              "IPY_MODEL_23fc7546cfac4a47bc351157ed4cd5b2"
            ],
            "layout": "IPY_MODEL_e1e863dde53e4924a56dff040d2a0545"
          }
        },
        "53e7265c51a146379f3973e0309c86ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f764375831cf43ef906b0a023e1072ef",
            "placeholder": "",
            "style": "IPY_MODEL_d4d6b7cca5ad487c8fa4f16cdff5bf36",
            "value": "tokenizer.json:100%"
          }
        },
        "a48c9d954f37468aaa5f65a8ca035cc5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_db3507823b9844848a180e541c72c4c7",
            "max": 2203239,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1bba856ca6194b22b70ff6743f5d5160",
            "value": 2203239
          }
        },
        "23fc7546cfac4a47bc351157ed4cd5b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c3ae684207894b3887f31035626bfb41",
            "placeholder": "",
            "style": "IPY_MODEL_e5b11bd81814497d9c9d08f964844ece",
            "value": "2.20M/2.20M[00:00&lt;00:00,9.01MB/s]"
          }
        },
        "e1e863dde53e4924a56dff040d2a0545": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f764375831cf43ef906b0a023e1072ef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d4d6b7cca5ad487c8fa4f16cdff5bf36": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "db3507823b9844848a180e541c72c4c7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1bba856ca6194b22b70ff6743f5d5160": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c3ae684207894b3887f31035626bfb41": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e5b11bd81814497d9c9d08f964844ece": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c22a6f46cf2b447b8af0f62dc018ffa3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0cf90816b3914e6c84b60ca89ceebd7e",
              "IPY_MODEL_2afee9437d444192b30fba33d7df4d0e",
              "IPY_MODEL_a83f80e518f54e788be2e7874be8f62c"
            ],
            "layout": "IPY_MODEL_23a46e48c4a4449abffebf2093e79ea0"
          }
        },
        "0cf90816b3914e6c84b60ca89ceebd7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_705bc884c0c041b6996e6006e5ef5683",
            "placeholder": "",
            "style": "IPY_MODEL_e2563276abc1432fae3734e16e05ab64",
            "value": "model.bin:100%"
          }
        },
        "2afee9437d444192b30fba33d7df4d0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_16d1767b2ce4415f82eba1bafd4d07c4",
            "max": 3086912962,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_76dc9d5391a04deaa5e7173f2ac7f202",
            "value": 3086912962
          }
        },
        "a83f80e518f54e788be2e7874be8f62c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3fcafca5bb174ba38ed5a1850cbb9c4f",
            "placeholder": "",
            "style": "IPY_MODEL_42001f5db63443ebaf8ea21e0180e357",
            "value": "3.09G/3.09G[01:12&lt;00:00,42.1MB/s]"
          }
        },
        "23a46e48c4a4449abffebf2093e79ea0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "705bc884c0c041b6996e6006e5ef5683": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e2563276abc1432fae3734e16e05ab64": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "16d1767b2ce4415f82eba1bafd4d07c4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "76dc9d5391a04deaa5e7173f2ac7f202": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3fcafca5bb174ba38ed5a1850cbb9c4f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "42001f5db63443ebaf8ea21e0180e357": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "79b71953660646609485bcda7214a19a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1c5196d424e6456bbc277bea895b5d4e",
              "IPY_MODEL_ba7cefcd6ed1421eaa3ffa03216dc6fe",
              "IPY_MODEL_ec915f7d20c54dc2a1721ceaae9ebcf9"
            ],
            "layout": "IPY_MODEL_ff0ba2ff78c847b289ef97120ba9aade"
          }
        },
        "1c5196d424e6456bbc277bea895b5d4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8e176c6703f04677bdd369b17a3ed40f",
            "placeholder": "",
            "style": "IPY_MODEL_199037df7c824e50b0861e9d1d267427",
            "value": "vocabulary.txt:100%"
          }
        },
        "ba7cefcd6ed1421eaa3ffa03216dc6fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0ab1429dc8c4449791cf50fa4e115c5b",
            "max": 459861,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_41590a89e41c43a69cfbe64bd8e4c45d",
            "value": 459861
          }
        },
        "ec915f7d20c54dc2a1721ceaae9ebcf9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f647c5a7472346fea405d24dde2f553b",
            "placeholder": "",
            "style": "IPY_MODEL_f05c27bfa741438f8fadd17a5260f6bb",
            "value": "460k/460k[00:00&lt;00:00,3.56MB/s]"
          }
        },
        "ff0ba2ff78c847b289ef97120ba9aade": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8e176c6703f04677bdd369b17a3ed40f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "199037df7c824e50b0861e9d1d267427": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0ab1429dc8c4449791cf50fa4e115c5b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "41590a89e41c43a69cfbe64bd8e4c45d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f647c5a7472346fea405d24dde2f553b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f05c27bfa741438f8fadd17a5260f6bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f8b13cdea202473a97928d008332771d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_dc230e277b614195b22efbf363755cdd",
              "IPY_MODEL_3f1615c626064219b6db7b2cd357f713",
              "IPY_MODEL_4da3983480244eb89105cf7be2b9b854"
            ],
            "layout": "IPY_MODEL_9d515a50029042a3b48d75c635100bd1"
          }
        },
        "dc230e277b614195b22efbf363755cdd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_773b7cd5e2534f67ab3ed840ec0355c0",
            "placeholder": "",
            "style": "IPY_MODEL_4df3e6e6cd4b47d88717bcc2e03f506a",
            "value": "config.json:100%"
          }
        },
        "3f1615c626064219b6db7b2cd357f713": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3d4ea0c0c68c421e876de354c7b82cf3",
            "max": 2796,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_73c4f19c40794dafba009119ce485ea6",
            "value": 2796
          }
        },
        "4da3983480244eb89105cf7be2b9b854": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3a0c96c89a4345c4b9e7ed432b8ff8c7",
            "placeholder": "",
            "style": "IPY_MODEL_bd7a11f3535b4455bb3b0a280cc87b9f",
            "value": "2.80k/2.80k[00:00&lt;00:00,72.3kB/s]"
          }
        },
        "9d515a50029042a3b48d75c635100bd1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "773b7cd5e2534f67ab3ed840ec0355c0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4df3e6e6cd4b47d88717bcc2e03f506a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3d4ea0c0c68c421e876de354c7b82cf3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "73c4f19c40794dafba009119ce485ea6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3a0c96c89a4345c4b9e7ed432b8ff8c7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bd7a11f3535b4455bb3b0a280cc87b9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b1fc50be6c3b40c4bd4b5e8df6bd6ede": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_32df6a61cd44478c8cacef20c06d6360",
              "IPY_MODEL_d763f50447434f2b873fcfd73c2f5547",
              "IPY_MODEL_174da3b8b94b477d8775a9e72d5fcc0b"
            ],
            "layout": "IPY_MODEL_ef01100af2a34e61bae9d2664d572ef1"
          }
        },
        "32df6a61cd44478c8cacef20c06d6360": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_15ece113dba74581b62ecd7285fc0721",
            "placeholder": "",
            "style": "IPY_MODEL_85b9a91bbf9745f58a04e6e4dfd2e403",
            "value": "config.json:100%"
          }
        },
        "d763f50447434f2b873fcfd73c2f5547": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9eb527d7c0024f58aec3a0d77c836084",
            "max": 2076,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dd722ac483d241e0a0e50e886e739f03",
            "value": 2076
          }
        },
        "174da3b8b94b477d8775a9e72d5fcc0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4c7ec88627ac4561b181effa3a28dedd",
            "placeholder": "",
            "style": "IPY_MODEL_c02eb4c6cb1a40abaefa554b7e2374bc",
            "value": "2.08k/2.08k[00:00&lt;00:00,185kB/s]"
          }
        },
        "ef01100af2a34e61bae9d2664d572ef1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "15ece113dba74581b62ecd7285fc0721": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "85b9a91bbf9745f58a04e6e4dfd2e403": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9eb527d7c0024f58aec3a0d77c836084": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dd722ac483d241e0a0e50e886e739f03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4c7ec88627ac4561b181effa3a28dedd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c02eb4c6cb1a40abaefa554b7e2374bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1ea3e8f9b8034860b12bb921628d7246": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2da5cb10605d4a8cb0caa41403505b97",
              "IPY_MODEL_a9121b0fdddf489da8dcc48d510f1795",
              "IPY_MODEL_0ce95ae460664cfb8125bb54b0cbe5f7"
            ],
            "layout": "IPY_MODEL_75258c54351642cda949fb3ba49a153c"
          }
        },
        "2da5cb10605d4a8cb0caa41403505b97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_894c4e1cbdea441f8e53deb9c32f16d7",
            "placeholder": "",
            "style": "IPY_MODEL_ab26f6828c4e4a5ea734c311668f91c2",
            "value": "model.safetensors:100%"
          }
        },
        "a9121b0fdddf489da8dcc48d510f1795": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8efdbd73a76c4203a17737b357eb7995",
            "max": 1261930388,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_929b0993b47a4066bb211dc3d453c90f",
            "value": 1261930388
          }
        },
        "0ce95ae460664cfb8125bb54b0cbe5f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ecdf1d0ec7cb4a0f87866dec32fe335c",
            "placeholder": "",
            "style": "IPY_MODEL_ab2a58e7a44a4669892a71084dc53706",
            "value": "1.26G/1.26G[00:29&lt;00:00,41.3MB/s]"
          }
        },
        "75258c54351642cda949fb3ba49a153c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "894c4e1cbdea441f8e53deb9c32f16d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ab26f6828c4e4a5ea734c311668f91c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8efdbd73a76c4203a17737b357eb7995": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "929b0993b47a4066bb211dc3d453c90f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ecdf1d0ec7cb4a0f87866dec32fe335c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ab2a58e7a44a4669892a71084dc53706": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d78903f68adf4f9d9fba031c168217c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_64161521d69a495ba066855c2749bbcd",
              "IPY_MODEL_2fa83df0a9194f13bc4989ef15e0e726",
              "IPY_MODEL_22b33a5afdfd4282ba6d8d7910a0e74f"
            ],
            "layout": "IPY_MODEL_d030eca7d22448818e63e488fda7e2e1"
          }
        },
        "64161521d69a495ba066855c2749bbcd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8f16b93b2108483096e9189576b79d19",
            "placeholder": "",
            "style": "IPY_MODEL_93bb87ca8dae44569e3f7c8f79c4c99a",
            "value": "tokenizer_config.json:100%"
          }
        },
        "2fa83df0a9194f13bc4989ef15e0e726": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a0fc4c16f0ff406ea27e292dfd0e2a29",
            "max": 1046,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_50783815a7994fe485462bf3495add5a",
            "value": 1046
          }
        },
        "22b33a5afdfd4282ba6d8d7910a0e74f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e6ae77b9d83644e6a296a8872b7505d3",
            "placeholder": "",
            "style": "IPY_MODEL_2d9ec28ec588404197736b159465c787",
            "value": "1.05k/1.05k[00:00&lt;00:00,69.7kB/s]"
          }
        },
        "d030eca7d22448818e63e488fda7e2e1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8f16b93b2108483096e9189576b79d19": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "93bb87ca8dae44569e3f7c8f79c4c99a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a0fc4c16f0ff406ea27e292dfd0e2a29": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "50783815a7994fe485462bf3495add5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e6ae77b9d83644e6a296a8872b7505d3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2d9ec28ec588404197736b159465c787": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fd4fbee16ebb4ba4aa7d4bd1c41db824": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3f97be094182405ca671d5dde629eeb0",
              "IPY_MODEL_b50a448d4a484e40a41115050a99dd93",
              "IPY_MODEL_b39584fa09964a1a99e5b4b62656f3c9"
            ],
            "layout": "IPY_MODEL_e749d1a6e2774079a376a86cd42f1812"
          }
        },
        "3f97be094182405ca671d5dde629eeb0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_289921a0df0e4cc2b819e3683cdd0e06",
            "placeholder": "",
            "style": "IPY_MODEL_db4aa6d29c4f40edbef48226a874300f",
            "value": "vocab.json:100%"
          }
        },
        "b50a448d4a484e40a41115050a99dd93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d26c9e28aed14216b8c0bcc6558b2799",
            "max": 286,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1165d84159a9427b9fc4482004e2b0cb",
            "value": 286
          }
        },
        "b39584fa09964a1a99e5b4b62656f3c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7f99aa512e484a96a27b0623e15dc959",
            "placeholder": "",
            "style": "IPY_MODEL_be11badf142f4c3082effe8c1ef18246",
            "value": "286/286[00:00&lt;00:00,27.5kB/s]"
          }
        },
        "e749d1a6e2774079a376a86cd42f1812": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "289921a0df0e4cc2b819e3683cdd0e06": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "db4aa6d29c4f40edbef48226a874300f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d26c9e28aed14216b8c0bcc6558b2799": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1165d84159a9427b9fc4482004e2b0cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7f99aa512e484a96a27b0623e15dc959": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "be11badf142f4c3082effe8c1ef18246": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b342a1fc3362490b8cf61207fb4a22c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5f9d82e19c6b4ce485d97833d7bea61a",
              "IPY_MODEL_d50689ebff53459db173299f71433198",
              "IPY_MODEL_fecba4998bf3499c83e9e61527f55802"
            ],
            "layout": "IPY_MODEL_d3ff2b5046b342ed8dde8eeb790e11ca"
          }
        },
        "5f9d82e19c6b4ce485d97833d7bea61a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5747c85621fe4ea091ea70969ff19be0",
            "placeholder": "",
            "style": "IPY_MODEL_af3c7d71c6fd42ab9c90cd1734e2524f",
            "value": "special_tokens_map.json:100%"
          }
        },
        "d50689ebff53459db173299f71433198": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f6bdefa4997c4c6ebc0e2f95b8be90ef",
            "max": 74,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d0edf36ff9184a9aa03c83c2640af3e1",
            "value": 74
          }
        },
        "fecba4998bf3499c83e9e61527f55802": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a20298c46e1e49bc814ab5ddd18bb3e2",
            "placeholder": "",
            "style": "IPY_MODEL_fc99ee7a55d64cc4ac6e23d317f833ad",
            "value": "74.0/74.0[00:00&lt;00:00,6.72kB/s]"
          }
        },
        "d3ff2b5046b342ed8dde8eeb790e11ca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5747c85621fe4ea091ea70969ff19be0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "af3c7d71c6fd42ab9c90cd1734e2524f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f6bdefa4997c4c6ebc0e2f95b8be90ef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d0edf36ff9184a9aa03c83c2640af3e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a20298c46e1e49bc814ab5ddd18bb3e2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fc99ee7a55d64cc4ac6e23d317f833ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}